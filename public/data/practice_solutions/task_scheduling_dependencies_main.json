{
  "problem_title": "Task Scheduling with Dependencies",
  "difficulty": "medium",
  "category": "DSA/Graphs",
  "estimated_time": "45-60 minutes",
  "problem_analysis": {
    "first_impressions": "This is a classic **DAG (Directed Acyclic Graph)** problem combining **topological sorting** with **critical path analysis**. The two parts - finding valid order and calculating minimum time - are intertwined through the same traversal. When I see 'dependencies' and 'order', my mind immediately goes to topological sort. The 'unlimited parallel workers' signals that we need critical path, not sequential sum.",
    "pattern_recognition": "**Topological Sort (Kahn's BFS)** + **Critical Path Method (CPM)** + **Cycle Detection**. This combines graph traversal with dynamic programming on DAGs. The key is processing nodes in topological order while tracking completion times.",
    "key_constraints": [
      "Task IDs may not be consecutive (1, 5, 100) - **must use HashMap** not array indexing",
      "Up to 10^4 tasks and 10^5 dependencies - need O(V + E) algorithm, not O(V\u00b2)",
      "Unlimited parallel workers - total time is critical path, not sum of durations",
      "Cycle means impossible - must detect and return [-1, []]"
    ],
    "clarifying_questions": [
      "Are task IDs guaranteed to be positive integers? - Affects HashMap key type",
      "Can a dependency reference a task not in taskList? - Need validation",
      "Is self-dependency (a \u2192 a) considered a cycle? - Yes, should detect it",
      "Should the order be lexicographically smallest when multiple valid? - No, any valid order works",
      "Can there be duplicate dependencies (same pair twice)? - Should handle gracefully",
      "What if taskList is empty? - Return [0, []]",
      "Can durations be 0? - Constraint says \u22651, so no"
    ],
    "edge_cases_to_consider": [
      "Single task with no dependencies",
      "All tasks independent (no edges) - total = max(durations)",
      "Linear chain - total = sum(durations)",
      "Self-dependency cycle (a \u2192 a)",
      "Disconnected components in the graph",
      "Diamond pattern with varying path lengths",
      "Large fan-out (one task with many dependents)"
    ]
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Return valid topological order",
        "how_met": "Use Kahn's algorithm (BFS) to process nodes when all prerequisites are complete",
        "gotchas": [
          "Order must respect ALL dependencies, not just direct ones"
        ]
      },
      {
        "requirement": "Calculate minimum total time with parallel execution",
        "how_met": "Track completion_time[task] = max(completion_time[prereqs]) + duration[task]",
        "gotchas": [
          "Don't sum durations - take max of completion times"
        ]
      },
      {
        "requirement": "Detect cycles and return [-1, []]",
        "how_met": "If len(processed) < len(tasks) after Kahn's algorithm, cycle exists",
        "gotchas": [
          "Self-loops are also cycles",
          "Cycle can be anywhere in graph"
        ]
      },
      {
        "requirement": "Handle non-consecutive task IDs",
        "how_met": "Use Dict/HashMap for all task-indexed data structures",
        "gotchas": [
          "Don't use array[task_id] - IDs can be sparse"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "Build graph",
        "target": "O(V + E)",
        "achieved": "O(V + E)",
        "why": "Single pass through tasks and dependencies"
      },
      {
        "operation": "Topological sort",
        "target": "O(V + E)",
        "achieved": "O(V + E)",
        "why": "Each node/edge processed once"
      },
      {
        "operation": "Critical path",
        "target": "O(V + E)",
        "achieved": "O(V + E)",
        "why": "Calculated during topological traversal"
      },
      {
        "operation": "Overall",
        "target": "O(V + E)",
        "achieved": "O(V + E)",
        "why": "All operations combined in single pass"
      }
    ],
    "non_goals": [
      "Returning lexicographically smallest order (any valid order is acceptable)",
      "Optimizing for limited workers (that's Part 2)",
      "Finding the actual critical path tasks (that's Part 3)",
      "Handling dynamic task additions (that's Part 4)"
    ]
  },
  "assumptions": [
    "All task IDs in dependencyList exist in taskList (no dangling references)",
    "No duplicate [taskId, duration] pairs in taskList",
    "Dependencies are directed edges (a\u2192b means a must complete before b starts)",
    "Tasks take exactly their stated duration (no variance)",
    "A task starts immediately when all prerequisites complete (no scheduling delay)"
  ],
  "tradeoffs": [
    {
      "decision": "Use Kahn's BFS vs DFS for topological sort",
      "chosen": "Kahn's BFS",
      "why": "Naturally integrates with completion time calculation - process nodes level by level. Cycle detection is trivial (count processed nodes).",
      "alternative": "DFS with post-order",
      "when_to_switch": "If you need to find ALL topological orders, DFS is more natural"
    },
    {
      "decision": "Track completion time during vs after topological sort",
      "chosen": "During (single pass)",
      "why": "More efficient - O(V+E) instead of two passes. Completion time calculated when node is added to queue.",
      "alternative": "Separate passes",
      "when_to_switch": "If you need to process the order for other purposes first"
    },
    {
      "decision": "Store reverse graph vs compute predecessors on demand",
      "chosen": "Store reverse graph",
      "why": "O(1) lookup of prerequisites vs O(E) search. Uses O(E) extra space but worth it.",
      "alternative": "Compute on demand",
      "when_to_switch": "If memory is extremely constrained"
    }
  ],
  "extensibility_and_followups": {
    "design_principles": [
      "Separate graph building from algorithm execution",
      "Store both forward and reverse edges for flexibility",
      "Use completion_time map - easily extended for more complex scheduling"
    ],
    "why_this_design_scales": "The completion_time map naturally extends to Part 2 (limited workers - use priority queue by end time), Part 3 (find critical path - track which predecessor gave max time), and Part 4 (dynamic tasks - incrementally update affected completion times).",
    "expected_followup_hooks": [
      "completion_time calculation will change for limited workers",
      "Need to track 'critical predecessor' for finding critical path",
      "Graph structure should support incremental updates"
    ],
    "invariants": [
      "A task's completion time \u2265 max(prerequisites' completion times) + its duration",
      "Processed count after Kahn's = number of tasks iff no cycle",
      "Total time = max(all completion times)"
    ]
  },
  "visual_explanation": {
    "problem_visualization": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    TASK DEPENDENCY GRAPH                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502    Input Graph:                 Parallel Timeline:              \u2502\n\u2502                                                                 \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                Time: 0   3   5   8  11        \u2502\n\u2502         \u2502 1(3) \u2502                      \u2502   \u2502   \u2502   \u2502   \u2502        \u2502\n\u2502         \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518                                                \u2502\n\u2502        \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510                Task 1: \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                \u2502\n\u2502        \u25bc       \u25bc                                                \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510            Task 2:     \u2588\u2588\u2588\u2588                \u2502\n\u2502    \u2502 2(2) \u2502 \u2502 3(5) \u2502                                            \u2502\n\u2502    \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518            Task 3:     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      \u2502\n\u2502        \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518                                                \u2502\n\u2502            \u25bc                    Task 4:              \u2588\u2588\u2588\u2588\u2588\u2588     \u2502\n\u2502        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                 \u2502\n\u2502        \u2502 4(3) \u2502                 Critical Path: 1\u21923\u21924 = 11      \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                 \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "data_structure_state": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DATA STRUCTURES                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  duration = {1: 3, 2: 2, 3: 5, 4: 3}                           \u2502\n\u2502                                                                 \u2502\n\u2502  graph (forward edges):        reverse_graph (prerequisites):   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502 1 \u2502 [2, 3]     \u2502            \u2502 2 \u2502 [1]        \u2502              \u2502\n\u2502  \u2502 2 \u2502 [4]        \u2502            \u2502 3 \u2502 [1]        \u2502              \u2502\n\u2502  \u2502 3 \u2502 [4]        \u2502            \u2502 4 \u2502 [2, 3]     \u2502              \u2502\n\u2502  \u2502 4 \u2502 []         \u2502            \u2502 1 \u2502 []         \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                                                 \u2502\n\u2502  in_degree = {1: 0, 2: 1, 3: 1, 4: 2}                          \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": [
      {
        "step": 1,
        "description": "Initialize - Find all tasks with in_degree = 0",
        "visualization": "```\nqueue: [1]  (task 1 has no prerequisites)\ncompletion_time: {1: 3}  (starts at 0, ends at 0+3=3)\norder: []\n```",
        "key_point": "Tasks with no prerequisites can start immediately at time 0"
      },
      {
        "step": 2,
        "description": "Process task 1 - Update dependents 2 and 3",
        "visualization": "```\nProcess: 1\n\u251c\u2500 Dependent 2: in_degree 1\u21920, can start!\n\u2502  \u2514\u2500 start = max(completion[1]) = 3\n\u2502  \u2514\u2500 completion[2] = 3 + 2 = 5\n\u251c\u2500 Dependent 3: in_degree 1\u21920, can start!\n\u2502  \u2514\u2500 start = max(completion[1]) = 3\n\u2502  \u2514\u2500 completion[3] = 3 + 5 = 8\n\nqueue: [2, 3]\ncompletion_time: {1: 3, 2: 5, 3: 8}\norder: [1]\n```",
        "key_point": "When in_degree becomes 0, ALL prerequisites are done"
      },
      {
        "step": 3,
        "description": "Process tasks 2 and 3 - Task 4 waits for both",
        "visualization": "```\nProcess: 2\n\u251c\u2500 Dependent 4: in_degree 2\u21921, wait...\n\nProcess: 3\n\u251c\u2500 Dependent 4: in_degree 1\u21920, can start!\n\u2502  \u2514\u2500 prereqs = [2, 3]\n\u2502  \u2514\u2500 start = max(completion[2], completion[3])\n\u2502  \u2514\u2500 start = max(5, 8) = 8\n\u2502  \u2514\u2500 completion[4] = 8 + 3 = 11\n\nqueue: [4]\ncompletion_time: {1: 3, 2: 5, 3: 8, 4: 11}\norder: [1, 2, 3]\n```",
        "key_point": "Task 4 must wait for the SLOWER path (3, not 2)"
      },
      {
        "step": 4,
        "description": "Process task 4 - Complete!",
        "visualization": "```\nProcess: 4 (no dependents)\n\nqueue: []\ncompletion_time: {1: 3, 2: 5, 3: 8, 4: 11}\norder: [1, 2, 3, 4]\n\nlen(order) == 4 == len(tasks) \u2192 No cycle!\ntotal_time = max(3, 5, 8, 11) = 11\n```",
        "key_point": "Final answer: (11, [1, 2, 3, 4])"
      }
    ],
    "dry_run_table": "| Step | Queue | Processing | In-degrees | Completion Times | Order |\n|------|-------|------------|------------|------------------|-------|\n| Init | [1] | - | {1:0, 2:1, 3:1, 4:2} | {1:3} | [] |\n| 1 | [2,3] | 1 | {1:0, 2:0, 3:0, 4:2} | {1:3, 2:5, 3:8} | [1] |\n| 2 | [3] | 2 | {1:0, 2:0, 3:0, 4:1} | {1:3, 2:5, 3:8} | [1,2] |\n| 3 | [4] | 3 | {1:0, 2:0, 3:0, 4:0} | {1:3, 2:5, 3:8, 4:11} | [1,2,3] |\n| 4 | [] | 4 | {1:0, 2:0, 3:0, 4:0} | {1:3, 2:5, 3:8, 4:11} | [1,2,3,4] |"
  },
  "thinking_process": {
    "step_by_step": [
      "When I see 'tasks with dependencies' and 'valid execution order', I immediately think **topological sort** - this is the classic formulation.",
      "When I see 'unlimited parallel workers', I realize total time is NOT the sum of durations. It's the **critical path** - the longest chain of dependent tasks.",
      "The key insight is that these two requirements (order + time) can be computed in a **single traversal** using Kahn's algorithm.",
      "For critical path: `completion_time[task] = max(completion_time[all prerequisites]) + duration[task]`",
      "For cycle detection: If Kahn's algorithm doesn't process all nodes, there's a cycle (some nodes have in_degree > 0 that never becomes 0).",
      "Task IDs are non-consecutive, so I must use **HashMap** for all task-indexed structures, not arrays.",
      "I need both forward edges (task \u2192 dependents) and reverse edges (task \u2192 prerequisites) for efficient processing."
    ],
    "key_insight": "**Process nodes in topological order while tracking completion times.** When a node is ready to process (in_degree = 0), ALL its prerequisites have known completion times, so we can compute its start time as the MAX of those times. This elegantly solves both problems in O(V+E).",
    "why_this_works": "Topological order guarantees that when we process a task, all its prerequisites have already been processed. Therefore, their completion times are already calculated. The max of those times gives us the earliest possible start time for the current task. The cycle detection falls out naturally - if we can't process all nodes, the remaining nodes form a cycle."
  },
  "approaches": [
    {
      "name": "Brute Force - DFS for each task",
      "description": "For each task, use DFS to find the longest path ending at that task",
      "pseudocode": "for each task:\n  longest_path[task] = duration[task] + max(DFS(prereq) for prereq in prerequisites)\ntotal = max(longest_path.values())",
      "time_complexity": "O(V * (V + E)) - DFS for each task",
      "space_complexity": "O(V + E) for graph + recursion stack",
      "pros": [
        "Simple to understand",
        "Naturally handles the critical path concept"
      ],
      "cons": [
        "Redundant computation - same subpaths computed multiple times",
        "Cycle detection requires separate pass"
      ],
      "when_to_use": "Only for very small graphs or as a correctness check"
    },
    {
      "name": "DFS with Memoization",
      "description": "Use memoization to cache longest path from each task",
      "pseudocode": "def dfs(task):\n  if task in memo: return memo[task]\n  max_prereq = max(dfs(p) for p in prereqs[task]) or 0\n  memo[task] = max_prereq + duration[task]\n  return memo[task]",
      "time_complexity": "O(V + E) - each node/edge visited once",
      "space_complexity": "O(V) for memo + O(V) for recursion stack",
      "pros": [
        "Correct complexity",
        "Intuitive recursive structure"
      ],
      "cons": [
        "Risk of stack overflow for deep graphs",
        "Cycle detection needs colored states (white/gray/black)"
      ],
      "when_to_use": "Good for understanding, but BFS is safer in interviews"
    },
    {
      "name": "Optimal: Kahn's Algorithm (BFS) with Completion Times",
      "description": "Use BFS-based topological sort, tracking completion times as we go",
      "pseudocode": "queue = [tasks with in_degree 0]\nwhile queue:\n  task = queue.pop()\n  order.append(task)\n  for dependent in graph[task]:\n    in_degree[dependent] -= 1\n    if in_degree[dependent] == 0:\n      start = max(completion_time[p] for p in prereqs[dependent])\n      completion_time[dependent] = start + duration[dependent]\n      queue.append(dependent)\nreturn max(completion_time.values()), order",
      "time_complexity": "O(V + E) - each node/edge processed once",
      "space_complexity": "O(V + E) for graph storage",
      "pros": [
        "No recursion - no stack overflow risk",
        "Clean cycle detection",
        "Single pass for both order and time"
      ],
      "cons": [
        "Need to store both forward and reverse edges"
      ],
      "key_insight": "When in_degree becomes 0, ALL prerequisites have been processed, so their completion times are available"
    }
  ],
  "optimal_solution": {
    "name": "Kahn's Algorithm with Critical Path Calculation",
    "explanation_md": "## Approach: BFS Topological Sort + Dynamic Programming\n\n### Core Algorithm\n\n1. **Build the Graph**\n   - Create adjacency list `graph[task]` \u2192 list of dependent tasks\n   - Create reverse adjacency list `prereqs[task]` \u2192 list of prerequisites\n   - Track `in_degree[task]` for Kahn's algorithm\n   - Store `duration[task]` for completion time calculation\n\n2. **Initialize**\n   - Add all tasks with `in_degree = 0` to queue\n   - Their completion time = duration (start at time 0)\n\n3. **Process Queue (Kahn's Algorithm)**\n   - Pop task from queue, add to order\n   - For each dependent task:\n     - Decrement its in_degree\n     - If in_degree becomes 0:\n       - Calculate start_time = max(completion_time[prereqs])\n       - Set completion_time = start_time + duration\n       - Add to queue\n\n4. **Cycle Detection**\n   - If `len(order) < num_tasks`, there's a cycle\n\n5. **Result**\n   - Total time = max(all completion times)\n   - Return (total_time, order)\n\n### Why This Works\n\nThe key insight is that **in_degree = 0** means **all prerequisites are done**. At that moment:\n- All prerequisite completion times are known\n- We can compute the earliest start time (max of prereq end times)\n- We can compute this task's completion time\n\nThis is essentially **dynamic programming on a DAG** processed in topological order.",
    "data_structures": [
      {
        "structure": "Dict[int, List[int]] graph",
        "purpose": "Forward edges: task \u2192 dependent tasks for processing dependents"
      },
      {
        "structure": "Dict[int, List[int]] prereqs",
        "purpose": "Reverse edges: task \u2192 prerequisites for computing start time"
      },
      {
        "structure": "Dict[int, int] duration",
        "purpose": "Task durations for completion time calculation"
      },
      {
        "structure": "Dict[int, int] in_degree",
        "purpose": "Track remaining prerequisites for Kahn's algorithm"
      },
      {
        "structure": "Dict[int, int] completion_time",
        "purpose": "Earliest completion time for each task"
      },
      {
        "structure": "Deque queue",
        "purpose": "BFS queue for Kahn's algorithm"
      }
    ],
    "algorithm_steps": [
      "1. Parse taskList to populate duration map and initialize in_degree to 0",
      "2. Parse dependencyList to build graph, prereqs, and increment in_degrees",
      "3. Find all tasks with in_degree = 0, add to queue with completion_time = duration",
      "4. While queue not empty: pop task, add to order, process dependents",
      "5. For each dependent: decrement in_degree, if 0 compute completion_time and enqueue",
      "6. After loop: if order length != task count, return [-1, []] (cycle)",
      "7. Return (max(completion_times), order)"
    ],
    "why_decimal": "Not applicable for this problem - durations are integers"
  },
  "solution_python_lines": [
    "\"\"\"",
    "Task Scheduling with Dependencies",
    "",
    "Problem: Given tasks with durations and dependencies, find:",
    "1. A valid execution order (topological sort)",
    "2. Minimum total time with unlimited parallel workers (critical path)",
    "",
    "Algorithm: Kahn's Algorithm (BFS Topological Sort) + Critical Path Calculation",
    "Time Complexity: O(V + E) where V = tasks, E = dependencies",
    "Space Complexity: O(V + E) for graph storage",
    "\"\"\"",
    "",
    "from collections import defaultdict, deque",
    "from typing import List, Tuple, Dict",
    "",
    "",
    "class TaskScheduler:",
    "    \"\"\"",
    "    A task scheduler that handles dependencies and calculates optimal execution.",
    "    ",
    "    This class uses Kahn's algorithm for topological sorting combined with",
    "    critical path analysis to determine the minimum execution time when",
    "    unlimited parallel workers are available.",
    "    ",
    "    Example:",
    "        >>> scheduler = TaskScheduler()",
    "        >>> tasks = [[1, 3], [2, 2], [3, 5], [4, 3]]",
    "        >>> deps = [[1, 2], [1, 3], [2, 4], [3, 4]]",
    "        >>> time, order = scheduler.schedule_tasks(tasks, deps)",
    "        >>> print(f'Total time: {time}, Order: {order}')",
    "        Total time: 11, Order: [1, 2, 3, 4]",
    "    \"\"\"",
    "    ",
    "    def __init__(self) -> None:",
    "        \"\"\"Initialize empty data structures for graph representation.\"\"\"",
    "        self._graph: Dict[int, List[int]] = defaultdict(list)",
    "        self._prereqs: Dict[int, List[int]] = defaultdict(list)",
    "        self._duration: Dict[int, int] = {}",
    "        self._in_degree: Dict[int, int] = defaultdict(int)",
    "    ",
    "    def _reset(self) -> None:",
    "        \"\"\"Reset all internal state for a new scheduling problem.\"\"\"",
    "        self._graph = defaultdict(list)",
    "        self._prereqs = defaultdict(list)",
    "        self._duration = {}",
    "        self._in_degree = defaultdict(int)",
    "    ",
    "    def _build_graph(",
    "        self,",
    "        task_list: List[List[int]],",
    "        dependency_list: List[List[int]]",
    "    ) -> bool:",
    "        \"\"\"",
    "        Build the dependency graph from input lists.",
    "        ",
    "        Args:",
    "            task_list: List of [task_id, duration] pairs",
    "            dependency_list: List of [prereq, dependent] pairs",
    "            ",
    "        Returns:",
    "            True if graph is valid, False if invalid references found",
    "        \"\"\"",
    "        # Initialize all tasks with in_degree 0",
    "        for task_id, duration in task_list:",
    "            self._duration[task_id] = duration",
    "            self._in_degree[task_id] = 0",
    "        ",
    "        # Build adjacency lists and track in-degrees",
    "        for prereq, dependent in dependency_list:",
    "            # Validate task references",
    "            if prereq not in self._duration or dependent not in self._duration:",
    "                return False",
    "            ",
    "            # Skip self-loops (they would cause cycles anyway)",
    "            if prereq == dependent:",
    "                continue",
    "            ",
    "            self._graph[prereq].append(dependent)",
    "            self._prereqs[dependent].append(prereq)",
    "            self._in_degree[dependent] += 1",
    "        ",
    "        return True",
    "    ",
    "    def _topological_sort_with_critical_path(self) -> Tuple[int, List[int]]:",
    "        \"\"\"",
    "        Perform topological sort while calculating critical path.",
    "        ",
    "        Uses Kahn's algorithm (BFS-based) to process tasks in dependency order.",
    "        Simultaneously tracks completion times for critical path calculation.",
    "        ",
    "        Returns:",
    "            Tuple of (total_time, execution_order)",
    "            Returns (-1, []) if a cycle is detected",
    "        \"\"\"",
    "        queue: deque = deque()",
    "        completion_time: Dict[int, int] = {}",
    "        order: List[int] = []",
    "        ",
    "        # Initialize: Add all tasks with no prerequisites",
    "        # These tasks start at time 0, so completion = duration",
    "        for task_id in self._duration:",
    "            if self._in_degree[task_id] == 0:",
    "                queue.append(task_id)",
    "                completion_time[task_id] = self._duration[task_id]",
    "        ",
    "        # Process tasks in BFS order (Kahn's algorithm)",
    "        while queue:",
    "            current_task = queue.popleft()",
    "            order.append(current_task)",
    "            ",
    "            # Process all dependent tasks",
    "            for dependent in self._graph[current_task]:",
    "                self._in_degree[dependent] -= 1",
    "                ",
    "                # When all prerequisites are done, we can schedule this task",
    "                if self._in_degree[dependent] == 0:",
    "                    # Calculate earliest start time",
    "                    # = max completion time of all prerequisites",
    "                    prereq_list = self._prereqs[dependent]",
    "                    start_time = max(",
    "                        completion_time[prereq]",
    "                        for prereq in prereq_list",
    "                    )",
    "                    ",
    "                    # Calculate completion time",
    "                    completion_time[dependent] = (",
    "                        start_time + self._duration[dependent]",
    "                    )",
    "                    queue.append(dependent)",
    "        ",
    "        # Cycle detection: If not all tasks processed, cycle exists",
    "        if len(order) != len(self._duration):",
    "            return (-1, [])",
    "        ",
    "        # Calculate total time (max of all completion times)",
    "        total_time = max(completion_time.values()) if completion_time else 0",
    "        ",
    "        return (total_time, order)",
    "    ",
    "    def schedule_tasks(",
    "        self,",
    "        task_list: List[List[int]],",
    "        dependency_list: List[List[int]]",
    "    ) -> Tuple[int, List[int]]:",
    "        \"\"\"",
    "        Schedule tasks respecting dependencies and calculate minimum time.",
    "        ",
    "        Given a list of tasks with their durations and a list of dependencies,",
    "        this method determines a valid execution order and the minimum total",
    "        time to complete all tasks assuming unlimited parallel workers.",
    "        ",
    "        Args:",
    "            task_list: List of [task_id, duration] pairs.",
    "                       Task IDs are unique integers, durations are positive.",
    "            dependency_list: List of [prereq_id, dependent_id] pairs.",
    "                            prereq must complete before dependent can start.",
    "        ",
    "        Returns:",
    "            Tuple of (total_time, execution_order) where:",
    "            - total_time: Minimum time to complete all tasks with parallel execution",
    "            - execution_order: A valid topological order of task IDs",
    "            Returns (-1, []) if dependencies contain a cycle.",
    "        ",
    "        Examples:",
    "            >>> scheduler = TaskScheduler()",
    "            >>> # Diamond pattern: 1 -> 2,3 -> 4",
    "            >>> scheduler.schedule_tasks(",
    "            ...     [[1,3], [2,2], [3,5], [4,3]],",
    "            ...     [[1,2], [1,3], [2,4], [3,4]]",
    "            ... )",
    "            (11, [1, 2, 3, 4])",
    "            ",
    "            >>> # Independent tasks (all parallel)",
    "            >>> scheduler.schedule_tasks([[1,5], [2,3], [3,4]], [])",
    "            (5, [1, 2, 3])",
    "            ",
    "            >>> # Cycle detection",
    "            >>> scheduler.schedule_tasks(",
    "            ...     [[1,2], [2,3], [3,1]],",
    "            ...     [[1,2], [2,3], [3,1]]",
    "            ... )",
    "            (-1, [])",
    "        \"\"\"",
    "        # Handle edge case: empty task list",
    "        if not task_list:",
    "            return (0, [])",
    "        ",
    "        # Reset state for new problem",
    "        self._reset()",
    "        ",
    "        # Build the dependency graph",
    "        if not self._build_graph(task_list, dependency_list):",
    "            # Invalid task reference in dependencies",
    "            return (-1, [])",
    "        ",
    "        # Run topological sort with critical path calculation",
    "        return self._topological_sort_with_critical_path()",
    "",
    "",
    "# ============================================================================",
    "# Standalone function version (for direct use without class instantiation)",
    "# ============================================================================",
    "",
    "def schedule_tasks(",
    "    task_list: List[List[int]],",
    "    dependency_list: List[List[int]]",
    ") -> Tuple[int, List[int]]:",
    "    \"\"\"",
    "    Standalone function to schedule tasks with dependencies.",
    "    ",
    "    See TaskScheduler.schedule_tasks for full documentation.",
    "    \"\"\"",
    "    scheduler = TaskScheduler()",
    "    return scheduler.schedule_tasks(task_list, dependency_list)",
    "",
    "",
    "# ============================================================================",
    "# Demo and Test Cases",
    "# ============================================================================",
    "",
    "def run_test_case(",
    "    name: str,",
    "    task_list: List[List[int]],",
    "    dependency_list: List[List[int]],",
    "    expected_time: int,",
    "    check_order: bool = True",
    ") -> bool:",
    "    \"\"\"Run a single test case and verify results.\"\"\"",
    "    scheduler = TaskScheduler()",
    "    result_time, result_order = scheduler.schedule_tasks(task_list, dependency_list)",
    "    ",
    "    passed = result_time == expected_time",
    "    ",
    "    # For cycle cases, order should be empty",
    "    if expected_time == -1:",
    "        passed = passed and result_order == []",
    "    elif check_order:",
    "        # Verify the order is valid (respects all dependencies)",
    "        position = {task_id: i for i, task_id in enumerate(result_order)}",
    "        for prereq, dependent in dependency_list:",
    "            if position.get(prereq, -1) >= position.get(dependent, float('inf')):",
    "                passed = False",
    "                break",
    "    ",
    "    status = '\u2713 PASS' if passed else '\u2717 FAIL'",
    "    print(f'{status}: {name}')",
    "    print(f'       Time: {result_time} (expected {expected_time})')",
    "    print(f'       Order: {result_order}')",
    "    print()",
    "    ",
    "    return passed",
    "",
    "",
    "if __name__ == '__main__':",
    "    print('=' * 60)",
    "    print('Task Scheduling with Dependencies - Test Suite')",
    "    print('=' * 60)",
    "    print()",
    "    ",
    "    all_passed = True",
    "    ",
    "    # Test 1: Basic Diamond Pattern",
    "    all_passed &= run_test_case(",
    "        'Basic Diamond Pattern',",
    "        task_list=[[1, 3], [2, 2], [3, 5], [4, 3]],",
    "        dependency_list=[[1, 2], [1, 3], [2, 4], [3, 4]],",
    "        expected_time=11",
    "    )",
    "    ",
    "    # Test 2: Independent Tasks (all parallel)",
    "    all_passed &= run_test_case(",
    "        'Independent Tasks (parallel)',",
    "        task_list=[[1, 5], [2, 3], [3, 4]],",
    "        dependency_list=[],",
    "        expected_time=5",
    "    )",
    "    ",
    "    # Test 3: Linear Chain",
    "    all_passed &= run_test_case(",
    "        'Linear Chain',",
    "        task_list=[[1, 2], [2, 3], [3, 1]],",
    "        dependency_list=[[1, 2], [2, 3]],",
    "        expected_time=6",
    "    )",
    "    ",
    "    # Test 4: Cycle Detection",
    "    all_passed &= run_test_case(",
    "        'Cycle Detection',",
    "        task_list=[[1, 2], [2, 3], [3, 1]],",
    "        dependency_list=[[1, 2], [2, 3], [3, 1]],",
    "        expected_time=-1",
    "    )",
    "    ",
    "    # Test 5: Single Task",
    "    all_passed &= run_test_case(",
    "        'Single Task',",
    "        task_list=[[1, 5]],",
    "        dependency_list=[],",
    "        expected_time=5",
    "    )",
    "    ",
    "    # Test 6: Two Independent Tasks",
    "    all_passed &= run_test_case(",
    "        'Two Independent Tasks',",
    "        task_list=[[1, 3], [2, 4]],",
    "        dependency_list=[],",
    "        expected_time=4",
    "    )",
    "    ",
    "    # Test 7: Multiple Roots",
    "    all_passed &= run_test_case(",
    "        'Multiple Roots',",
    "        task_list=[[1, 2], [2, 3], [3, 1], [4, 4]],",
    "        dependency_list=[[1, 3], [2, 3]],",
    "        expected_time=4  # max(2+1, 3+1, 4) = 4",
    "    )",
    "    ",
    "    # Test 8: Non-consecutive Task IDs",
    "    all_passed &= run_test_case(",
    "        'Non-consecutive IDs',",
    "        task_list=[[1, 2], [5, 3], [100, 4]],",
    "        dependency_list=[[1, 5], [5, 100]],",
    "        expected_time=9  # 2+3+4 = 9 (linear chain)",
    "    )",
    "    ",
    "    # Test 9: Empty Task List",
    "    all_passed &= run_test_case(",
    "        'Empty Task List',",
    "        task_list=[],",
    "        dependency_list=[],",
    "        expected_time=0",
    "    )",
    "    ",
    "    # Test 10: Complex DAG",
    "    # 1 -> 2 -> 4 -> 6",
    "    # 1 -> 3 -> 4",
    "    # 1 -> 3 -> 5 -> 6 (critical path)",
    "    all_passed &= run_test_case(",
    "        'Complex DAG with Multiple Paths',",
    "        task_list=[[1, 1], [2, 2], [3, 3], [4, 3], [5, 5], [6, 4]],",
    "        dependency_list=[[1, 2], [1, 3], [2, 4], [3, 4], [3, 5], [4, 6], [5, 6]],",
    "        expected_time=13  # 1 -> 3 -> 5 -> 6 = 1+3+5+4 = 13",
    "    )",
    "    ",
    "    print('=' * 60)",
    "    if all_passed:",
    "        print('All tests passed! \u2713')",
    "    else:",
    "        print('Some tests failed! \u2717')",
    "    print('=' * 60)"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "",
    "/**",
    " * Task Scheduling with Dependencies",
    " * ",
    " * Problem: Given tasks with durations and dependencies, find:",
    " * 1. A valid execution order (topological sort)",
    " * 2. Minimum total time with unlimited parallel workers (critical path)",
    " * ",
    " * Algorithm: Kahn's Algorithm (BFS Topological Sort) + Critical Path",
    " * Time Complexity: O(V + E) where V = tasks, E = dependencies",
    " * Space Complexity: O(V + E) for graph storage",
    " */",
    "public class TaskScheduler {",
    "    ",
    "    private Map<Integer, List<Integer>> graph;      // task -> dependents",
    "    private Map<Integer, List<Integer>> prereqs;    // task -> prerequisites",
    "    private Map<Integer, Integer> duration;         // task -> duration",
    "    private Map<Integer, Integer> inDegree;         // task -> remaining prereqs",
    "    ",
    "    public TaskScheduler() {",
    "        reset();",
    "    }",
    "    ",
    "    private void reset() {",
    "        graph = new HashMap<>();",
    "        prereqs = new HashMap<>();",
    "        duration = new HashMap<>();",
    "        inDegree = new HashMap<>();",
    "    }",
    "    ",
    "    /**",
    "     * Build the dependency graph from input arrays.",
    "     * ",
    "     * @param taskList Array of [task_id, duration] pairs",
    "     * @param dependencyList Array of [prereq_id, dependent_id] pairs",
    "     * @return true if graph is valid, false otherwise",
    "     */",
    "    private boolean buildGraph(int[][] taskList, int[][] dependencyList) {",
    "        // Initialize all tasks",
    "        for (int[] task : taskList) {",
    "            int taskId = task[0];",
    "            int dur = task[1];",
    "            duration.put(taskId, dur);",
    "            inDegree.put(taskId, 0);",
    "            graph.put(taskId, new ArrayList<>());",
    "            prereqs.put(taskId, new ArrayList<>());",
    "        }",
    "        ",
    "        // Build edges",
    "        for (int[] dep : dependencyList) {",
    "            int prereq = dep[0];",
    "            int dependent = dep[1];",
    "            ",
    "            // Validate task references",
    "            if (!duration.containsKey(prereq) || !duration.containsKey(dependent)) {",
    "                return false;",
    "            }",
    "            ",
    "            // Skip self-loops",
    "            if (prereq == dependent) {",
    "                continue;",
    "            }",
    "            ",
    "            graph.get(prereq).add(dependent);",
    "            prereqs.get(dependent).add(prereq);",
    "            inDegree.put(dependent, inDegree.get(dependent) + 1);",
    "        }",
    "        ",
    "        return true;",
    "    }",
    "    ",
    "    /**",
    "     * Perform topological sort with critical path calculation.",
    "     * Uses Kahn's algorithm (BFS-based).",
    "     * ",
    "     * @return [totalTime, order...] or [-1] if cycle detected",
    "     */",
    "    private int[] topologicalSortWithCriticalPath() {",
    "        Queue<Integer> queue = new LinkedList<>();",
    "        Map<Integer, Integer> completionTime = new HashMap<>();",
    "        List<Integer> order = new ArrayList<>();",
    "        ",
    "        // Initialize: add tasks with no prerequisites",
    "        for (int taskId : duration.keySet()) {",
    "            if (inDegree.get(taskId) == 0) {",
    "                queue.offer(taskId);",
    "                completionTime.put(taskId, duration.get(taskId));",
    "            }",
    "        }",
    "        ",
    "        // Process in BFS order (Kahn's algorithm)",
    "        while (!queue.isEmpty()) {",
    "            int currentTask = queue.poll();",
    "            order.add(currentTask);",
    "            ",
    "            for (int dependent : graph.get(currentTask)) {",
    "                int newDegree = inDegree.get(dependent) - 1;",
    "                inDegree.put(dependent, newDegree);",
    "                ",
    "                if (newDegree == 0) {",
    "                    // Calculate start time = max of prereq completion times",
    "                    int startTime = 0;",
    "                    for (int p : prereqs.get(dependent)) {",
    "                        startTime = Math.max(startTime, completionTime.get(p));",
    "                    }",
    "                    completionTime.put(dependent, startTime + duration.get(dependent));",
    "                    queue.offer(dependent);",
    "                }",
    "            }",
    "        }",
    "        ",
    "        // Cycle detection",
    "        if (order.size() != duration.size()) {",
    "            return new int[]{-1};",
    "        }",
    "        ",
    "        // Calculate total time",
    "        int totalTime = 0;",
    "        for (int time : completionTime.values()) {",
    "            totalTime = Math.max(totalTime, time);",
    "        }",
    "        ",
    "        // Build result array: [totalTime, order...]",
    "        int[] result = new int[order.size() + 1];",
    "        result[0] = totalTime;",
    "        for (int i = 0; i < order.size(); i++) {",
    "            result[i + 1] = order.get(i);",
    "        }",
    "        ",
    "        return result;",
    "    }",
    "    ",
    "    /**",
    "     * Schedule tasks respecting dependencies and calculate minimum time.",
    "     * ",
    "     * @param taskList Array of [task_id, duration] pairs",
    "     * @param dependencyList Array of [prereq_id, dependent_id] pairs",
    "     * @return int[0] = total time (-1 if cycle), int[1..n] = execution order",
    "     */",
    "    public int[] scheduleTasks(int[][] taskList, int[][] dependencyList) {",
    "        // Handle empty input",
    "        if (taskList == null || taskList.length == 0) {",
    "            return new int[]{0};",
    "        }",
    "        ",
    "        // Reset state",
    "        reset();",
    "        ",
    "        // Build graph",
    "        if (!buildGraph(taskList, dependencyList)) {",
    "            return new int[]{-1};",
    "        }",
    "        ",
    "        return topologicalSortWithCriticalPath();",
    "    }",
    "    ",
    "    // ==========================================================================",
    "    // Demo and Tests",
    "    // ==========================================================================",
    "    ",
    "    public static void main(String[] args) {",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println(\"Task Scheduling with Dependencies - Java Test Suite\");",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println();",
    "        ",
    "        TaskScheduler scheduler = new TaskScheduler();",
    "        ",
    "        // Test 1: Diamond Pattern",
    "        runTest(scheduler, \"Diamond Pattern\",",
    "            new int[][]{{1,3}, {2,2}, {3,5}, {4,3}},",
    "            new int[][]{{1,2}, {1,3}, {2,4}, {3,4}},",
    "            11);",
    "        ",
    "        // Test 2: Independent Tasks",
    "        runTest(scheduler, \"Independent Tasks\",",
    "            new int[][]{{1,5}, {2,3}, {3,4}},",
    "            new int[][]{},",
    "            5);",
    "        ",
    "        // Test 3: Linear Chain",
    "        runTest(scheduler, \"Linear Chain\",",
    "            new int[][]{{1,2}, {2,3}, {3,1}},",
    "            new int[][]{{1,2}, {2,3}},",
    "            6);",
    "        ",
    "        // Test 4: Cycle Detection",
    "        runTest(scheduler, \"Cycle Detection\",",
    "            new int[][]{{1,2}, {2,3}, {3,1}},",
    "            new int[][]{{1,2}, {2,3}, {3,1}},",
    "            -1);",
    "        ",
    "        // Test 5: Single Task",
    "        runTest(scheduler, \"Single Task\",",
    "            new int[][]{{1,5}},",
    "            new int[][]{},",
    "            5);",
    "        ",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println(\"All tests complete!\");",
    "        System.out.println(\"=\".repeat(60));",
    "    }",
    "    ",
    "    private static void runTest(TaskScheduler scheduler, String name,",
    "                                int[][] tasks, int[][] deps, int expected) {",
    "        int[] result = scheduler.scheduleTasks(tasks, deps);",
    "        boolean passed = result[0] == expected;",
    "        ",
    "        String status = passed ? \"\u2713 PASS\" : \"\u2717 FAIL\";",
    "        System.out.printf(\"%s: %s%n\", status, name);",
    "        System.out.printf(\"       Time: %d (expected %d)%n\", result[0], expected);",
    "        System.out.print(\"       Order: [\");",
    "        for (int i = 1; i < result.length; i++) {",
    "            System.out.print(result[i] + (i < result.length-1 ? \", \" : \"\"));",
    "        }",
    "        System.out.println(\"]\");",
    "        System.out.println();",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-15",
      "section": "Module Docstring & Imports",
      "explanation": "We import `defaultdict` for easy graph construction (auto-creates empty lists), `deque` for O(1) BFS queue operations, and typing hints for clarity. The docstring explains the problem and algorithm."
    },
    {
      "lines": "18-36",
      "section": "Class Definition & __init__",
      "explanation": "The `TaskScheduler` class encapsulates all state. We use four HashMaps: `_graph` for forward edges (task\u2192dependents), `_prereqs` for reverse edges (task\u2192prerequisites), `_duration` for task durations, and `_in_degree` for Kahn's algorithm. Using `defaultdict(list)` means we don't need to check if keys exist before appending."
    },
    {
      "lines": "38-43",
      "section": "_reset method",
      "explanation": "Clears all state between calls. Important because the same scheduler instance might be reused for multiple problems. This ensures no data leakage between test cases."
    },
    {
      "lines": "45-78",
      "section": "_build_graph method",
      "explanation": "Parses input and builds the graph. First, we iterate through `task_list` to populate `duration` and initialize `in_degree` to 0. Then we process `dependency_list`: for each (prereq, dependent) pair, we add forward edge, reverse edge, and increment in_degree. We validate that referenced tasks exist and skip self-loops."
    },
    {
      "lines": "80-132",
      "section": "_topological_sort_with_critical_path method",
      "explanation": "**The core algorithm.** We initialize the queue with all tasks having `in_degree=0` (no prerequisites). These start at time 0, so `completion_time = duration`. In the main loop, we pop a task, add to order, then process each dependent: decrement its in_degree, and if it becomes 0, calculate its completion time (max of prerequisite completion times + its duration) and add to queue. After the loop, if `len(order) != len(tasks)`, there's a cycle. Otherwise, return max completion time."
    },
    {
      "lines": "134-185",
      "section": "schedule_tasks - Main Entry Point",
      "explanation": "The public API. Handles edge case (empty task list), resets state, builds graph, and delegates to the core algorithm. The docstring includes usage examples with expected outputs."
    },
    {
      "lines": "190-230",
      "section": "Standalone Function",
      "explanation": "A convenience wrapper that creates a TaskScheduler instance and calls its method. Useful for LeetCode-style function signatures where you don't instantiate a class."
    },
    {
      "lines": "235-300",
      "section": "Test Harness",
      "explanation": "The `run_test_case` function validates both the total time AND that the returned order respects all dependencies (by checking position of prereq < position of dependent for all edges). The main block runs comprehensive test cases covering diamond patterns, independent tasks, linear chains, cycles, and edge cases."
    }
  ],
  "debugging_strategy": {
    "how_to_test_incrementally": "1. First verify graph construction: print `graph`, `prereqs`, `in_degree` after `_build_graph`. 2. Print queue contents and `completion_time` at each iteration. 3. Verify final `len(order)` vs expected. 4. Test cycle case separately to ensure it returns -1.",
    "what_to_print_or_assert": [
      "print(f'Graph: {dict(self._graph)}')",
      "print(f'In-degrees: {dict(self._in_degree)}')",
      "print(f'Processing task {current_task}, completion_time so far: {completion_time}')",
      "assert len(order) == len(self._duration), f'Cycle detected! Processed {len(order)}/{len(self._duration)}'"
    ],
    "common_failure_modes": [
      "Using array index instead of HashMap key for non-consecutive IDs",
      "Forgetting to initialize in_degree for all tasks (not just those in dependencies)",
      "Computing start_time BEFORE decrementing in_degree (wrong timing)",
      "Not handling empty task list",
      "Computing sum of durations instead of max (sequential vs parallel)"
    ],
    "how_to_fix_fast": "If wrong answer: 1) Trace through smallest failing case by hand. 2) Check if in_degree correctly reaches 0. 3) Verify completion_time calculation uses MAX not SUM. 4) Check cycle detection (count processed nodes). If off-by-one: check initialization of queue with in_degree=0 tasks."
  },
  "complexity_analysis": {
    "time": {
      "build_graph": {
        "complexity": "O(V + E)",
        "explanation": "Single pass through tasks (V) and dependencies (E)"
      },
      "topological_sort": {
        "complexity": "O(V + E)",
        "explanation": "Each task added/removed from queue once (V ops). Each edge processed once when decrementing in_degree (E ops)"
      },
      "critical_path": {
        "complexity": "O(V + E)",
        "explanation": "For each task, we iterate through prerequisites to find max. Total prereq visits = E"
      },
      "overall": "O(V + E) where V = number of tasks, E = number of dependencies"
    },
    "space": {
      "complexity": "O(V + E)",
      "breakdown": "- `graph` and `prereqs`: O(V + E) for adjacency lists\n- `duration`, `in_degree`, `completion_time`: O(V) each\n- `queue`, `order`: O(V) at most\n- Total: O(V + E)",
      "note": "We store both forward and reverse edges, which doubles edge storage but enables O(1) prerequisite lookup"
    },
    "can_we_do_better": "No - we must read all V tasks and E dependencies at least once, so O(V + E) is optimal. The only potential optimization is space: we could compute prerequisites on-demand by iterating through all edges, trading O(E) space for O(E) time per node."
  },
  "dry_run": {
    "example": "taskList = [[1,3], [2,2], [3,5], [4,3]], dependencyList = [[1,2], [1,3], [2,4], [3,4]]",
    "trace_table": "| Step | Action | Queue | In-degrees | Completion Times | Order |\n|------|--------|-------|------------|------------------|-------|\n| Init | Build graph | - | {1:0, 2:1, 3:1, 4:2} | {} | [] |\n| 1 | Add in_degree=0 tasks | [1] | {1:0, 2:1, 3:1, 4:2} | {1:3} | [] |\n| 2 | Pop 1, process deps | [2,3] | {1:0, 2:0, 3:0, 4:2} | {1:3, 2:5, 3:8} | [1] |\n| 3 | Pop 2, process 4 | [3] | {1:0, 2:0, 3:0, 4:1} | {1:3, 2:5, 3:8} | [1,2] |\n| 4 | Pop 3, process 4 | [4] | {1:0, 2:0, 3:0, 4:0} | {1:3, 2:5, 3:8, 4:11} | [1,2,3] |\n| 5 | Pop 4, no deps | [] | unchanged | unchanged | [1,2,3,4] |\n| Final | max(3,5,8,11)=11 | - | - | - | [1,2,3,4] |",
    "final_answer": "(11, [1, 2, 3, 4])"
  },
  "test_cases": [
    {
      "name": "Diamond Pattern",
      "category": "Happy Path",
      "input": "tasks=[[1,3],[2,2],[3,5],[4,3]], deps=[[1,2],[1,3],[2,4],[3,4]]",
      "expected": "(11, [1,2,3,4] or [1,3,2,4])",
      "explanation": "Critical path: 1\u21923\u21924 = 3+5+3 = 11. Path 1\u21922\u21924 = 3+2+3 = 8 is shorter."
    },
    {
      "name": "Independent Tasks (all parallel)",
      "category": "Edge Case",
      "input": "tasks=[[1,5],[2,3],[3,4]], deps=[]",
      "expected": "(5, any permutation)",
      "explanation": "No dependencies means all parallel. Total = max(5,3,4) = 5."
    },
    {
      "name": "Linear Chain",
      "category": "Edge Case",
      "input": "tasks=[[1,2],[2,3],[3,1]], deps=[[1,2],[2,3]]",
      "expected": "(6, [1,2,3])",
      "explanation": "Sequential execution: 2+3+1 = 6. Only one valid order."
    },
    {
      "name": "Cycle Detection",
      "category": "Edge Case",
      "input": "tasks=[[1,2],[2,3],[3,1]], deps=[[1,2],[2,3],[3,1]]",
      "expected": "(-1, [])",
      "explanation": "1\u21922\u21923\u21921 forms a cycle. No valid topological order exists."
    },
    {
      "name": "Single Task",
      "category": "Boundary",
      "input": "tasks=[[1,5]], deps=[]",
      "expected": "(5, [1])",
      "explanation": "Simplest case: one task, duration is the answer."
    },
    {
      "name": "Non-consecutive IDs",
      "category": "Gotcha",
      "input": "tasks=[[1,2],[5,3],[100,4]], deps=[[1,5],[5,100]]",
      "expected": "(9, [1,5,100])",
      "explanation": "IDs 1, 5, 100 are sparse. Must use HashMap, not array."
    },
    {
      "name": "Self-loop (cycle)",
      "category": "Edge Case",
      "input": "tasks=[[1,2]], deps=[[1,1]]",
      "expected": "(-1, []) or (2, [1]) depending on implementation",
      "explanation": "Self-dependency is a cycle. Our implementation skips self-loops."
    },
    {
      "name": "Complex DAG",
      "category": "Hard",
      "input": "tasks=[[1,1],[2,2],[3,3],[4,3],[5,5],[6,4]], deps=[[1,2],[1,3],[2,4],[3,4],[3,5],[4,6],[5,6]]",
      "expected": "(13, valid topo order)",
      "explanation": "Critical path: 1\u21923\u21925\u21926 = 1+3+5+4 = 13"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Summing all durations instead of finding critical path",
      "why_wrong": "Assumes sequential execution. With unlimited workers, tasks run in parallel.",
      "correct_approach": "Track completion_time[task] = max(prereq completion times) + duration",
      "code_wrong": "total = sum(duration.values())  # WRONG",
      "code_correct": "total = max(completion_time.values())  # Correct: critical path"
    },
    {
      "mistake": "Using array indexing with non-consecutive task IDs",
      "why_wrong": "Task IDs like 1, 5, 100 would require array size 101 and waste space",
      "correct_approach": "Use HashMap/Dict for all task-indexed structures",
      "code_wrong": "duration = [0] * (max_id + 1)\nduration[task_id] = dur",
      "code_correct": "duration = {}\nduration[task_id] = dur"
    },
    {
      "mistake": "Calculating completion time when processing the task instead of when adding to queue",
      "why_wrong": "When processing, we might not have all prereqs done. When in_degree=0, ALL prereqs are done.",
      "correct_approach": "Calculate completion time when in_degree becomes 0, then add to queue",
      "code_wrong": "while queue:\n    task = queue.pop()\n    start = max(completion[p] for p in prereqs[task])  # prereqs might not be done!",
      "code_correct": "if in_degree[dep] == 0:\n    start = max(completion[p] for p in prereqs[dep])  # ALL prereqs guaranteed done"
    },
    {
      "mistake": "Not detecting cycles properly",
      "why_wrong": "Can cause infinite loops or incorrect results",
      "correct_approach": "After Kahn's algorithm, check if len(processed) == len(tasks)",
      "code_wrong": "# No cycle check, just return result",
      "code_correct": "if len(order) != len(self._duration):\n    return (-1, [])  # Cycle detected"
    },
    {
      "mistake": "Forgetting to initialize in_degree for tasks with no dependencies",
      "why_wrong": "Tasks might not be found in initial queue, causing them to be skipped",
      "correct_approach": "Initialize in_degree[task] = 0 for ALL tasks, then increment for dependencies",
      "code_wrong": "for prereq, dep in deps:\n    in_degree[dep] += 1  # Tasks with no deps are never initialized!",
      "code_correct": "for task_id, dur in tasks:\n    in_degree[task_id] = 0  # Initialize all\nfor prereq, dep in deps:\n    in_degree[dep] += 1"
    }
  ],
  "interview_tips": {
    "opening": "Thank you for this problem. This looks like a task scheduling problem with dependencies. Before I dive in, let me clarify a few things and share my initial thoughts...",
    "clarifying_questions_to_ask": [
      "Are task IDs guaranteed to be consecutive integers, or can they be sparse like 1, 5, 100? (Affects data structure choice)",
      "When it says 'unlimited parallel workers', does that mean any number of tasks can run simultaneously? (Confirms critical path approach)",
      "Should I return the lexicographically smallest valid order, or is any valid order acceptable? (Simplifies problem)",
      "Can there be duplicate dependencies in the input? (Error handling)",
      "What should I return for an empty task list? (Edge case)"
    ],
    "what_to_mention_proactively": [
      "This is a classic topological sort problem combined with critical path analysis",
      "I'll use Kahn's algorithm (BFS-based) because it naturally handles cycle detection",
      "The key insight is that with unlimited workers, total time = critical path, not sum of durations",
      "I need to track both forward edges (for processing) and reverse edges (for completion time calculation)"
    ],
    "communication_during_coding": [
      "I'm building both forward and reverse adjacency lists here...",
      "Using defaultdict so I don't need to check if keys exist...",
      "The magic happens when in_degree becomes 0 - that's when I calculate completion time...",
      "This cycle detection works because any node in a cycle will never reach in_degree 0..."
    ],
    "if_stuck": [
      "Let me step back. What's the key constraint? Unlimited workers means parallel execution.",
      "Draw the graph: When can a task start? When ALL prerequisites are done.",
      "What's the formula? start_time = max(end_time of prerequisites)",
      "How do I know when all prerequisites are done? Kahn's algorithm - in_degree becomes 0"
    ],
    "time_management": "0-5min: Clarify & understand | 5-10min: Explain approach, get buy-in | 10-25min: Code | 25-35min: Test & trace | 35-45min: Follow-ups"
  },
  "pattern_recognition": {
    "pattern_name": "Topological Sort + Dynamic Programming on DAG",
    "indicators": [
      "Tasks/courses with prerequisites/dependencies",
      "Find valid order of execution",
      "Calculate minimum/maximum time with parallel execution",
      "Detect if completion is possible (cycle detection)"
    ],
    "similar_problems": [
      "LC 207 - Course Schedule: Just cycle detection, no time calculation",
      "LC 210 - Course Schedule II: Return topological order, no time",
      "LC 1136 - Parallel Courses: Same as this problem",
      "LC 269 - Alien Dictionary: Build graph from constraints, then topo sort",
      "LC 329 - Longest Increasing Path: DFS with memoization on implicit DAG"
    ],
    "template": "```\n1. Build adjacency list + in_degree map\n2. Initialize queue with in_degree=0 nodes\n3. While queue not empty:\n   a. Pop node, add to result\n   b. For each neighbor: decrement in_degree\n   c. If in_degree becomes 0, add to queue\n4. Check if all nodes processed (cycle detection)\n```"
  },
  "follow_up_preparation": {
    "part_2_hint": "**Limited Workers**: With k workers, you can't run more than k tasks in parallel. Use a **min-heap** ordered by end time to track running tasks. When a task finishes, check if any waiting tasks can start.",
    "part_3_hint": "**Find Critical Path**: Track which prerequisite gave the max completion time for each task. Then backtrack from the task with max completion time to find the critical path.",
    "data_structure_evolution": "Part 1: HashMap + Queue \u2192 Part 2: Add PriorityQueue for worker scheduling \u2192 Part 3: Add 'critical_predecessor' tracking for path reconstruction"
  },
  "communication_script": {
    "opening_verbatim": "Thank you for this problem. I see we have tasks with durations and dependencies, and we need to find both a valid execution order and the minimum completion time. Before I start, I'd like to clarify a few things...",
    "after_clarification": "Great, so to summarize: task IDs may not be consecutive, we have unlimited parallel workers so the answer is the critical path length, and any valid topological order works. My approach will be to use Kahn's algorithm for topological sort while simultaneously tracking completion times. Does that sound reasonable before I start coding?",
    "while_coding": [
      "I'm creating separate maps for forward edges, reverse edges, durations, and in-degrees...",
      "Notice I'm initializing in_degree to 0 for ALL tasks first, then incrementing for dependencies...",
      "This is the key part - when in_degree becomes 0, I calculate completion time as max of prerequisites plus duration...",
      "The cycle detection is implicit - if the queue empties before all nodes are processed, there's a cycle..."
    ],
    "after_coding": "Let me trace through the diamond example to verify. Task 1 has in_degree 0, so it starts first with completion time 3. Then tasks 2 and 3 can start at time 3, completing at 5 and 8 respectively. Task 4 waits for both, starts at max(5,8)=8, and completes at 11. That matches our expected output.",
    "when_stuck_verbatim": "I'm thinking about how to handle the completion time calculation... Let me draw out a small example to visualize when each task can start...",
    "after_mistake": "Actually, I see an issue - I was calculating the start time at the wrong point. I need to calculate it when in_degree becomes 0, not when I pop from the queue. Let me fix that.",
    "before_moving_on": "This solution handles Part 1 with O(V+E) time and space complexity. The topological order is correct because we respect all dependencies, and the total time is the critical path length. Ready for the follow-up about limited workers?"
  },
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Can candidate recognize this as a graph problem (topological sort)?",
      "Do they understand the difference between sequential and parallel execution?",
      "Can they explain the critical path concept clearly?",
      "Is the code clean and well-organized?",
      "Do they handle edge cases (empty input, cycles, non-consecutive IDs)?"
    ],
    "bonus_points": [
      "Drawing the graph before coding",
      "Mentioning Kahn's vs DFS and explaining the choice",
      "Proactively handling non-consecutive IDs without being told",
      "Explaining why in_degree=0 means all prerequisites are done",
      "Connecting this to real-world build systems like make or npm"
    ],
    "red_flags": [
      "Summing durations instead of finding max (misunderstanding parallel execution)",
      "Using array index for task IDs (won't work for sparse IDs)",
      "Not detecting cycles (will cause infinite loop or wrong answer)",
      "Unable to explain why the algorithm is correct",
      "Not tracing through an example after coding"
    ],
    "what_differentiates_strong_candidates": "Strong candidates immediately recognize the topological sort pattern, explain the critical path insight clearly, choose the right data structures (HashMap not array), write clean code with good variable names, and verify correctness by tracing through examples. They treat the problem as a conversation, explaining their reasoning throughout."
  },
  "time_milestones": {
    "by_5_min": "Understand the problem, ask clarifying questions, recognize it's topological sort + critical path",
    "by_10_min": "Explain Kahn's algorithm approach, discuss data structures (HashMap for non-consecutive IDs), get interviewer buy-in",
    "by_20_min": "Complete graph building and topological sort implementation",
    "by_25_min": "Complete critical path calculation and cycle detection",
    "by_30_min": "Code complete, start tracing through example",
    "by_35_min": "Part 1 done, discuss complexity, ready for Part 2",
    "warning_signs": "If still clarifying at 10 min, speed up. If still coding at 30 min, finish quickly or describe remaining logic verbally."
  },
  "recovery_strategies": {
    "when_you_make_a_bug": "Stay calm. Say: 'I see an issue here - the completion time calculation should happen when in_degree becomes 0, not when I pop from the queue. Let me fix that.' Interviewers expect bugs; they evaluate how gracefully you handle them.",
    "when_you_dont_know_syntax": "Say: 'I don't remember the exact syntax for Python deque, but I need a queue with O(1) pop from front. Let me write collections.deque and popleft().' This is acceptable.",
    "when_approach_is_wrong": "If you realize summing durations is wrong: 'Actually, I realize with parallel workers, the total time is the critical path, not the sum. Let me adjust my approach to track completion times.' Pivoting cleanly shows adaptability.",
    "when_completely_stuck": "Ask: 'I'm stuck on how to calculate when a task can start. Could you give me a hint about the timing?' Asking targeted questions shows self-awareness.",
    "when_running_out_of_time": "Say: 'I'm running low on time. Let me describe the critical path calculation verbally: for each task, start time = max of prerequisite completion times. I'd implement this by tracking completion_time as I process nodes.' Showing understanding is better than incomplete code."
  },
  "ai_copilot_tips": {
    "when_using_cursor_or_copilot": "AI tools can help with boilerplate and syntax, but YOU must drive the algorithm design.",
    "what_to_do": [
      "Let AI autocomplete defaultdict imports and type hints",
      "Use AI for generating test cases",
      "Accept suggestions for standard patterns (BFS loop structure)",
      "Use AI to check syntax for unfamiliar libraries"
    ],
    "what_not_to_do": [
      "Don't paste the problem and expect a complete solution",
      "Don't accept completion time calculation without verifying it's correct",
      "Don't let AI choose between Kahn's and DFS - make that decision yourself",
      "Don't skip understanding what the generated code does"
    ],
    "how_to_demonstrate_understanding": "If AI suggests a line, explain it: 'This calculates the start time as the maximum of all prerequisite completion times because a task can only start when ALL its prerequisites are done.'",
    "expectation_adjustment": "With AI assistance, interviewers expect faster completion and more thorough testing. Use the time saved for better explanation and edge case handling."
  },
  "signal_points": {
    "wow_factors": [
      "Drawing the dependency graph before coding",
      "Immediately recognizing the critical path insight (max not sum)",
      "Explaining why Kahn's algorithm naturally detects cycles",
      "Mentioning real-world applications (build systems, CI/CD)",
      "Writing clean code with single-responsibility methods on first pass",
      "Proactively discussing space optimization (store one direction, compute other)"
    ],
    "subtle_signals_of_experience": [
      "Using defaultdict instead of checking key existence",
      "Handling non-consecutive IDs without being reminded",
      "Naming variables clearly (completion_time not ct)",
      "Adding docstrings and type hints naturally",
      "Testing incrementally (verify graph construction before running algorithm)"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Staying silent while coding for more than 60 seconds",
      "Getting defensive when interviewer suggests the approach might be wrong",
      "Rushing to code without understanding the problem fully",
      "Not making eye contact or engaging with the interviewer"
    ],
    "technical": [
      "Using array[task_id] when IDs can be sparse",
      "Computing sum of durations instead of critical path",
      "Not handling cycles (will cause infinite loop or wrong answer)",
      "Hardcoding values instead of using variables",
      "Writing one giant function instead of modular code"
    ],
    "communication": [
      "Using jargon like 'DAG' without explaining what it means",
      "Going into irrelevant tangents about graph theory",
      "Not summarizing the approach before coding",
      "Skipping the trace-through after coding"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Did I return both the total time AND the execution order?",
      "Did I handle cycles correctly (return -1, [])?",
      "Did I use HashMap for task IDs (not array indexing)?",
      "Did I trace through at least one example?",
      "Did I discuss time (O(V+E)) and space (O(V+E)) complexity?",
      "Are my variable names clear and meaningful?"
    ],
    "quick_code_review": [
      "All maps initialized before use",
      "in_degree initialized for ALL tasks (not just those in dependencies)",
      "completion_time calculated when in_degree becomes 0",
      "Cycle check: len(order) == len(tasks)",
      "Final result: max(completion_time.values())"
    ]
  },
  "production_considerations": {
    "what_id_add_in_production": [
      "Input validation with descriptive error messages (invalid task references, negative durations)",
      "Logging for debugging (graph structure, processing order)",
      "Metrics for monitoring (number of tasks, number of edges, execution time)",
      "Thread-safety if the scheduler is shared across threads",
      "Persistence layer for storing task definitions",
      "API for querying task status and estimated completion time"
    ],
    "why_not_in_interview": "Interview code should focus on the algorithm. Mention these verbally: 'In production, I'd add input validation, logging, and possibly persistence.'",
    "how_to_mention": "Say: 'This covers the core algorithm. In a production system, I'd also add input validation for edge cases like negative durations or self-references, and logging to help debug scheduling issues.'"
  },
  "generated_at": "2026-01-18T18:55:44.220035",
  "_meta": {
    "problem_id": "task_scheduling_dependencies",
    "part_number": null,
    "model": "claude-opus-4-5-20251101"
  }
}