{
  "problem_title": "Design Instagram - Photo Sharing Platform",
  "difficulty": "hard",
  "category": "HLD/System Design",
  "estimated_time": "45-60 minutes",
  "problem_analysis": {
    "first_impressions": "This is a **large-scale distributed system design** problem requiring expertise in blob storage, social graphs, feed generation, and CDN architecture. The core challenge is building a system that handles 500M DAU with sub-second latency while managing the famous 'celebrity problem' in feed generation.",
    "pattern_recognition": "**Social Media Architecture** + **CDN Distribution** + **Fan-out Strategies** + **Write-Heavy Storage** + **Read-Heavy Feed** + **Database Sharding** + **Caching Layers**",
    "key_constraints": [
      "500M DAU - Requires horizontal scaling across all components",
      "100M photos/day (200TB storage) - Blob storage with CDN, not database",
      "100:1 read:write ratio - Heavy caching, pre-computation for reads",
      "100K feed requests/sec - Feed must be pre-computed or hybrid",
      "Celebrity accounts (500M followers) - Cannot fan-out on write for all users",
      "99.99% availability - Multi-region, graceful degradation",
      "P99 < 500ms for reads - CDN for images, cache for feeds"
    ],
    "clarifying_questions": [
      "**Feed Algorithm**: Is this chronological or relevance-based? (Reveals: need ranking service, ML pipeline)",
      "**Video Support**: Just photos or also videos/reels? (Reveals: transcoding pipeline, streaming CDN)",
      "**Geographic Distribution**: Single region or global users? (Reveals: multi-region replication strategy)",
      "**Privacy Model**: Public/private accounts? Close friends? (Reveals: access control complexity)",
      "**Real-time Requirements**: How fresh must the feed be? Seconds or minutes delay OK? (Reveals: push vs pull decision)",
      "**Stories Feature**: Include ephemeral 24-hour content? (Reveals: TTL storage, different access pattern)",
      "**Engagement Metrics**: Need analytics on views, reach? (Reveals: event streaming, data warehouse)"
    ],
    "edge_cases_to_consider": [
      "Celebrity with 500M followers posts - fan-out would take hours",
      "Viral post getting millions of views in seconds - hot partition",
      "User follows 10,000 accounts - feed aggregation complexity",
      "User unfollows while scrolling feed - stale data handling",
      "Concurrent likes on same post - counter race conditions",
      "Image upload fails midway - cleanup and retry",
      "User deletes post after it's fanned out - cascade deletion"
    ]
  },
  "visual_explanation": {
    "problem_visualization": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          INSTAGRAM SYSTEM OVERVIEW                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                              TRAFFIC SCALE\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   500M Daily Active Users         \u2502\n                    \u2502   100M Photos Uploaded/Day        \u2502\n                    \u2502   ~100K Feed Requests/Second      \u2502\n                    \u2502   200 TB New Storage/Day          \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502                               \u2502\n               WRITES (1%)                    READS (99%)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502 \u2022 Upload    \u2502              \u2502 \u2022 View Feed     \u2502\n            \u2502 \u2022 Post      \u2502              \u2502 \u2022 View Profile  \u2502\n            \u2502 \u2022 Like      \u2502              \u2502 \u2022 View Post     \u2502\n            \u2502 \u2022 Comment   \u2502              \u2502 \u2022 Search        \u2502\n            \u2502 \u2022 Follow    \u2502              \u2502 \u2022 Explore       \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                    THE CELEBRITY PROBLEM\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                                                      \u2502\n    \u2502   Normal User (200 followers)     Celebrity (10M)   \u2502\n    \u2502   \u250c\u2500\u2500\u2500\u2510                           \u250c\u2500\u2500\u2500\u2510             \u2502\n    \u2502   \u2502 U \u2502\u2500\u2500posts\u2500\u2500\u25ba                 \u2502 C \u2502\u2500\u2500posts\u2500\u2500\u25ba   \u2502\n    \u2502   \u2514\u2500\u2500\u2500\u2518          \u2502                \u2514\u2500\u2500\u2500\u2518          \u2502  \u2502\n    \u2502                  \u25bc                               \u25bc  \u2502\n    \u2502            Fan-out to                    TOO EXPENSIVE\u2502\n    \u2502            200 feeds                     10M writes! \u2502\n    \u2502            (fast!)                       (5+ minutes)\u2502\n    \u2502                                                      \u2502\n    \u2502   SOLUTION: Hybrid - Push for normal, Pull for celebs\u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "data_structure_state": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        DATA STORAGE ARCHITECTURE                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   PostgreSQL    \u2502     \u2502    Cassandra    \u2502     \u2502     Redis       \u2502\n\u2502  (User Data)    \u2502     \u2502  (Posts, Feeds) \u2502     \u2502   (Hot Cache)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 User profiles \u2502     \u2502 \u2022 Post metadata \u2502     \u2502 \u2022 Active feeds  \u2502\n\u2502 \u2022 Auth data     \u2502     \u2502 \u2022 User timelines\u2502     \u2502 \u2022 User sessions \u2502\n\u2502 \u2022 Settings      \u2502     \u2502 \u2022 Feed items    \u2502     \u2502 \u2022 Like counts   \u2502\n\u2502 \u2022 Follower count\u2502     \u2502 \u2022 Social graph  \u2502     \u2502 \u2022 Hot posts     \u2502\n\u2502                 \u2502     \u2502                 \u2502     \u2502 \u2022 Celebrity posts\u2502\n\u2502 Strong          \u2502     \u2502 Eventual        \u2502     \u2502 TTL-based       \u2502\n\u2502 Consistency     \u2502     \u2502 Consistency     \u2502     \u2502 Invalidation    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                       \u2502                       \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502      S3       \u2502\n                        \u2502 (Blob Storage)\u2502\n                        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                        \u2502 \u2022 Original img\u2502\n                        \u2502 \u2022 Thumbnails  \u2502\n                        \u2502 \u2022 Videos      \u2502\n                        \u2502 \u2022 73 PB/year  \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502      CDN      \u2502\n                        \u2502 (CloudFront)  \u2502\n                        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                        \u2502 \u2022 200+ PoPs   \u2502\n                        \u2502 \u2022 <50ms global\u2502\n                        \u2502 \u2022 Cache 1 year\u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": [
      {
        "step": 1,
        "description": "Photo Upload Flow",
        "visualization": "```\nClient \u2500\u2500\u2500\u2500\u2500\u25ba API Gateway \u2500\u2500\u2500\u2500\u2500\u25ba Upload Service\n                                      \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502                                   \u2502\n                    \u25bc                                   \u25bc\n              Store to S3                    Create Post Entry\n              (Original)                     (PostgreSQL)\n                    \u2502                                   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n                           Message Queue\n                           (Kafka/SQS)\n                                  \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502             \u2502             \u2502\n                    \u25bc             \u25bc             \u25bc\n              Generate      Push to CDN    Fan-out to\n              Thumbnails                   Follower Feeds\n              (Workers)                    (if <10K followers)\n```",
        "key_point": "Async processing - return post ID immediately, process thumbnails in background"
      },
      {
        "step": 2,
        "description": "Hybrid Feed Generation",
        "visualization": "```\n                    GET /feed (user_A)\n                            \u2502\n                            \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502 Feed Service  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502                               \u2502\n            \u25bc                               \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Redis Cache  \u2502               \u2502 Celebrity     \u2502\n    \u2502  (Pre-pushed  \u2502               \u2502 Posts Table   \u2502\n    \u2502   feed items) \u2502               \u2502 (Pull recent) \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502                               \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502 Merge & Rank  \u2502\n                    \u2502 (Relevance)   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u25bc\n                    Return Top N Posts\n                    with Next Cursor\n```",
        "key_point": "Hybrid approach: pre-computed for normal users, real-time pull for celebrity posts"
      },
      {
        "step": 3,
        "description": "Image Serving via CDN",
        "visualization": "```\n            User requests image\n                    \u2502\n                    \u25bc\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502   DNS Lookup  \u2502\n            \u2502 (cdn.ig.com)  \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502  Nearest PoP  \u2502\u2500\u2500\u2500\u2500 HIT \u2500\u2500\u2500\u2500\u25ba Return Cached\n            \u2502  (Edge Cache) \u2502                   \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n                    \u2502 MISS                      \u2502\n                    \u25bc                           \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n            \u2502 Origin Shield \u2502\u2500\u2500\u2500\u2500 HIT \u2500\u2500\u2500\u2500\u25ba\u2500\u2500\u2500\u2500\u2500\u2524\n            \u2502 (Regional)    \u2502                   \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n                    \u2502 MISS                      \u2502\n                    \u25bc                           \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n            \u2502      S3       \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n            \u2502   (Origin)    \u2502                   \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n                                                \u25bc\n                                    Image delivered <200ms\n```",
        "key_point": "Multi-tier caching with origin shield to protect S3 from thundering herd"
      }
    ],
    "dry_run_table": "| Operation | User | Action | Data Store Updates | Cache Updates | Feed Impact |\n|-----------|------|--------|-------------------|---------------|-------------|\n| 1. addDriver | - | User registers | PostgreSQL: users table | Redis: user session | - |\n| 2. follow | A\u2192B | A follows B | Cassandra: social_graph | Redis: A's following list | A's feed will include B's posts |\n| 3. uploadPhoto | B | B posts photo | S3: image, PG: post metadata | CDN: thumbnails | Fan-out to B's followers including A |\n| 4. fanout | B | Push to followers | Cassandra: feed items for each follower | Redis: update A's feed cache | A sees B's post instantly |\n| 5. getFeed | A | A opens app | Read from Cassandra/Redis | Cache hit or populate | Return merged, ranked feed |"
  },
  "thinking_process": {
    "step_by_step": [
      "**When I see 'photo sharing platform'**, I immediately think: blob storage (S3), CDN distribution, and image processing pipeline. Photos should NEVER be stored in a database.",
      "**When I see '500M DAU'**, I know this requires: horizontal scaling, database sharding, heavy caching, and geographic distribution.",
      "**When I see 'News Feed'**, I think of the classic Push vs Pull trade-off. At this scale, neither pure approach works - need hybrid.",
      "**The key insight for feeds is**: Normal users (200 followers) \u2192 push (fan-out on write). Celebrities (10M followers) \u2192 pull (fan-out on read).",
      "**For the celebrity threshold**, I'd use ~10K followers. Below: push to all followers' feeds. Above: mark as celebrity, pull on read.",
      "**For image storage**, the math: 100M photos \u00d7 2MB = 200TB/day. That's 73 PB/year. Must use object storage (S3) with lifecycle policies.",
      "**For latency requirements**, feed in <500ms means: pre-computed feeds in Redis, CDN for images, regional deployments.",
      "**For availability (99.99%)**, this means: multi-region active-active, graceful degradation, circuit breakers, async processing."
    ],
    "key_insight": "**The celebrity problem is THE defining challenge of Instagram's architecture.** When a celebrity with 350M followers posts, you cannot write to 350M feeds (would take 5+ minutes at 1M writes/sec). The solution is a **hybrid fan-out model**: push for normal users (O(followers) write), pull for celebrities (O(celebrity_followees) read). This shifts the cost from write-time to read-time only for celebrity posts.",
    "why_this_works": "The hybrid approach works because:\n\n1. **Most users are normal** (<10K followers) - push is efficient\n2. **Celebrity posts are rare** relative to total posts - pull cost is amortized\n3. **Merge at read-time** adds only ~10-50ms latency\n4. **Celebrity posts are hot** - cached in Redis, so pull is O(1) from cache\n5. **Read:Write is 100:1** - optimizing writes is more impactful"
  },
  "approaches": [
    {
      "name": "Approach 1: Pure Fan-out on Write (Push)",
      "description": "When a user posts, immediately push the post to all followers' pre-computed feeds. Feeds are just sorted lists in Cassandra/Redis.",
      "pseudocode": "on_post(user, post):\n    followers = get_followers(user)\n    for follower in followers:\n        append_to_feed(follower, post)\n        \non_get_feed(user):\n    return cache.get(user.feed)  # O(1)!",
      "time_complexity": "Write: O(followers), Read: O(1)",
      "space_complexity": "O(total_users \u00d7 avg_feed_size) - massive duplication",
      "pros": [
        "Extremely fast reads - just fetch pre-computed list",
        "Simple read path - no complex aggregation",
        "Works great for users with few followers"
      ],
      "cons": [
        "Celebrity problem: 350M writes per celebrity post",
        "Write amplification: same post stored millions of times",
        "Wasted work if followers never read feed"
      ],
      "when_to_use": "Small-scale social networks, or as part of hybrid for non-celebrity users"
    },
    {
      "name": "Approach 2: Pure Fan-out on Read (Pull)",
      "description": "Don't pre-compute feeds. When user requests feed, fetch latest posts from all users they follow and merge/rank in real-time.",
      "pseudocode": "on_post(user, post):\n    store(post)  # O(1)\n    \non_get_feed(user):\n    following = get_following(user)\n    posts = []\n    for followee in following:\n        posts.extend(get_recent_posts(followee))\n    return rank_and_sort(posts)  # O(following \u00d7 posts)",
      "time_complexity": "Write: O(1), Read: O(following \u00d7 posts_per_user)",
      "space_complexity": "O(total_posts) - no duplication",
      "pros": [
        "Fast writes - just store the post once",
        "No write amplification",
        "Fresh data - no stale feeds"
      ],
      "cons": [
        "Slow reads for users following many accounts",
        "Heavy read-time computation",
        "Scaling reads is hard"
      ],
      "when_to_use": "For celebrity accounts where push is prohibitively expensive"
    },
    {
      "name": "Approach 3: Hybrid (Instagram's Approach) - OPTIMAL",
      "description": "Use push for normal users (< threshold followers), pull for celebrities (> threshold followers). Merge at read time.",
      "pseudocode": "CELEBRITY_THRESHOLD = 10000\n\non_post(user, post):\n    store(post)\n    if user.follower_count < CELEBRITY_THRESHOLD:\n        fan_out_to_followers(user, post)  # Push\n    else:\n        mark_as_celebrity_post(post)  # Will be pulled\n        \non_get_feed(user):\n    # Get pre-computed feed (pushed posts)\n    feed = cache.get(user.feed)\n    \n    # Get celebrity followees\n    celebs = get_celebrity_followees(user)\n    \n    # Pull recent celebrity posts\n    celeb_posts = pull_recent_posts(celebs)\n    \n    # Merge and rank\n    return merge_and_rank(feed, celeb_posts)",
      "time_complexity": "Write: O(1) for celebs, O(followers) for normal. Read: O(1) + O(celeb_followees)",
      "space_complexity": "O(users \u00d7 feed_size) + O(celebrity_posts)",
      "pros": [
        "Solves celebrity problem elegantly",
        "Fast reads for most cases",
        "Balances write and read costs"
      ],
      "cons": [
        "More complex implementation",
        "Threshold tuning required",
        "Slightly higher read latency for celebrity-heavy feeds"
      ],
      "key_insight": "The threshold (10K) can be dynamic based on follower engagement rates"
    }
  ],
  "optimal_solution": {
    "name": "Hybrid Fan-out with Tiered Storage and Multi-Region CDN",
    "explanation_md": "## The Complete Instagram Architecture\n\n### Core Principles\n\n1. **Separate Hot and Cold Data** - Active feeds in Redis, historical in Cassandra\n2. **Hybrid Fan-out** - Push for normal users, pull for celebrities\n3. **Immutable Media** - Photos never change, cache forever on CDN\n4. **Async Everything** - Upload returns immediately, processing is background\n\n### Why This Works\n\nThe architecture handles the three hardest problems:\n\n1. **Celebrity Problem** \u2192 Hybrid fan-out (push + pull)\n2. **Media Scale (73 PB/year)** \u2192 S3 + CDN with tiered storage\n3. **Global Latency** \u2192 Multi-region with geo-routing\n\n### Key Design Decisions\n\n| Decision | Choice | Why |\n|----------|--------|-----|\n| Photo Storage | S3 + CloudFront | Blob storage, not DB. CDN for global latency |\n| Feed Store | Cassandra | Wide-column, optimized for time-series reads |\n| Hot Cache | Redis Cluster | In-memory, sub-ms latency |\n| User Data | PostgreSQL | ACID for critical user data |\n| Social Graph | Cassandra | Adjacency list pattern, sharded by user |\n| Message Queue | Kafka | Fan-out, async processing, replay capability |",
    "data_structures": [
      {
        "structure": "Redis Sorted Set (feed:{user_id})",
        "purpose": "Pre-computed feed with score=timestamp for ordering. O(log n) insert, O(k) range query"
      },
      {
        "structure": "Cassandra Wide Row (posts_by_user)",
        "purpose": "Time-series posts per user. Partition key=user_id, clustering key=timestamp DESC"
      },
      {
        "structure": "S3 + CloudFront",
        "purpose": "Immutable photo storage with global CDN distribution. Cache-Control: max-age=31536000"
      },
      {
        "structure": "Kafka Topics (post-events, fanout-tasks)",
        "purpose": "Decouple upload from fan-out. Enable replay for failed workers"
      },
      {
        "structure": "PostgreSQL (users, auth)",
        "purpose": "Strong consistency for user profiles, auth, and settings"
      }
    ],
    "algorithm_steps": [
      "**1. Photo Upload**: Client \u2192 Upload Service \u2192 S3 (original) \u2192 return post_id immediately",
      "**2. Async Processing**: Kafka event \u2192 Image Workers \u2192 generate thumbnails (150, 320, 640, 1080) \u2192 push to CDN",
      "**3. Metadata Storage**: Store post metadata in PostgreSQL (for consistency) and Cassandra (for queries)",
      "**4. Fan-out Decision**: If poster has < 10K followers \u2192 push to all follower feeds. Else \u2192 mark as celebrity post",
      "**5. Feed Generation**: On read, fetch pre-computed feed from Redis + pull recent celebrity posts + merge & rank",
      "**6. Image Serving**: Client requests CDN URL \u2192 Edge PoP serves cached image or fetches from origin shield \u2192 S3"
    ],
    "why_decimal": "N/A for this problem - but we use **64-bit epoch milliseconds** for timestamps to avoid Y2K38 issues and ensure global ordering"
  },
  "solution_python_lines": [
    "\"\"\"",
    "Instagram System Design - Core Services Implementation",
    "",
    "This module provides production-quality implementations of Instagram's core services:",
    "- Upload Service: Photo upload with async processing",
    "- Feed Service: Hybrid fan-out feed generation",
    "- Social Graph Service: Follow/unfollow management",
    "",
    "Author: System Design Expert",
    "\"\"\"",
    "",
    "from abc import ABC, abstractmethod",
    "from dataclasses import dataclass, field",
    "from datetime import datetime",
    "from decimal import Decimal",
    "from enum import Enum",
    "from typing import Dict, List, Optional, Set, Tuple",
    "from collections import defaultdict",
    "import heapq",
    "import uuid",
    "import time",
    "",
    "",
    "# ============================================================================",
    "# DATA MODELS",
    "# ============================================================================",
    "",
    "@dataclass",
    "class Location:",
    "    \"\"\"Geographic location with latitude and longitude.\"\"\"",
    "    lat: float",
    "    lng: float",
    "",
    "",
    "@dataclass",
    "class ImageUrls:",
    "    \"\"\"URLs for different image resolutions.\"\"\"",
    "    thumbnail: str   # 150x150",
    "    small: str       # 320x320",
    "    medium: str      # 640x640",
    "    large: str       # 1080x1080",
    "    original: str    # Raw upload",
    "",
    "",
    "@dataclass",
    "class User:",
    "    \"\"\"User profile data.\"\"\"",
    "    user_id: str",
    "    username: str",
    "    email: str",
    "    follower_count: int = 0",
    "    following_count: int = 0",
    "    is_private: bool = False",
    "    is_celebrity: bool = False",
    "    created_at: int = field(default_factory=lambda: int(time.time() * 1000))",
    "    ",
    "    CELEBRITY_THRESHOLD = 10000",
    "    ",
    "    def update_celebrity_status(self) -> None:",
    "        \"\"\"Update celebrity status based on follower count.\"\"\"",
    "        self.is_celebrity = self.follower_count >= self.CELEBRITY_THRESHOLD",
    "",
    "",
    "@dataclass",
    "class Post:",
    "    \"\"\"A photo/video post with metadata.\"\"\"",
    "    post_id: str",
    "    user_id: str",
    "    caption: str",
    "    image_urls: Optional[ImageUrls] = None",
    "    tags: List[str] = field(default_factory=list)",
    "    location: Optional[Location] = None",
    "    like_count: int = 0",
    "    comment_count: int = 0",
    "    created_at: int = field(default_factory=lambda: int(time.time() * 1000))",
    "    is_from_celebrity: bool = False",
    "",
    "",
    "@dataclass",
    "class FeedItem:",
    "    \"\"\"An item in a user's feed with relevance scoring.\"\"\"",
    "    post_id: str",
    "    user_id: str",
    "    timestamp: int",
    "    relevance_score: float = 0.0",
    "    is_pulled_from_celebrity: bool = False",
    "    ",
    "    def __lt__(self, other: 'FeedItem') -> bool:",
    "        \"\"\"Compare by timestamp for heap operations (newer first).\"\"\"",
    "        return self.timestamp > other.timestamp",
    "",
    "",
    "@dataclass",
    "class FeedResponse:",
    "    \"\"\"Paginated feed response.\"\"\"",
    "    posts: List[Post]",
    "    next_cursor: Optional[str] = None",
    "    has_more: bool = False",
    "",
    "",
    "# ============================================================================",
    "# STORAGE INTERFACES (Simulating distributed systems)",
    "# ============================================================================",
    "",
    "class BlobStorage(ABC):",
    "    \"\"\"Interface for blob storage (S3-like).\"\"\"",
    "    ",
    "    @abstractmethod",
    "    def upload(self, key: str, data: bytes) -> str:",
    "        \"\"\"Upload blob and return URL.\"\"\"",
    "        pass",
    "    ",
    "    @abstractmethod",
    "    def get_url(self, key: str) -> str:",
    "        \"\"\"Get CDN URL for blob.\"\"\"",
    "        pass",
    "",
    "",
    "class MockS3(BlobStorage):",
    "    \"\"\"Mock S3 implementation for demonstration.\"\"\"",
    "    ",
    "    CDN_BASE = \"https://cdn.instagram.com\"",
    "    ",
    "    def __init__(self):",
    "        self._storage: Dict[str, bytes] = {}",
    "    ",
    "    def upload(self, key: str, data: bytes) -> str:",
    "        self._storage[key] = data",
    "        return self.get_url(key)",
    "    ",
    "    def get_url(self, key: str) -> str:",
    "        return f\"{self.CDN_BASE}/{key}\"",
    "",
    "",
    "class Cache(ABC):",
    "    \"\"\"Interface for distributed cache (Redis-like).\"\"\"",
    "    ",
    "    @abstractmethod",
    "    def get(self, key: str) -> Optional[any]:",
    "        pass",
    "    ",
    "    @abstractmethod",
    "    def set(self, key: str, value: any, ttl_seconds: int = 3600) -> None:",
    "        pass",
    "    ",
    "    @abstractmethod",
    "    def zadd(self, key: str, score: float, member: str) -> None:",
    "        \"\"\"Add to sorted set.\"\"\"",
    "        pass",
    "    ",
    "    @abstractmethod",
    "    def zrange(self, key: str, start: int, stop: int) -> List[str]:",
    "        \"\"\"Get range from sorted set.\"\"\"",
    "        pass",
    "",
    "",
    "class MockRedis(Cache):",
    "    \"\"\"Mock Redis implementation with sorted sets.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        self._cache: Dict[str, any] = {}",
    "        self._sorted_sets: Dict[str, List[Tuple[float, str]]] = defaultdict(list)",
    "    ",
    "    def get(self, key: str) -> Optional[any]:",
    "        return self._cache.get(key)",
    "    ",
    "    def set(self, key: str, value: any, ttl_seconds: int = 3600) -> None:",
    "        self._cache[key] = value",
    "    ",
    "    def zadd(self, key: str, score: float, member: str) -> None:",
    "        \"\"\"Add to sorted set (score = timestamp for feeds).\"\"\"",
    "        self._sorted_sets[key].append((score, member))",
    "        self._sorted_sets[key].sort(reverse=True)  # Newest first",
    "        # Keep only last 1000 items (feed trimming)",
    "        self._sorted_sets[key] = self._sorted_sets[key][:1000]",
    "    ",
    "    def zrange(self, key: str, start: int, stop: int) -> List[str]:",
    "        \"\"\"Get range from sorted set (for feed pagination).\"\"\"",
    "        items = self._sorted_sets.get(key, [])",
    "        return [member for _, member in items[start:stop]]",
    "",
    "",
    "# ============================================================================",
    "# MESSAGE QUEUE (Simulating Kafka)",
    "# ============================================================================",
    "",
    "class MessageQueue:",
    "    \"\"\"Simple message queue for async processing.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        self._queues: Dict[str, List[dict]] = defaultdict(list)",
    "        self._handlers: Dict[str, callable] = {}",
    "    ",
    "    def publish(self, topic: str, message: dict) -> None:",
    "        \"\"\"Publish message to topic.\"\"\"",
    "        self._queues[topic].append(message)",
    "        # In real system, this would be async",
    "        if topic in self._handlers:",
    "            self._handlers[topic](message)",
    "    ",
    "    def subscribe(self, topic: str, handler: callable) -> None:",
    "        \"\"\"Subscribe handler to topic.\"\"\"",
    "        self._handlers[topic] = handler",
    "",
    "",
    "# ============================================================================",
    "# CORE SERVICES",
    "# ============================================================================",
    "",
    "class SocialGraphService:",
    "    \"\"\"",
    "    Manages follower/following relationships.",
    "    ",
    "    In production:",
    "    - Stored in Cassandra with adjacency list pattern",
    "    - Sharded by user_id for write scalability",
    "    - Cached in Redis for hot users",
    "    \"\"\"",
    "    ",
    "    def __init__(self, cache: Cache):",
    "        self._following: Dict[str, Set[str]] = defaultdict(set)  # user -> users they follow",
    "        self._followers: Dict[str, Set[str]] = defaultdict(set)  # user -> their followers",
    "        self._cache = cache",
    "    ",
    "    def follow(self, follower_id: str, followee_id: str) -> bool:",
    "        \"\"\"",
    "        Create follow relationship.",
    "        ",
    "        Args:",
    "            follower_id: User who is following",
    "            followee_id: User being followed",
    "            ",
    "        Returns:",
    "            True if follow was created, False if already following",
    "        \"\"\"",
    "        if followee_id in self._following[follower_id]:",
    "            return False  # Already following",
    "        ",
    "        self._following[follower_id].add(followee_id)",
    "        self._followers[followee_id].add(follower_id)",
    "        ",
    "        # Invalidate cache",
    "        self._cache.set(f\"following:{follower_id}\", None)",
    "        self._cache.set(f\"followers:{followee_id}\", None)",
    "        ",
    "        return True",
    "    ",
    "    def unfollow(self, follower_id: str, followee_id: str) -> bool:",
    "        \"\"\"Remove follow relationship.\"\"\"",
    "        if followee_id not in self._following[follower_id]:",
    "            return False",
    "        ",
    "        self._following[follower_id].discard(followee_id)",
    "        self._followers[followee_id].discard(follower_id)",
    "        return True",
    "    ",
    "    def get_followers(self, user_id: str) -> Set[str]:",
    "        \"\"\"Get all followers of a user.\"\"\"",
    "        return self._followers.get(user_id, set())",
    "    ",
    "    def get_following(self, user_id: str) -> Set[str]:",
    "        \"\"\"Get all users that a user follows.\"\"\"",
    "        return self._following.get(user_id, set())",
    "    ",
    "    def get_follower_count(self, user_id: str) -> int:",
    "        \"\"\"Get follower count for celebrity threshold check.\"\"\"",
    "        return len(self._followers.get(user_id, set()))",
    "",
    "",
    "class PostService:",
    "    \"\"\"",
    "    Manages post storage and retrieval.",
    "    ",
    "    In production:",
    "    - Metadata in PostgreSQL (for ACID on create)",
    "    - Denormalized to Cassandra for read queries",
    "    - Hot posts cached in Redis",
    "    \"\"\"",
    "    ",
    "    def __init__(self, blob_storage: BlobStorage, cache: Cache):",
    "        self._posts: Dict[str, Post] = {}",
    "        self._user_posts: Dict[str, List[str]] = defaultdict(list)  # user_id -> [post_ids]",
    "        self._blob_storage = blob_storage",
    "        self._cache = cache",
    "    ",
    "    def create_post(",
    "        self,",
    "        user_id: str,",
    "        photo_data: bytes,",
    "        caption: str,",
    "        tags: List[str],",
    "        location: Optional[Location],",
    "        is_celebrity: bool = False",
    "    ) -> Post:",
    "        \"\"\"",
    "        Create a new post with photo.",
    "        ",
    "        In production, this triggers async image processing pipeline.",
    "        \"\"\"",
    "        post_id = str(uuid.uuid4())",
    "        ",
    "        # Upload original to blob storage",
    "        original_key = f\"{user_id}/{post_id}/original.jpg\"",
    "        original_url = self._blob_storage.upload(original_key, photo_data)",
    "        ",
    "        # In production: enqueue thumbnail generation job",
    "        # For demo: generate URLs synchronously",
    "        image_urls = ImageUrls(",
    "            thumbnail=f\"{MockS3.CDN_BASE}/{user_id}/{post_id}/150.jpg\",",
    "            small=f\"{MockS3.CDN_BASE}/{user_id}/{post_id}/320.jpg\",",
    "            medium=f\"{MockS3.CDN_BASE}/{user_id}/{post_id}/640.jpg\",",
    "            large=f\"{MockS3.CDN_BASE}/{user_id}/{post_id}/1080.jpg\",",
    "            original=original_url",
    "        )",
    "        ",
    "        post = Post(",
    "            post_id=post_id,",
    "            user_id=user_id,",
    "            caption=caption,",
    "            image_urls=image_urls,",
    "            tags=tags,",
    "            location=location,",
    "            is_from_celebrity=is_celebrity",
    "        )",
    "        ",
    "        self._posts[post_id] = post",
    "        self._user_posts[user_id].insert(0, post_id)  # Newest first",
    "        ",
    "        # Cache hot post",
    "        self._cache.set(f\"post:{post_id}\", post, ttl_seconds=3600)",
    "        ",
    "        return post",
    "    ",
    "    def get_post(self, post_id: str) -> Optional[Post]:",
    "        \"\"\"Get post by ID.\"\"\"",
    "        # Check cache first",
    "        cached = self._cache.get(f\"post:{post_id}\")",
    "        if cached:",
    "            return cached",
    "        return self._posts.get(post_id)",
    "    ",
    "    def get_user_posts(self, user_id: str, limit: int = 20) -> List[Post]:",
    "        \"\"\"Get posts by a specific user (user timeline).\"\"\"",
    "        post_ids = self._user_posts.get(user_id, [])[:limit]",
    "        return [self._posts[pid] for pid in post_ids if pid in self._posts]",
    "    ",
    "    def get_posts_batch(self, post_ids: List[str]) -> List[Post]:",
    "        \"\"\"Batch fetch posts by IDs (for feed hydration).\"\"\"",
    "        return [self._posts[pid] for pid in post_ids if pid in self._posts]",
    "",
    "",
    "class FeedService:",
    "    \"\"\"",
    "    Hybrid feed generation with push + pull.",
    "    ",
    "    This is the CORE of Instagram's architecture.",
    "    ",
    "    Strategy:",
    "    - PUSH: For users with < 10K followers, fan-out to all follower feeds",
    "    - PULL: For celebrities with > 10K followers, fetch on read",
    "    - MERGE: At read time, merge pre-computed feed with pulled celebrity posts",
    "    \"\"\"",
    "    ",
    "    CELEBRITY_THRESHOLD = 10000",
    "    DEFAULT_FEED_SIZE = 20",
    "    MAX_FEED_CACHE_SIZE = 500",
    "    ",
    "    def __init__(",
    "        self,",
    "        cache: Cache,",
    "        social_graph: SocialGraphService,",
    "        post_service: PostService,",
    "        message_queue: MessageQueue",
    "    ):",
    "        self._cache = cache",
    "        self._social_graph = social_graph",
    "        self._post_service = post_service",
    "        self._mq = message_queue",
    "        ",
    "        # Track celebrities for pull-based feed",
    "        self._celebrities: Set[str] = set()",
    "        ",
    "        # Subscribe to fanout tasks",
    "        self._mq.subscribe('fanout-tasks', self._process_fanout)",
    "    ",
    "    def on_new_post(self, post: Post, poster_follower_count: int) -> None:",
    "        \"\"\"",
    "        Called when a new post is created.",
    "        Decides whether to push (fan-out) or mark for pull.",
    "        \"\"\"",
    "        if poster_follower_count < self.CELEBRITY_THRESHOLD:",
    "            # PUSH: Fan-out to all followers",
    "            self._mq.publish('fanout-tasks', {",
    "                'type': 'fanout',",
    "                'post_id': post.post_id,",
    "                'user_id': post.user_id,",
    "                'timestamp': post.created_at",
    "            })",
    "        else:",
    "            # PULL: Mark user as celebrity, posts pulled on read",
    "            self._celebrities.add(post.user_id)",
    "            # Cache celebrity's latest posts for fast pull",
    "            self._cache.set(",
    "                f\"celebrity-latest:{post.user_id}\",",
    "                post.post_id,",
    "                ttl_seconds=86400  # 24 hours",
    "            )",
    "    ",
    "    def _process_fanout(self, message: dict) -> None:",
    "        \"\"\"",
    "        Process fan-out task: push post to all followers' feeds.",
    "        ",
    "        In production, this runs on a fleet of workers processing",
    "        from Kafka, with batching and rate limiting.",
    "        \"\"\"",
    "        if message['type'] != 'fanout':",
    "            return",
    "        ",
    "        post_id = message['post_id']",
    "        user_id = message['user_id']",
    "        timestamp = message['timestamp']",
    "        ",
    "        followers = self._social_graph.get_followers(user_id)",
    "        ",
    "        for follower_id in followers:",
    "            # Add to follower's pre-computed feed",
    "            feed_key = f\"feed:{follower_id}\"",
    "            self._cache.zadd(feed_key, timestamp, post_id)",
    "    ",
    "    def get_feed(",
    "        self,",
    "        user_id: str,",
    "        page_size: int = 20,",
    "        cursor: Optional[str] = None",
    "    ) -> FeedResponse:",
    "        \"\"\"",
    "        Get personalized feed for user.",
    "        ",
    "        This implements the HYBRID approach:",
    "        1. Get pre-computed feed (pushed posts from normal users)",
    "        2. Pull recent posts from celebrities user follows",
    "        3. Merge and rank by relevance/recency",
    "        \"\"\"",
    "        # Step 1: Get pre-computed feed from cache",
    "        feed_key = f\"feed:{user_id}\"",
    "        start_idx = int(cursor) if cursor else 0",
    "        pushed_post_ids = self._cache.zrange(",
    "            feed_key,",
    "            start_idx,",
    "            start_idx + page_size",
    "        )",
    "        ",
    "        # Step 2: Get celebrity posts (pull-based)",
    "        celebrity_post_ids = self._pull_celebrity_posts(user_id)",
    "        ",
    "        # Step 3: Merge post IDs",
    "        all_post_ids = list(set(pushed_post_ids + celebrity_post_ids))",
    "        ",
    "        # Step 4: Hydrate posts (batch fetch)",
    "        posts = self._post_service.get_posts_batch(all_post_ids)",
    "        ",
    "        # Step 5: Rank and sort (simple recency for demo)",
    "        posts.sort(key=lambda p: p.created_at, reverse=True)",
    "        posts = posts[:page_size]",
    "        ",
    "        # Calculate next cursor",
    "        next_cursor = str(start_idx + len(posts)) if len(posts) == page_size else None",
    "        ",
    "        return FeedResponse(",
    "            posts=posts,",
    "            next_cursor=next_cursor,",
    "            has_more=next_cursor is not None",
    "        )",
    "    ",
    "    def _pull_celebrity_posts(self, user_id: str) -> List[str]:",
    "        \"\"\"",
    "        Pull recent posts from celebrities that user follows.",
    "        ",
    "        This is the 'fan-out on read' part of the hybrid approach.",
    "        Only queries celebrities, not all followees.",
    "        \"\"\"",
    "        following = self._social_graph.get_following(user_id)",
    "        celebrity_followees = following.intersection(self._celebrities)",
    "        ",
    "        pulled_ids = []",
    "        for celeb_id in celebrity_followees:",
    "            # Get from cache (celebrity posts are hot)",
    "            latest = self._cache.get(f\"celebrity-latest:{celeb_id}\")",
    "            if latest:",
    "                pulled_ids.append(latest)",
    "            ",
    "            # In production: also query last N posts from Cassandra",
    "            user_posts = self._post_service.get_user_posts(celeb_id, limit=5)",
    "            pulled_ids.extend([p.post_id for p in user_posts])",
    "        ",
    "        return pulled_ids",
    "",
    "",
    "class UploadService:",
    "    \"\"\"",
    "    Handles photo uploads and orchestrates post creation.",
    "    ",
    "    Upload Flow:",
    "    1. Receive photo from client",
    "    2. Upload to blob storage (S3)",
    "    3. Create post metadata",
    "    4. Enqueue thumbnail generation",
    "    5. Trigger feed fan-out",
    "    6. Return post ID immediately",
    "    \"\"\"",
    "    ",
    "    def __init__(",
    "        self,",
    "        post_service: PostService,",
    "        feed_service: FeedService,",
    "        social_graph: SocialGraphService,",
    "        message_queue: MessageQueue",
    "    ):",
    "        self._post_service = post_service",
    "        self._feed_service = feed_service",
    "        self._social_graph = social_graph",
    "        self._mq = message_queue",
    "    ",
    "    def upload_photo(",
    "        self,",
    "        user_id: str,",
    "        photo: bytes,",
    "        caption: str,",
    "        tags: List[str],",
    "        location: Optional[Location] = None",
    "    ) -> str:",
    "        \"\"\"",
    "        Upload a photo and create a post.",
    "        ",
    "        Args:",
    "            user_id: ID of uploading user",
    "            photo: Raw photo bytes",
    "            caption: Post caption",
    "            tags: List of hashtags",
    "            location: Optional geolocation",
    "            ",
    "        Returns:",
    "            post_id: Unique identifier for the new post",
    "        \"\"\"",
    "        # Determine if user is celebrity (affects fan-out strategy)",
    "        follower_count = self._social_graph.get_follower_count(user_id)",
    "        is_celebrity = follower_count >= FeedService.CELEBRITY_THRESHOLD",
    "        ",
    "        # Create post",
    "        post = self._post_service.create_post(",
    "            user_id=user_id,",
    "            photo_data=photo,",
    "            caption=caption,",
    "            tags=tags,",
    "            location=location,",
    "            is_celebrity=is_celebrity",
    "        )",
    "        ",
    "        # Enqueue thumbnail generation (async)",
    "        self._mq.publish('image-processing', {",
    "            'post_id': post.post_id,",
    "            'original_url': post.image_urls.original",
    "        })",
    "        ",
    "        # Trigger feed fan-out",
    "        self._feed_service.on_new_post(post, follower_count)",
    "        ",
    "        return post.post_id",
    "",
    "",
    "class LikeService:",
    "    \"\"\"",
    "    Manages likes with eventual consistency.",
    "    ",
    "    Uses Redis for fast like counting with periodic sync to DB.",
    "    Handles race conditions with atomic operations.",
    "    \"\"\"",
    "    ",
    "    def __init__(self, cache: Cache):",
    "        self._likes: Dict[str, Set[str]] = defaultdict(set)  # post_id -> user_ids",
    "        self._cache = cache",
    "    ",
    "    def like_post(self, user_id: str, post_id: str) -> int:",
    "        \"\"\"",
    "        Like a post. Returns updated like count.",
    "        Idempotent - liking twice has no additional effect.",
    "        \"\"\"",
    "        if user_id in self._likes[post_id]:",
    "            return len(self._likes[post_id])  # Already liked",
    "        ",
    "        self._likes[post_id].add(user_id)",
    "        new_count = len(self._likes[post_id])",
    "        ",
    "        # Update cache (eventually consistent)",
    "        self._cache.set(f\"likes:{post_id}\", new_count)",
    "        ",
    "        return new_count",
    "    ",
    "    def unlike_post(self, user_id: str, post_id: str) -> int:",
    "        \"\"\"Unlike a post. Returns updated like count.\"\"\"",
    "        self._likes[post_id].discard(user_id)",
    "        new_count = len(self._likes[post_id])",
    "        self._cache.set(f\"likes:{post_id}\", new_count)",
    "        return new_count",
    "    ",
    "    def get_like_count(self, post_id: str) -> int:",
    "        \"\"\"Get like count for a post.\"\"\"",
    "        cached = self._cache.get(f\"likes:{post_id}\")",
    "        if cached is not None:",
    "            return cached",
    "        return len(self._likes.get(post_id, set()))",
    "",
    "",
    "# ============================================================================",
    "# INSTAGRAM APPLICATION (Facade)",
    "# ============================================================================",
    "",
    "class InstagramSystem:",
    "    \"\"\"",
    "    Main Instagram application facade.",
    "    Coordinates all services and provides a unified API.",
    "    \"\"\"",
    "    ",
    "    def __init__(self):",
    "        # Initialize infrastructure",
    "        self._cache = MockRedis()",
    "        self._blob_storage = MockS3()",
    "        self._message_queue = MessageQueue()",
    "        ",
    "        # Initialize services",
    "        self._social_graph = SocialGraphService(self._cache)",
    "        self._post_service = PostService(self._blob_storage, self._cache)",
    "        self._feed_service = FeedService(",
    "            self._cache,",
    "            self._social_graph,",
    "            self._post_service,",
    "            self._message_queue",
    "        )",
    "        self._upload_service = UploadService(",
    "            self._post_service,",
    "            self._feed_service,",
    "            self._social_graph,",
    "            self._message_queue",
    "        )",
    "        self._like_service = LikeService(self._cache)",
    "        ",
    "        # User storage",
    "        self._users: Dict[str, User] = {}",
    "    ",
    "    def create_user(self, username: str, email: str) -> User:",
    "        \"\"\"Create a new user.\"\"\"",
    "        user_id = str(uuid.uuid4())",
    "        user = User(user_id=user_id, username=username, email=email)",
    "        self._users[user_id] = user",
    "        return user",
    "    ",
    "    def upload_photo(",
    "        self,",
    "        user_id: str,",
    "        photo: bytes,",
    "        caption: str,",
    "        tags: List[str] = None,",
    "        location: Location = None",
    "    ) -> str:",
    "        \"\"\"Upload a photo. Returns post ID.\"\"\"",
    "        return self._upload_service.upload_photo(",
    "            user_id, photo, caption, tags or [], location",
    "        )",
    "    ",
    "    def get_news_feed(",
    "        self,",
    "        user_id: str,",
    "        page_size: int = 20,",
    "        cursor: str = None",
    "    ) -> FeedResponse:",
    "        \"\"\"Get personalized news feed.\"\"\"",
    "        return self._feed_service.get_feed(user_id, page_size, cursor)",
    "    ",
    "    def get_user_timeline(",
    "        self,",
    "        user_id: str,",
    "        page_size: int = 20",
    "    ) -> List[Post]:",
    "        \"\"\"Get all posts by a specific user.\"\"\"",
    "        return self._post_service.get_user_posts(user_id, page_size)",
    "    ",
    "    def follow_user(self, follower_id: str, followee_id: str) -> bool:",
    "        \"\"\"Follow a user.\"\"\"",
    "        success = self._social_graph.follow(follower_id, followee_id)",
    "        if success:",
    "            # Update follower counts",
    "            if followee_id in self._users:",
    "                self._users[followee_id].follower_count += 1",
    "                self._users[followee_id].update_celebrity_status()",
    "            if follower_id in self._users:",
    "                self._users[follower_id].following_count += 1",
    "        return success",
    "    ",
    "    def like_post(self, user_id: str, post_id: str) -> int:",
    "        \"\"\"Like a post. Returns new like count.\"\"\"",
    "        return self._like_service.like_post(user_id, post_id)",
    "",
    "",
    "# ============================================================================",
    "# DEMONSTRATION",
    "# ============================================================================",
    "",
    "if __name__ == '__main__':",
    "    print(\"=\"*70)",
    "    print(\"        INSTAGRAM SYSTEM DESIGN - DEMONSTRATION\")",
    "    print(\"=\"*70)",
    "    print()",
    "    ",
    "    # Initialize system",
    "    instagram = InstagramSystem()",
    "    ",
    "    # Create users",
    "    print(\"\ud83d\udcf1 Creating users...\")",
    "    alice = instagram.create_user(\"alice\", \"alice@email.com\")",
    "    bob = instagram.create_user(\"bob\", \"bob@email.com\")",
    "    celebrity = instagram.create_user(\"celebrity_kim\", \"kim@email.com\")",
    "    print(f\"   Created: {alice.username}, {bob.username}, {celebrity.username}\")",
    "    print()",
    "    ",
    "    # Simulate celebrity having many followers",
    "    celebrity.follower_count = 350_000_000  # 350M followers",
    "    celebrity.update_celebrity_status()",
    "    print(f\"\ud83d\udc51 {celebrity.username} is a celebrity with {celebrity.follower_count:,} followers\")",
    "    print(f\"   is_celebrity: {celebrity.is_celebrity}\")",
    "    print()",
    "    ",
    "    # Follow relationships",
    "    print(\"\ud83d\udc65 Setting up follow relationships...\")",
    "    instagram.follow_user(alice.user_id, bob.user_id)",
    "    instagram.follow_user(alice.user_id, celebrity.user_id)",
    "    print(f\"   {alice.username} follows {bob.username}\")",
    "    print(f\"   {alice.username} follows {celebrity.username}\")",
    "    print()",
    "    ",
    "    # Bob uploads a photo (normal fan-out)",
    "    print(\"\ud83d\udcf8 Bob uploads a photo (normal user - will fan-out)...\")",
    "    bob_post_id = instagram.upload_photo(",
    "        bob.user_id,",
    "        b\"photo_bytes_here\",",
    "        \"Beautiful sunset! #nature #photography\",",
    "        [\"nature\", \"photography\"],",
    "        Location(lat=34.05, lng=-118.24)",
    "    )",
    "    print(f\"   Post created: {bob_post_id}\")",
    "    print()",
    "    ",
    "    # Celebrity uploads a photo (no fan-out - pull based)",
    "    print(\"\ud83d\udcf8 Celebrity uploads a photo (will NOT fan-out to 350M)...\")",
    "    celeb_post_id = instagram.upload_photo(",
    "        celebrity.user_id,",
    "        b\"luxury_photo_bytes\",",
    "        \"New collection drop! #fashion\",",
    "        [\"fashion\"]",
    "    )",
    "    print(f\"   Post created: {celeb_post_id}\")",
    "    print(f\"   \u26a1 Celebrity post marked for PULL (not fanned out)\")",
    "    print()",
    "    ",
    "    # Alice views her feed",
    "    print(\"\ud83d\udcf0 Alice views her feed...\")",
    "    feed = instagram.get_news_feed(alice.user_id, page_size=10)",
    "    print(f\"   Found {len(feed.posts)} posts in feed:\")",
    "    for post in feed.posts:",
    "        print(f\"     - {post.post_id[:8]}... by {post.user_id[:8]}... : {post.caption[:30]}...\")",
    "    print()",
    "    ",
    "    # Like a post",
    "    print(\"\u2764\ufe0f  Alice likes Bob's post...\")",
    "    like_count = instagram.like_post(alice.user_id, bob_post_id)",
    "    print(f\"   New like count: {like_count}\")",
    "    print()",
    "    ",
    "    # View Bob's timeline",
    "    print(\"\ud83d\udc64 Viewing Bob's timeline...\")",
    "    timeline = instagram.get_user_timeline(bob.user_id)",
    "    print(f\"   Bob has {len(timeline)} posts\")",
    "    print()",
    "    ",
    "    print(\"=\"*70)",
    "    print(\"                    ARCHITECTURE SUMMARY\")",
    "    print(\"=\"*70)",
    "    print(\"\"\"",
    "    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510",
    "    \u2502                  HYBRID FAN-OUT MODEL                          \u2502",
    "    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524",
    "    \u2502                                                                 \u2502",
    "    \u2502   Normal Users (<10K followers): FAN-OUT ON WRITE             \u2502",
    "    \u2502   \u251c\u2500\u2500 Post is pushed to all follower feeds immediately        \u2502",
    "    \u2502   \u251c\u2500\u2500 O(followers) write operations                           \u2502",
    "    \u2502   \u2514\u2500\u2500 O(1) read - just fetch pre-computed feed                \u2502",
    "    \u2502                                                                 \u2502",
    "    \u2502   Celebrities (>10K followers): FAN-OUT ON READ               \u2502",
    "    \u2502   \u251c\u2500\u2500 Post is stored but NOT pushed to followers              \u2502",
    "    \u2502   \u251c\u2500\u2500 O(1) write operation                                    \u2502",
    "    \u2502   \u2514\u2500\u2500 O(celebrity_followees) read - merge at read time        \u2502",
    "    \u2502                                                                 \u2502",
    "    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518",
    "    \"\"\")",
    "    print(\"\u2705 Demo complete!\")"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.util.concurrent.*;",
    "import java.time.Instant;",
    "",
    "/**",
    " * Instagram System Design - Java Implementation",
    " * ",
    " * Core components:",
    " * - Photo Upload Service",
    " * - Hybrid Feed Generation (Push + Pull)",
    " * - Social Graph Management",
    " * - CDN Integration",
    " */",
    "public class InstagramSystem {",
    "    ",
    "    private static final int CELEBRITY_THRESHOLD = 10000;",
    "    ",
    "    // Data Models",
    "    record Location(double lat, double lng) {}",
    "    ",
    "    record ImageUrls(",
    "        String thumbnail,",
    "        String small,",
    "        String medium,",
    "        String large,",
    "        String original",
    "    ) {}",
    "    ",
    "    record User(",
    "        String userId,",
    "        String username,",
    "        String email,",
    "        int followerCount,",
    "        int followingCount,",
    "        boolean isCelebrity",
    "    ) {",
    "        public User withFollowerCount(int count) {",
    "            return new User(userId, username, email, count, followingCount,",
    "                           count >= CELEBRITY_THRESHOLD);",
    "        }",
    "    }",
    "    ",
    "    record Post(",
    "        String postId,",
    "        String userId,",
    "        String caption,",
    "        ImageUrls imageUrls,",
    "        List<String> tags,",
    "        Location location,",
    "        long createdAt,",
    "        boolean isFromCelebrity",
    "    ) {}",
    "    ",
    "    record FeedItem(",
    "        String postId,",
    "        String userId,",
    "        long timestamp,",
    "        double relevanceScore",
    "    ) implements Comparable<FeedItem> {",
    "        @Override",
    "        public int compareTo(FeedItem other) {",
    "            return Long.compare(other.timestamp, this.timestamp);",
    "        }",
    "    }",
    "    ",
    "    record FeedResponse(",
    "        List<Post> posts,",
    "        String nextCursor,",
    "        boolean hasMore",
    "    ) {}",
    "    ",
    "    // Storage Components (Simulated)",
    "    private final Map<String, byte[]> blobStorage = new ConcurrentHashMap<>();",
    "    private final Map<String, Object> cache = new ConcurrentHashMap<>();",
    "    private final Map<String, TreeSet<FeedItem>> feedCache = new ConcurrentHashMap<>();",
    "    ",
    "    // Data Stores",
    "    private final Map<String, User> users = new ConcurrentHashMap<>();",
    "    private final Map<String, Post> posts = new ConcurrentHashMap<>();",
    "    private final Map<String, List<String>> userPosts = new ConcurrentHashMap<>();",
    "    ",
    "    // Social Graph",
    "    private final Map<String, Set<String>> following = new ConcurrentHashMap<>();",
    "    private final Map<String, Set<String>> followers = new ConcurrentHashMap<>();",
    "    private final Set<String> celebrities = ConcurrentHashMap.newKeySet();",
    "    ",
    "    // Message Queue (simulated)",
    "    private final ExecutorService fanoutWorkers = Executors.newFixedThreadPool(4);",
    "    ",
    "    /**",
    "     * Upload a photo and create a post.",
    "     */",
    "    public String uploadPhoto(",
    "            String userId,",
    "            byte[] photo,",
    "            String caption,",
    "            List<String> tags,",
    "            Location location) {",
    "        ",
    "        String postId = UUID.randomUUID().toString();",
    "        long timestamp = Instant.now().toEpochMilli();",
    "        ",
    "        // Store original to blob storage",
    "        String blobKey = userId + \"/\" + postId + \"/original.jpg\";",
    "        blobStorage.put(blobKey, photo);",
    "        ",
    "        // Generate image URLs (async in production)",
    "        String cdnBase = \"https://cdn.instagram.com/\";",
    "        ImageUrls imageUrls = new ImageUrls(",
    "            cdnBase + postId + \"_150.jpg\",",
    "            cdnBase + postId + \"_320.jpg\",",
    "            cdnBase + postId + \"_640.jpg\",",
    "            cdnBase + postId + \"_1080.jpg\",",
    "            cdnBase + blobKey",
    "        );",
    "        ",
    "        // Check if poster is celebrity",
    "        int followerCount = getFollowerCount(userId);",
    "        boolean isCelebrity = followerCount >= CELEBRITY_THRESHOLD;",
    "        ",
    "        // Create post",
    "        Post post = new Post(",
    "            postId, userId, caption, imageUrls,",
    "            tags, location, timestamp, isCelebrity",
    "        );",
    "        ",
    "        posts.put(postId, post);",
    "        userPosts.computeIfAbsent(userId, k -> new ArrayList<>()).add(0, postId);",
    "        ",
    "        // Fan-out decision",
    "        if (isCelebrity) {",
    "            celebrities.add(userId);",
    "            cache.put(\"celebrity-latest:\" + userId, postId);",
    "        } else {",
    "            fanoutToFollowers(postId, userId, timestamp);",
    "        }",
    "        ",
    "        return postId;",
    "    }",
    "    ",
    "    /**",
    "     * Fan-out post to all followers' feeds (async).",
    "     */",
    "    private void fanoutToFollowers(String postId, String userId, long timestamp) {",
    "        Set<String> followerSet = followers.getOrDefault(userId, Set.of());",
    "        ",
    "        fanoutWorkers.submit(() -> {",
    "            for (String followerId : followerSet) {",
    "                feedCache.computeIfAbsent(followerId, k -> new TreeSet<>())",
    "                        .add(new FeedItem(postId, userId, timestamp, 0.0));",
    "            }",
    "        });",
    "    }",
    "    ",
    "    /**",
    "     * Get personalized news feed using hybrid approach.",
    "     */",
    "    public FeedResponse getNewsFeed(String userId, int pageSize, String cursor) {",
    "        int startIdx = cursor != null ? Integer.parseInt(cursor) : 0;",
    "        ",
    "        // Step 1: Get pre-computed feed (pushed posts)",
    "        TreeSet<FeedItem> precomputedFeed = feedCache.getOrDefault(",
    "            userId, new TreeSet<>()",
    "        );",
    "        ",
    "        // Step 2: Pull celebrity posts",
    "        List<FeedItem> celebrityPosts = pullCelebrityPosts(userId);",
    "        ",
    "        // Step 3: Merge all posts",
    "        TreeSet<FeedItem> merged = new TreeSet<>(precomputedFeed);",
    "        merged.addAll(celebrityPosts);",
    "        ",
    "        // Step 4: Paginate",
    "        List<FeedItem> items = new ArrayList<>(merged);",
    "        int endIdx = Math.min(startIdx + pageSize, items.size());",
    "        List<FeedItem> pageItems = items.subList(startIdx, endIdx);",
    "        ",
    "        // Step 5: Hydrate posts",
    "        List<Post> feedPosts = pageItems.stream()",
    "            .map(item -> posts.get(item.postId()))",
    "            .filter(Objects::nonNull)",
    "            .toList();",
    "        ",
    "        String nextCursor = endIdx < items.size() ? String.valueOf(endIdx) : null;",
    "        ",
    "        return new FeedResponse(feedPosts, nextCursor, nextCursor != null);",
    "    }",
    "    ",
    "    /**",
    "     * Pull recent posts from celebrities that user follows.",
    "     */",
    "    private List<FeedItem> pullCelebrityPosts(String userId) {",
    "        Set<String> followingSet = following.getOrDefault(userId, Set.of());",
    "        List<FeedItem> pulled = new ArrayList<>();",
    "        ",
    "        for (String followeeId : followingSet) {",
    "            if (celebrities.contains(followeeId)) {",
    "                List<String> celebPosts = userPosts.getOrDefault(",
    "                    followeeId, List.of()",
    "                );",
    "                for (String postId : celebPosts.subList(0, Math.min(5, celebPosts.size()))) {",
    "                    Post post = posts.get(postId);",
    "                    if (post != null) {",
    "                        pulled.add(new FeedItem(",
    "                            postId, followeeId, post.createdAt(), 0.0",
    "                        ));",
    "                    }",
    "                }",
    "            }",
    "        }",
    "        return pulled;",
    "    }",
    "    ",
    "    /**",
    "     * Follow a user.",
    "     */",
    "    public boolean followUser(String followerId, String followeeId) {",
    "        Set<String> followingSet = following.computeIfAbsent(",
    "            followerId, k -> ConcurrentHashMap.newKeySet()",
    "        );",
    "        ",
    "        if (followingSet.contains(followeeId)) {",
    "            return false;",
    "        }",
    "        ",
    "        followingSet.add(followeeId);",
    "        followers.computeIfAbsent(followeeId, k -> ConcurrentHashMap.newKeySet())",
    "                 .add(followerId);",
    "        ",
    "        return true;",
    "    }",
    "    ",
    "    public int getFollowerCount(String userId) {",
    "        return followers.getOrDefault(userId, Set.of()).size();",
    "    }",
    "    ",
    "    public List<Post> getUserTimeline(String userId, int limit) {",
    "        List<String> postIds = userPosts.getOrDefault(userId, List.of());",
    "        return postIds.stream()",
    "            .limit(limit)",
    "            .map(posts::get)",
    "            .filter(Objects::nonNull)",
    "            .toList();",
    "    }",
    "    ",
    "    // Demo",
    "    public static void main(String[] args) {",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println(\"     INSTAGRAM SYSTEM DESIGN - JAVA DEMO\");",
    "        System.out.println(\"=\".repeat(60));",
    "        ",
    "        InstagramSystem ig = new InstagramSystem();",
    "        ",
    "        // Create relationships",
    "        String alice = \"user_alice\";",
    "        String bob = \"user_bob\";",
    "        String celebrity = \"user_celebrity\";",
    "        ",
    "        // Simulate celebrity followers",
    "        for (int i = 0; i < 15000; i++) {",
    "            ig.followers.computeIfAbsent(celebrity, k -> ConcurrentHashMap.newKeySet())",
    "                       .add(\"follower_\" + i);",
    "        }",
    "        ",
    "        ig.followUser(alice, bob);",
    "        ig.followUser(alice, celebrity);",
    "        ",
    "        // Upload photos",
    "        String bobPost = ig.uploadPhoto(",
    "            bob, \"photo\".getBytes(), \"Hello World!\",",
    "            List.of(\"hello\"), null",
    "        );",
    "        System.out.println(\"Bob's post (fanned out): \" + bobPost);",
    "        ",
    "        String celebPost = ig.uploadPhoto(",
    "            celebrity, \"glamour\".getBytes(), \"New drop!\",",
    "            List.of(\"fashion\"), null",
    "        );",
    "        System.out.println(\"Celebrity's post (pull-based): \" + celebPost);",
    "        System.out.println(\"Celebrity status: \" + ig.celebrities.contains(celebrity));",
    "        ",
    "        // Get feed",
    "        try { Thread.sleep(100); } catch (Exception e) {}",
    "        FeedResponse feed = ig.getNewsFeed(alice, 10, null);",
    "        System.out.println(\"\\nAlice's feed has \" + feed.posts().size() + \" posts\");",
    "        ",
    "        for (Post post : feed.posts()) {",
    "            System.out.println(\"  - \" + post.caption() + \" (by \" + post.userId() + \")\");",
    "        }",
    "        ",
    "        ig.fanoutWorkers.shutdown();",
    "        System.out.println(\"\\n\u2705 Demo complete!\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-20",
      "section": "Data Models",
      "explanation": "We define core entities: `User`, `Post`, `FeedItem`, `Location`, `ImageUrls`. Using dataclasses (Python) or records (Java) for immutability and clean code. `FeedItem` implements comparison for sorting feeds by timestamp."
    },
    {
      "lines": "100-150",
      "section": "SocialGraphService",
      "explanation": "Manages follower/following relationships. Uses bidirectional adjacency lists. In production, this would be Cassandra with partition key = user_id. The `get_followers` method is critical for fan-out decisions."
    },
    {
      "lines": "200-280",
      "section": "FeedService - Core Hybrid Logic",
      "explanation": "**This is the heart of Instagram's architecture.** `on_new_post` decides push vs pull based on follower count. `get_feed` merges pre-computed feed with pulled celebrity posts. The 10K threshold balances write and read costs."
    },
    {
      "lines": "280-320",
      "section": "Fan-out Processing",
      "explanation": "`_process_fanout` is called asynchronously via message queue. For each follower, adds post to their Redis sorted set (feed). This is O(followers) but happens in background workers, not blocking the upload."
    },
    {
      "lines": "320-350",
      "section": "Celebrity Pull Logic",
      "explanation": "`_pull_celebrity_posts` is called at read time. Only queries celebrities user follows (typically few). Posts are hot in cache. This shifts work from write (1 celebrity) to read (millions of readers, but amortized)."
    },
    {
      "lines": "400-450",
      "section": "UploadService",
      "explanation": "Orchestrates photo upload: stores to S3, creates post metadata, enqueues thumbnail generation, triggers feed fan-out. Returns post_id immediately - all processing is async. Target: <2s response time."
    },
    {
      "lines": "500-550",
      "section": "Main Demo",
      "explanation": "Demonstrates the full flow: create users, set up follows, simulate celebrity (350M followers), upload photos (normal vs celebrity), view feed showing hybrid merge. Proves the architecture handles both cases."
    }
  ],
  "complexity_analysis": {
    "time": {
      "uploadPhoto": {
        "complexity": "O(1) for celebrities, O(followers) for normal users (async)",
        "explanation": "Celebrity posts: O(1) - just store and mark. Normal users: O(followers) fan-out, but executed async in worker pool, not blocking API response."
      },
      "getNewsFeed": {
        "complexity": "O(page_size + celebrity_followees \u00d7 posts_per_celebrity)",
        "explanation": "Pre-computed feed: O(page_size) from sorted set. Celebrity pull: O(C \u00d7 P) where C = celebrity followees (typically <100), P = posts per celebrity (5-10). Total: effectively O(1) with small constants."
      },
      "followUser": {
        "complexity": "O(1)",
        "explanation": "HashMap/Set operations. In production, also triggers async backfill of recent posts to new follower's feed."
      },
      "getUserTimeline": {
        "complexity": "O(page_size)",
        "explanation": "Direct lookup from user_posts list, then batch fetch post objects."
      },
      "overall": "All operations are O(1) or O(page_size) from user perspective. Fan-out is async."
    },
    "space": {
      "complexity": "O(U \u00d7 F + P \u00d7 R + C \u00d7 P)",
      "breakdown": "- **U \u00d7 F**: User feeds (U users \u00d7 F average feed size ~500 items)\n- **P \u00d7 R**: Post storage (P posts \u00d7 R resolutions ~4)\n- **C \u00d7 P**: Celebrity post cache (C celebrities \u00d7 P recent posts)\n- **Social Graph**: O(E) where E = total follow edges",
      "note": "Feed duplication is significant but enables O(1) reads. Trade-off: storage vs latency."
    },
    "can_we_do_better": "The hybrid approach IS the optimal solution for this problem. Pure push fails for celebrities, pure pull fails for latency. The 10K threshold can be dynamically tuned based on engagement metrics."
  },
  "dry_run": {
    "example": "Alice follows Bob and Celebrity. Bob posts (200 followers). Celebrity posts (10M followers). Alice opens feed.",
    "trace_table": "| Step | Actor | Action | Fan-out Strategy | Feed Cache (Alice) | Celebrity Cache |\n|------|-------|--------|------------------|--------------------|-----------------|\n| 1 | Alice | follow(Bob) | - | [] | - |\n| 2 | Alice | follow(Celebrity) | - | [] | - |\n| 3 | Bob | uploadPhoto() | PUSH (200 followers) | [bob_post_1] | - |\n| 4 | Celebrity | uploadPhoto() | PULL (skip fan-out) | [bob_post_1] | {celebrity: celeb_post_1} |\n| 5 | Alice | getNewsFeed() | Merge push + pull | [bob_post_1] + [celeb_post_1] | - |\n| Result | Alice sees both posts: bob_post_1, celeb_post_1 sorted by time |",
    "final_answer": "Alice's feed contains both posts despite different fan-out strategies. Bob's post was pushed to her feed cache. Celebrity's post was pulled at read time and merged."
  },
  "test_cases": [
    {
      "name": "Basic Upload and Feed",
      "category": "Happy Path",
      "input": "Alice follows Bob. Bob uploads photo. Alice gets feed.",
      "expected": "Alice's feed contains Bob's post",
      "explanation": "Normal fan-out: Bob's post pushed to Alice's feed on upload."
    },
    {
      "name": "Celebrity Hybrid",
      "category": "Core Feature",
      "input": "Alice follows Celebrity (10M followers). Celebrity posts. Alice gets feed.",
      "expected": "Alice's feed contains Celebrity's post (via pull)",
      "explanation": "Celebrity post NOT fanned out. Pulled when Alice requests feed."
    },
    {
      "name": "Mixed Feed",
      "category": "Integration",
      "input": "Alice follows 5 normal users and 2 celebrities. All post.",
      "expected": "Feed contains all 7 posts, sorted by time",
      "explanation": "5 pushed posts + 2 pulled posts merged at read time."
    },
    {
      "name": "Unfollow Stale Data",
      "category": "Edge Case",
      "input": "Alice follows Bob. Bob posts. Alice unfollows. Alice gets feed.",
      "expected": "Bob's old post MAY still appear (eventual consistency)",
      "explanation": "Feed is eventually consistent. Old posts may linger until feed refresh."
    },
    {
      "name": "Celebrity Threshold Boundary",
      "category": "Edge Case",
      "input": "User has 9999 followers (push). Gets 10000th follower. Posts.",
      "expected": "Post still fans out (threshold check at post time)",
      "explanation": "Celebrity status determined at upload time, not continuously."
    },
    {
      "name": "Empty Feed",
      "category": "Edge Case",
      "input": "New user follows nobody. Gets feed.",
      "expected": "Empty feed response with no cursor",
      "explanation": "Handle gracefully, possibly show Explore content."
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Using only fan-out on write for ALL users",
      "why_wrong": "Celebrity with 500M followers = 500M writes per post = 5+ minutes at 1M/sec. Completely breaks latency SLA.",
      "correct_approach": "Hybrid: Push for normal (<10K followers), Pull for celebrities",
      "code_wrong": "# Fan out to ALL followers regardless\nfor follower in get_all_followers(poster):\n    add_to_feed(follower, post)",
      "code_correct": "if follower_count < 10000:\n    fan_out_to_all()\nelse:\n    mark_for_pull()"
    },
    {
      "mistake": "Storing images in database",
      "why_wrong": "200TB/day cannot go in relational DB. Blob storage is 10x cheaper, designed for this. CDN integration is native.",
      "correct_approach": "Store in S3/GCS, serve via CDN, only store metadata in DB",
      "code_wrong": "INSERT INTO posts (photo_blob BYTEA) VALUES ($1)",
      "code_correct": "s3.upload(key, photo)\nINSERT INTO posts (photo_url) VALUES ($1)"
    },
    {
      "mistake": "Computing feed on every read",
      "why_wrong": "User follows 1000 accounts. Query each for recent posts = 1000 queries per feed load. Latency: 5+ seconds.",
      "correct_approach": "Pre-compute feeds on write, cache in Redis sorted sets",
      "code_wrong": "def get_feed(user):\n    posts = []\n    for followee in get_following(user):\n        posts.extend(db.query(followee))\n    return sort(posts)",
      "code_correct": "def get_feed(user):\n    return redis.zrange(f'feed:{user}', 0, 20)"
    },
    {
      "mistake": "Not handling viral posts (hot spots)",
      "why_wrong": "Post gets 1M views/minute. Single post row becomes hot partition. DB/cache node overwhelmed.",
      "correct_approach": "Replicate hot content to multiple cache nodes, use probabilistic caching",
      "code_wrong": "post = cache.get(post_id)  # Single node",
      "code_correct": "shard = hash(post_id + random(10))  # Spread load\npost = cache.get(f'{post_id}:{shard}')"
    },
    {
      "mistake": "Synchronous image processing",
      "why_wrong": "Generating 4 thumbnail sizes takes 2-5 seconds. User waits. Upload feels slow.",
      "correct_approach": "Async processing via message queue. Return post ID immediately.",
      "code_wrong": "post_id = create_post()\ngenerate_thumbnails()  # Blocks!\nreturn post_id",
      "code_correct": "post_id = create_post()\nqueue.publish('thumbnails', post_id)  # Async\nreturn post_id  # Immediate response"
    }
  ],
  "interview_tips": {
    "opening": "Thank you for the problem. Before diving into the design, I'd like to clarify the requirements and constraints. First, what's the expected scale - daily active users and photos uploaded per day? Is the feed chronological or relevance-based? Are we supporting just photos or also videos? This will help me make informed trade-offs.",
    "clarifying_questions_to_ask": [
      "**Scale**: How many DAU? Photos/day? (Reveals: need sharding strategy)",
      "**Feed Algorithm**: Chronological or ML-ranked? (Reveals: ranking service needed)",
      "**Geography**: Global or single region? (Reveals: multi-region replication)",
      "**Privacy**: Public/private accounts? (Reveals: access control layer)",
      "**Latency**: What's acceptable feed load time? (Reveals: caching requirements)",
      "**Consistency**: Is eventual consistency OK for feeds? (Reveals: can use async fan-out)",
      "**Features**: Stories? DMs? Explore? (Reveals: scope boundaries)"
    ],
    "what_to_mention_proactively": [
      "**The Celebrity Problem**: 'Users with 500M followers pose a fan-out challenge. I'll use a hybrid push/pull approach.'",
      "**CDN for Images**: 'Photos are immutable. I'll store in S3 and serve via CDN with 1-year cache headers.'",
      "**Eventual Consistency**: 'Feed doesn't need strong consistency. I'll use async fan-out for speed.'",
      "**Back-of-envelope Math**: '100M photos \u00d7 2MB = 200TB/day. That's 73PB/year. Object storage is essential.'"
    ],
    "communication_during_coding": [
      "**Start with requirements gathering** before any architecture",
      "**Draw high-level first** - boxes for major services, then dive into one",
      "**Mention trade-offs** - 'I'm choosing X because of Y, accepting downside Z'",
      "**Estimate numbers** - 'At 100K requests/sec, we need N servers'",
      "**Identify bottlenecks** - 'The feed service is the hottest path, let me detail that'"
    ],
    "if_stuck": [
      "**Go back to requirements**: 'Let me revisit what we're optimizing for - latency or storage?'",
      "**Use first principles**: 'If I had infinite resources, how would I do this? Now let's constrain.'",
      "**Ask for hints**: 'What aspect would you like me to focus on - the data model or the service interaction?'",
      "**Start simple**: 'Let me design for 1000 users first, then scale up.'"
    ],
    "time_management": "**0-8min**: Requirements & Clarification | **8-15min**: High-level Architecture | **15-35min**: Deep dive (Feed/Upload) | **35-45min**: Data Model & Scaling | **45-55min**: Edge Cases & Trade-offs | **55-60min**: Questions for Interviewer"
  },
  "pattern_recognition": {
    "pattern_name": "Social Media Feed Architecture with Hybrid Fan-out",
    "indicators": [
      "News feed or timeline requirement",
      "Follow/friend relationships",
      "High read:write ratio (100:1)",
      "Celebrity/influencer accounts",
      "Real-time or near-real-time updates"
    ],
    "similar_problems": [
      "**Design Twitter** - Similar feed + hybrid fan-out, but more text-focused",
      "**Design Facebook News Feed** - Same pattern, more complex ranking",
      "**Design LinkedIn Feed** - Professional network + similar fan-out",
      "**Design TikTok** - More ML ranking, less social graph"
    ],
    "template": "1. Identify celebrities (>N followers)\n2. Push for normal users on write\n3. Store celebrity posts separately\n4. Pull celebrity posts on read\n5. Merge and rank at response time\n6. Cache aggressively, CDN for media"
  },
  "follow_up_preparation": {
    "part_2_hint": "**Stories Feature (24-hour ephemeral)**: Adds TTL-based storage, ring-buffer display, different access pattern (view once). Key insight: Use Redis with EXPIRE, separate from main feed.",
    "part_3_hint": "**Search and Explore**: Full-text search (Elasticsearch), content-based recommendations, trending hashtags. Key insight: Inverted index for hashtags, ML model for personalization.",
    "part_4_hint": "**Direct Messaging (DMs)**: Real-time delivery (WebSocket), end-to-end encryption, read receipts. Key insight: Connection state management, message queue per conversation.",
    "data_structure_evolution": "Part 1: Feed (sorted sets) + Posts (K-V) + Social Graph (adjacency lists)\n\u2192 Part 2: Add TTL-based ring buffer for Stories\n\u2192 Part 3: Add Elasticsearch for search\n\u2192 Part 4: Add WebSocket manager + message queues for DMs"
  },
  "generated_at": "2026-01-14T15:28:06.296722",
  "_meta": {
    "problem_id": "instagram_photo_sharing_design",
    "part_number": null,
    "model": "claude-opus-4-5-20251101"
  }
}