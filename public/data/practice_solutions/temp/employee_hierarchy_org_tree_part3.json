{
  "problem_title": "Employee Hierarchy / Org Tree - Part 3: Generic Aggregation & Filtering",
  "part_number": 3,
  "builds_on": "Part 2",
  "difficulty": "hard",
  "problem_understanding": {
    "what_changes": "Part 3 transforms our rigid, single-purpose aggregation from Part 2 into a **flexible, generic analytics engine**. Instead of hard-coded 'best performing team' logic, we now support ANY grouping key (department, level, location), ANY value extractor (salary, rating, tenure), and ANY aggregation function (SUM, AVG, MIN, MAX, COUNT). This is essentially building a mini SQL GROUP BY engine on top of our org tree.",
    "new_requirements": [
      "Extended Employee model with department, level, and salary fields",
      "Generic groupByAggregate() accepting functional interfaces for key/value extraction",
      "filterGroupByAggregate() with predicate-based filtering before aggregation",
      "Support for 5 aggregation types: SUM, AVG, MIN, MAX, COUNT",
      "Single-pass O(n) processing through all employees"
    ],
    "new_constraints": [
      "Must handle empty groups gracefully (return 0 or skip)",
      "AVG aggregation requires tracking both sum and count per group",
      "Function parameters must be flexible (support both lambdas and string field names for testing)",
      "Results should use double precision for all numeric aggregations"
    ],
    "key_insight": "**The key insight is that groupBy + aggregate follows a predictable pattern: collect \u2192 partition \u2192 reduce.** By using a HashMap<String, List<Double>> as an intermediate accumulator, we can collect all values per group in a single pass, then apply any aggregation function uniformly. This is exactly how SQL GROUP BY works under the hood and mirrors Java Streams' collect/groupingBy pattern."
  },
  "visual_explanation": {
    "before_after": "```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    BEFORE (Part 2) vs AFTER (Part 3)               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                    \u2551\n\u2551  PART 2: Hard-coded aggregation                                    \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                   \u2551\n\u2551  \u2502 getBestPerformingTeam()     \u2502 \u2192 Fixed: rating, team scope       \u2551\n\u2551  \u2502 getTeamAverageRating()      \u2502 \u2192 Fixed: AVG only, rating only    \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2551\n\u2551                                                                    \u2551\n\u2551  PART 3: Generic, composable operations                            \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2551\n\u2551  \u2502 filterGroupByAggregate(                                     \u2502   \u2551\n\u2551  \u2502   filter:   (emp) \u2192 boolean    \u2190 ANY predicate              \u2502   \u2551\n\u2551  \u2502   keyFn:    (emp) \u2192 string     \u2190 ANY grouping key           \u2502   \u2551\n\u2551  \u2502   valueFn:  (emp) \u2192 double     \u2190 ANY numeric value          \u2502   \u2551\n\u2551  \u2502   aggType:  SUM|AVG|MIN|MAX|COUNT                           \u2502   \u2551\n\u2551  \u2502 )                                                           \u2502   \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2551\n\u2551                                                                    \u2551\n\u2551  Examples of what's now possible:                                  \u2551\n\u2551  \u2022 Total salary by department                                      \u2551\n\u2551  \u2022 Avg rating of level >= 3 engineers                              \u2551\n\u2551  \u2022 Max salary per location                                         \u2551\n\u2551  \u2022 Count employees by level                                        \u2551\n\u2551                                                                    \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n```",
    "algorithm_flow": "```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    GENERIC AGGREGATION PIPELINE                          \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                          \u2551\n\u2551  INPUT: All Employees                                                    \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2551\n\u2551  \u2502 Alice(Eng,L5,$200k) Bob(Eng,L3,$120k) Carol(Sales,L4,$150k)       \u2502   \u2551\n\u2551  \u2502 Dave(Sales,L2,$80k)                                               \u2502   \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2551\n\u2551                               \u2502                                          \u2551\n\u2551                               \u25bc                                          \u2551\n\u2551  STEP 1: FILTER \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2551\n\u2551  \u2502 filter_fn = (emp) \u2192 emp.level >= 3                                \u2502   \u2551\n\u2551  \u2502                                                                   \u2502   \u2551\n\u2551  \u2502 Alice \u2713   Bob \u2713   Carol \u2713   Dave \u2717                                \u2502   \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2551\n\u2551                               \u2502                                          \u2551\n\u2551                               \u25bc                                          \u2551\n\u2551  STEP 2: EXTRACT KEY + VALUE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2551\n\u2551  \u2502 key_fn = (emp) \u2192 emp.department                                   \u2502   \u2551\n\u2551  \u2502 value_fn = (emp) \u2192 emp.salary                                     \u2502   \u2551\n\u2551  \u2502                                                                   \u2502   \u2551\n\u2551  \u2502 Alice  \u2192 (\"Engineering\", 200000)                                  \u2502   \u2551\n\u2551  \u2502 Bob    \u2192 (\"Engineering\", 120000)                                  \u2502   \u2551\n\u2551  \u2502 Carol  \u2192 (\"Sales\", 150000)                                        \u2502   \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2551\n\u2551                               \u2502                                          \u2551\n\u2551                               \u25bc                                          \u2551\n\u2551  STEP 3: GROUP BY KEY \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2551\n\u2551  \u2502 groups = HashMap<String, List<Double>>                            \u2502   \u2551\n\u2551  \u2502                                                                   \u2502   \u2551\n\u2551  \u2502 \"Engineering\" \u2192 [200000, 120000]                                  \u2502   \u2551\n\u2551  \u2502 \"Sales\"       \u2192 [150000]                                          \u2502   \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2551\n\u2551                               \u2502                                          \u2551\n\u2551                               \u25bc                                          \u2551\n\u2551  STEP 4: AGGREGATE PER GROUP \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2551\n\u2551  \u2502 aggType = \"AVG\"                                                   \u2502   \u2551\n\u2551  \u2502                                                                   \u2502   \u2551\n\u2551  \u2502 \"Engineering\" \u2192 AVG([200000, 120000]) = 160000                    \u2502   \u2551\n\u2551  \u2502 \"Sales\"       \u2192 AVG([150000]) = 150000                            \u2502   \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2551\n\u2551                               \u2502                                          \u2551\n\u2551                               \u25bc                                          \u2551\n\u2551  OUTPUT: {\"Engineering\": 160000, \"Sales\": 150000}                        \u2551\n\u2551                                                                          \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n```"
  },
  "approaches": [
    {
      "name": "Naive Extension",
      "description": "Add separate methods for each combination of grouping and aggregation. For example: getSalaryByDepartment(), getRatingByLevel(), getCountByDepartment(). This means N \u00d7 M methods for N group keys and M aggregation types.",
      "time_complexity": "O(n) per method",
      "space_complexity": "O(k) where k = unique keys",
      "why_not_optimal": "Code explosion problem! With 5 groupable fields \u00d7 5 aggregation types = 25 methods. Adding a new field requires 5 new methods. This violates DRY principle and is unmaintainable. The functional approach uses 1 method to handle all combinations."
    },
    {
      "name": "Optimal Approach - Functional Pipeline",
      "description": "Use functional interfaces (lambdas) to parameterize the grouping key, value extraction, and aggregation. Single method handles ALL combinations. Collect values per group using HashMap<String, List<Double>>, then reduce each list using the specified aggregation function.",
      "time_complexity": "O(n) for both groupByAggregate and filterGroupByAggregate",
      "space_complexity": "O(n) worst case for groups HashMap + values lists",
      "key_insight": "**Composition over enumeration.** Instead of writing methods for every combination, compose a single generic method from three orthogonal functions: filter, key-extract, value-extract. This is the same insight behind SQL and MapReduce."
    }
  ],
  "optimal_solution": {
    "explanation_md": "## Optimal Solution: Functional Pipeline Aggregation\n\n### Core Insight\nThe solution implements a **stream-like pipeline** pattern:\n1. **Filter** - Select which employees to include\n2. **Map/Extract** - Pull out the grouping key and numeric value\n3. **Collect/GroupBy** - Partition values into groups\n4. **Reduce/Aggregate** - Apply aggregation function per group\n\n### Implementation Strategy\n\n**Step 1: Collect Phase**\n```\ngroups = defaultdict(list)\nfor employee in employees:\n    if filter_fn(employee):           # Filter\n        key = key_fn(employee)        # Extract key\n        value = value_fn(employee)    # Extract value\n        groups[key].append(value)     # Collect\n```\n\n**Step 2: Reduce Phase**\n```\nresult = {}\nfor key, values in groups.items():\n    result[key] = aggregate(values, agg_type)  # Reduce\n```\n\n### Key Design Decisions\n\n1. **Two-Phase Processing**: We use a collect-then-reduce approach rather than online aggregation because AVG requires knowing the count, which isn't available until all values are collected.\n\n2. **Flexible Function Resolution**: Support both actual lambda functions (for production use) AND string field names (for testing/serialization).\n\n3. **Unified Method**: `groupByAggregate` simply calls `filterGroupByAggregate` with a pass-all filter, avoiding code duplication.\n\n4. **Type Safety**: All values converted to float/double for uniform aggregation handling.\n\n### Why This Works\n- **O(n) time**: Single pass through employees for collection, single pass through groups for reduction\n- **O(n) space**: Worst case all employees in one group\n- **Extensible**: Add new aggregations by modifying only `_apply_aggregation`\n- **Composable**: Any filter \u00d7 any grouping \u00d7 any value \u00d7 any aggregation",
    "data_structures": [
      {
        "structure": "HashMap<Integer, Employee>",
        "purpose": "O(1) employee lookup by ID"
      },
      {
        "structure": "HashMap<String, List<Double>>",
        "purpose": "Intermediate accumulator to collect values per group"
      },
      {
        "structure": "Function/Predicate interfaces",
        "purpose": "Parameterize the pipeline stages"
      }
    ],
    "algorithm_steps": [
      "Step 1: Initialize empty groups HashMap<String, List<Double>>",
      "Step 2: Iterate through all employees in self.employees",
      "Step 3: Apply filter predicate - skip if returns False",
      "Step 4: Extract grouping key using key_fn",
      "Step 5: Extract numeric value using value_fn",
      "Step 6: Append value to groups[key] list",
      "Step 7: Initialize result HashMap<String, Double>",
      "Step 8: For each group, apply aggregation function to its values list",
      "Step 9: Return result map"
    ]
  },
  "solution_python_lines": [
    "\"\"\"",
    "Employee Hierarchy / Org Tree - Part 3: Generic Aggregation & Filtering",
    "",
    "This module implements a flexible organizational chart with generic",
    "group-by aggregation capabilities, similar to SQL GROUP BY operations.",
    "\"\"\"",
    "",
    "from typing import Dict, List, Optional, Callable, Union, Any",
    "from collections import defaultdict",
    "from dataclasses import dataclass, field",
    "",
    "",
    "@dataclass",
    "class Employee:",
    "    \"\"\"",
    "    Extended Employee class with department, level, and salary.",
    "    ",
    "    Attributes:",
    "        id: Unique employee identifier",
    "        name: Employee's full name",
    "        rating: Performance rating (1-10)",
    "        department: Department name (e.g., 'Engineering', 'Sales')",
    "        level: Seniority level (1=junior, 5=exec)",
    "        salary: Annual salary",
    "        manager_id: ID of manager, None for CEO",
    "        subordinates: List of direct reports",
    "    \"\"\"",
    "    id: int",
    "    name: str",
    "    rating: int",
    "    department: str = \"\"",
    "    level: int = 1",
    "    salary: float = 0.0",
    "    manager_id: Optional[int] = None",
    "    subordinates: List['Employee'] = field(default_factory=list)",
    "",
    "",
    "class OrgChart:",
    "    \"\"\"",
    "    Organizational Chart with generic aggregation and filtering.",
    "    ",
    "    Supports flexible analytics queries using functional composition:",
    "    - Group employees by any attribute",
    "    - Aggregate using SUM, AVG, MIN, MAX, COUNT",
    "    - Filter employees before aggregation",
    "    ",
    "    Example:",
    "        >>> org = OrgChart()",
    "        >>> org.add_employee_extended(1, 'Alice', 8, 'Engineering', 5, 200000, None)",
    "        >>> org.group_by_aggregate(",
    "        ...     lambda e: e.department,",
    "        ...     lambda e: e.salary,",
    "        ...     'SUM'",
    "        ... )",
    "        {'Engineering': 200000.0}",
    "    \"\"\"",
    "    ",
    "    # Field accessor mappings for string-based queries (testing support)",
    "    _KEY_EXTRACTORS: Dict[str, Callable[['Employee'], str]] = {",
    "        'department': lambda e: e.department,",
    "        'level': lambda e: str(e.level),",
    "        'name': lambda e: e.name,",
    "    }",
    "    ",
    "    _VALUE_EXTRACTORS: Dict[str, Callable[['Employee'], float]] = {",
    "        'salary': lambda e: e.salary,",
    "        'rating': lambda e: float(e.rating),",
    "        'level': lambda e: float(e.level),",
    "    }",
    "    ",
    "    def __init__(self) -> None:",
    "        \"\"\"Initialize an empty organizational chart.\"\"\"",
    "        self.employees: Dict[int, Employee] = {}",
    "        self.root: Optional[Employee] = None",
    "    ",
    "    def add_employee_extended(",
    "        self,",
    "        id: int,",
    "        name: str,",
    "        rating: int,",
    "        dept: str,",
    "        level: int,",
    "        salary: float,",
    "        manager_id: Optional[int]",
    "    ) -> bool:",
    "        \"\"\"",
    "        Add an employee with extended attributes to the org chart.",
    "        ",
    "        Args:",
    "            id: Unique employee ID",
    "            name: Employee name",
    "            rating: Performance rating (1-10)",
    "            dept: Department name",
    "            level: Seniority level (1-5)",
    "            salary: Annual salary",
    "            manager_id: Manager's ID or None for CEO",
    "            ",
    "        Returns:",
    "            True if added successfully, False if ID exists or manager not found",
    "            ",
    "        Time Complexity: O(1)",
    "        \"\"\"",
    "        # Validate: no duplicate IDs",
    "        if id in self.employees:",
    "            return False",
    "        ",
    "        # Validate: manager must exist (unless this is CEO)",
    "        if manager_id is not None and manager_id not in self.employees:",
    "            return False",
    "        ",
    "        # Create and store the employee",
    "        employee = Employee(",
    "            id=id,",
    "            name=name,",
    "            rating=rating,",
    "            department=dept,",
    "            level=level,",
    "            salary=salary,",
    "            manager_id=manager_id",
    "        )",
    "        self.employees[id] = employee",
    "        ",
    "        # Link to parent or set as root",
    "        if manager_id is None:",
    "            self.root = employee",
    "        else:",
    "            self.employees[manager_id].subordinates.append(employee)",
    "        ",
    "        return True",
    "    ",
    "    def _resolve_key_fn(",
    "        self,",
    "        key_fn: Union[str, Callable[[Employee], str]]",
    "    ) -> Callable[[Employee], str]:",
    "        \"\"\"",
    "        Resolve key extractor from string field name or callable.",
    "        ",
    "        Args:",
    "            key_fn: Either a string field name or a lambda function",
    "            ",
    "        Returns:",
    "            Callable that extracts the grouping key from an Employee",
    "            ",
    "        Raises:",
    "            ValueError: If string field name is not recognized",
    "        \"\"\"",
    "        if isinstance(key_fn, str):",
    "            if key_fn not in self._KEY_EXTRACTORS:",
    "                raise ValueError(f\"Unknown key field: {key_fn}\")",
    "            return self._KEY_EXTRACTORS[key_fn]",
    "        return key_fn",
    "    ",
    "    def _resolve_value_fn(",
    "        self,",
    "        value_fn: Union[str, Callable[[Employee], float]]",
    "    ) -> Callable[[Employee], float]:",
    "        \"\"\"",
    "        Resolve value extractor from string field name or callable.",
    "        ",
    "        Args:",
    "            value_fn: Either a string field name or a lambda function",
    "            ",
    "        Returns:",
    "            Callable that extracts the numeric value from an Employee",
    "            ",
    "        Raises:",
    "            ValueError: If string field name is not recognized",
    "        \"\"\"",
    "        if isinstance(value_fn, str):",
    "            if value_fn not in self._VALUE_EXTRACTORS:",
    "                raise ValueError(f\"Unknown value field: {value_fn}\")",
    "            return self._VALUE_EXTRACTORS[value_fn]",
    "        return value_fn",
    "    ",
    "    def _apply_aggregation(self, values: List[float], agg_type: str) -> float:",
    "        \"\"\"",
    "        Apply aggregation function to a list of values.",
    "        ",
    "        Args:",
    "            values: List of numeric values to aggregate",
    "            agg_type: One of 'SUM', 'AVG', 'MIN', 'MAX', 'COUNT'",
    "            ",
    "        Returns:",
    "            Aggregated result as float",
    "            ",
    "        Raises:",
    "            ValueError: If aggregation type is not recognized",
    "            ",
    "        Time Complexity: O(k) where k = len(values)",
    "        \"\"\"",
    "        if not values:",
    "            return 0.0",
    "        ",
    "        agg_type = agg_type.upper()",
    "        ",
    "        if agg_type == 'SUM':",
    "            return sum(values)",
    "        elif agg_type == 'AVG':",
    "            return sum(values) / len(values)",
    "        elif agg_type == 'MIN':",
    "            return min(values)",
    "        elif agg_type == 'MAX':",
    "            return max(values)",
    "        elif agg_type == 'COUNT':",
    "            return float(len(values))",
    "        else:",
    "            raise ValueError(f\"Unknown aggregation type: {agg_type}\")",
    "    ",
    "    def group_by_aggregate(",
    "        self,",
    "        key_fn: Union[str, Callable[[Employee], str]],",
    "        value_fn: Union[str, Callable[[Employee], float]],",
    "        agg_type: str",
    "    ) -> Dict[str, float]:",
    "        \"\"\"",
    "        Group all employees by key and aggregate values.",
    "        ",
    "        This is equivalent to SQL:",
    "            SELECT key, AGG(value) FROM employees GROUP BY key",
    "        ",
    "        Args:",
    "            key_fn: Function or field name to extract grouping key",
    "            value_fn: Function or field name to extract numeric value",
    "            agg_type: Aggregation type ('SUM', 'AVG', 'MIN', 'MAX', 'COUNT')",
    "            ",
    "        Returns:",
    "            Dictionary mapping group keys to aggregated values",
    "            ",
    "        Example:",
    "            >>> org.group_by_aggregate('department', 'salary', 'SUM')",
    "            {'Engineering': 320000.0, 'Sales': 230000.0}",
    "            ",
    "        Time Complexity: O(n) where n = number of employees",
    "        Space Complexity: O(n) for intermediate storage",
    "        \"\"\"",
    "        return self.filter_group_by_aggregate(",
    "            filter_fn=lambda _: True,  # No filtering - include all",
    "            key_fn=key_fn,",
    "            value_fn=value_fn,",
    "            agg_type=agg_type",
    "        )",
    "    ",
    "    def filter_group_by_aggregate(",
    "        self,",
    "        filter_fn: Callable[[Employee], bool],",
    "        key_fn: Union[str, Callable[[Employee], str]],",
    "        value_fn: Union[str, Callable[[Employee], float]],",
    "        agg_type: str",
    "    ) -> Dict[str, float]:",
    "        \"\"\"",
    "        Filter employees, group by key, and aggregate values.",
    "        ",
    "        This implements a stream-like pipeline: filter \u2192 groupBy \u2192 aggregate",
    "        ",
    "        Equivalent SQL:",
    "            SELECT key, AGG(value) FROM employees WHERE condition GROUP BY key",
    "        ",
    "        Args:",
    "            filter_fn: Predicate to filter employees (return True to include)",
    "            key_fn: Function or field name to extract grouping key",
    "            value_fn: Function or field name to extract numeric value",
    "            agg_type: Aggregation type ('SUM', 'AVG', 'MIN', 'MAX', 'COUNT')",
    "            ",
    "        Returns:",
    "            Dictionary mapping group keys to aggregated values",
    "            ",
    "        Example:",
    "            >>> # Average salary of senior employees by department",
    "            >>> org.filter_group_by_aggregate(",
    "            ...     lambda e: e.level >= 3,",
    "            ...     lambda e: e.department,",
    "            ...     lambda e: e.salary,",
    "            ...     'AVG'",
    "            ... )",
    "            {'Engineering': 160000.0, 'Sales': 150000.0}",
    "            ",
    "        Time Complexity: O(n) where n = number of employees",
    "        Space Complexity: O(n) worst case for groups accumulator",
    "        \"\"\"",
    "        # Resolve string field names to actual functions",
    "        resolved_key_fn = self._resolve_key_fn(key_fn)",
    "        resolved_value_fn = self._resolve_value_fn(value_fn)",
    "        ",
    "        # Phase 1: Collect values per group",
    "        groups: Dict[str, List[float]] = defaultdict(list)",
    "        ",
    "        for employee in self.employees.values():",
    "            # Apply filter",
    "            if not filter_fn(employee):",
    "                continue",
    "            ",
    "            # Extract key and value",
    "            key = resolved_key_fn(employee)",
    "            value = resolved_value_fn(employee)",
    "            ",
    "            # Collect into group",
    "            groups[key].append(value)",
    "        ",
    "        # Phase 2: Apply aggregation to each group",
    "        result: Dict[str, float] = {}",
    "        for key, values in groups.items():",
    "            result[key] = self._apply_aggregation(values, agg_type)",
    "        ",
    "        return result",
    "",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# DEMO AND TESTING",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "def main():",
    "    \"\"\"Demonstrate the generic aggregation and filtering capabilities.\"\"\"",
    "    print(\"\u2550\" * 70)",
    "    print(\"PART 3: Generic Aggregation & Filtering Demo\")",
    "    print(\"\u2550\" * 70)",
    "    ",
    "    # Build the org chart",
    "    org = OrgChart()",
    "    ",
    "    # Add employees (from example)",
    "    employees_data = [",
    "        (1, 'Alice', 8, 'Engineering', 5, 200000, None),   # CEO",
    "        (2, 'Bob', 7, 'Engineering', 3, 120000, 1),        # Engineer",
    "        (3, 'Carol', 6, 'Sales', 4, 150000, 1),            # VP Sales",
    "        (4, 'Dave', 5, 'Sales', 2, 80000, 3),              # Junior Sales",
    "    ]",
    "    ",
    "    print(\"\\n\ud83d\udcca Adding employees:\")",
    "    for emp_data in employees_data:",
    "        success = org.add_employee_extended(*emp_data)",
    "        emp = org.employees[emp_data[0]]",
    "        print(f\"  {emp.name}: {emp.department}, L{emp.level}, ${emp.salary:,.0f}\")",
    "    ",
    "    # Test 1: Total salary by department (using string field names)",
    "    print(\"\\n\" + \"\u2500\" * 70)",
    "    print(\"TEST 1: Total salary by department (SUM)\")",
    "    print(\"\u2500\" * 70)",
    "    result = org.group_by_aggregate('department', 'salary', 'SUM')",
    "    print(f\"  Result: {result}\")",
    "    print(f\"  Expected: {{'Engineering': 320000.0, 'Sales': 230000.0}}\")",
    "    ",
    "    # Test 2: Average rating by department (using lambdas)",
    "    print(\"\\n\" + \"\u2500\" * 70)",
    "    print(\"TEST 2: Average rating by department (AVG)\")",
    "    print(\"\u2500\" * 70)",
    "    result = org.group_by_aggregate(",
    "        lambda e: e.department,",
    "        lambda e: float(e.rating),",
    "        'AVG'",
    "    )",
    "    print(f\"  Result: {result}\")",
    "    print(f\"  Engineering: (8+7)/2 = 7.5, Sales: (6+5)/2 = 5.5\")",
    "    ",
    "    # Test 3: Average salary of senior employees (level >= 3) by department",
    "    print(\"\\n\" + \"\u2500\" * 70)",
    "    print(\"TEST 3: Avg salary of seniors (level >= 3) by department\")",
    "    print(\"\u2500\" * 70)",
    "    result = org.filter_group_by_aggregate(",
    "        filter_fn=lambda e: e.level >= 3,",
    "        key_fn=lambda e: e.department,",
    "        value_fn=lambda e: e.salary,",
    "        agg_type='AVG'",
    "    )",
    "    print(f\"  Result: {result}\")",
    "    print(f\"  Seniors: Alice(Eng,L5), Bob(Eng,L3), Carol(Sales,L4)\")",
    "    print(f\"  Eng: (200k+120k)/2 = 160k, Sales: 150k/1 = 150k\")",
    "    ",
    "    # Test 4: Count employees by level",
    "    print(\"\\n\" + \"\u2500\" * 70)",
    "    print(\"TEST 4: Count employees by level\")",
    "    print(\"\u2500\" * 70)",
    "    result = org.group_by_aggregate(",
    "        lambda e: f\"Level {e.level}\",",
    "        lambda e: 1.0,  # Value doesn't matter for COUNT",
    "        'COUNT'",
    "    )",
    "    print(f\"  Result: {result}\")",
    "    ",
    "    # Test 5: Max salary by department",
    "    print(\"\\n\" + \"\u2500\" * 70)",
    "    print(\"TEST 5: Max salary by department\")",
    "    print(\"\u2500\" * 70)",
    "    result = org.group_by_aggregate('department', 'salary', 'MAX')",
    "    print(f\"  Result: {result}\")",
    "    print(f\"  Engineering: max(200k,120k) = 200k, Sales: max(150k,80k) = 150k\")",
    "    ",
    "    # Test 6: Min rating of high earners (salary > 100k)",
    "    print(\"\\n\" + \"\u2500\" * 70)",
    "    print(\"TEST 6: Min rating of high earners (salary > 100k)\")",
    "    print(\"\u2500\" * 70)",
    "    result = org.filter_group_by_aggregate(",
    "        filter_fn=lambda e: e.salary > 100000,",
    "        key_fn=lambda e: e.department,",
    "        value_fn=lambda e: float(e.rating),",
    "        agg_type='MIN'",
    "    )",
    "    print(f\"  Result: {result}\")",
    "    print(f\"  High earners: Alice(8), Bob(7), Carol(6)\")",
    "    ",
    "    print(\"\\n\" + \"\u2550\" * 70)",
    "    print(\"All tests completed!\")",
    "    print(\"\u2550\" * 70)",
    "",
    "",
    "if __name__ == '__main__':",
    "    main()"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.util.function.*;",
    "import java.util.stream.*;",
    "",
    "/**",
    " * Employee Hierarchy / Org Tree - Part 3: Generic Aggregation & Filtering",
    " * ",
    " * This solution implements a flexible organizational chart with generic",
    " * group-by aggregation capabilities, similar to SQL GROUP BY operations.",
    " */",
    "public class OrgChart {",
    "    ",
    "    /**",
    "     * Extended Employee class with department, level, and salary.",
    "     */",
    "    public static class Employee {",
    "        private final int id;",
    "        private final String name;",
    "        private final int rating;",
    "        private final String department;",
    "        private final int level;",
    "        private final double salary;",
    "        private final Integer managerId;",
    "        private final List<Employee> subordinates;",
    "        ",
    "        public Employee(int id, String name, int rating, String department,",
    "                       int level, double salary, Integer managerId) {",
    "            this.id = id;",
    "            this.name = name;",
    "            this.rating = rating;",
    "            this.department = department;",
    "            this.level = level;",
    "            this.salary = salary;",
    "            this.managerId = managerId;",
    "            this.subordinates = new ArrayList<>();",
    "        }",
    "        ",
    "        // Getters",
    "        public int getId() { return id; }",
    "        public String getName() { return name; }",
    "        public int getRating() { return rating; }",
    "        public String getDepartment() { return department; }",
    "        public int getLevel() { return level; }",
    "        public double getSalary() { return salary; }",
    "        public Integer getManagerId() { return managerId; }",
    "        public List<Employee> getSubordinates() { return subordinates; }",
    "    }",
    "    ",
    "    // Core data structures",
    "    private final Map<Integer, Employee> employees;",
    "    private Employee root;",
    "    ",
    "    // Field accessor mappings for string-based queries",
    "    private static final Map<String, Function<Employee, String>> KEY_EXTRACTORS;",
    "    private static final Map<String, Function<Employee, Double>> VALUE_EXTRACTORS;",
    "    ",
    "    static {",
    "        KEY_EXTRACTORS = new HashMap<>();",
    "        KEY_EXTRACTORS.put(\"department\", Employee::getDepartment);",
    "        KEY_EXTRACTORS.put(\"level\", e -> String.valueOf(e.getLevel()));",
    "        KEY_EXTRACTORS.put(\"name\", Employee::getName);",
    "        ",
    "        VALUE_EXTRACTORS = new HashMap<>();",
    "        VALUE_EXTRACTORS.put(\"salary\", Employee::getSalary);",
    "        VALUE_EXTRACTORS.put(\"rating\", e -> (double) e.getRating());",
    "        VALUE_EXTRACTORS.put(\"level\", e -> (double) e.getLevel());",
    "    }",
    "    ",
    "    /**",
    "     * Initialize an empty organizational chart.",
    "     */",
    "    public OrgChart() {",
    "        this.employees = new HashMap<>();",
    "        this.root = null;",
    "    }",
    "    ",
    "    /**",
    "     * Add an employee with extended attributes.",
    "     * ",
    "     * @param id        Unique employee ID",
    "     * @param name      Employee name",
    "     * @param rating    Performance rating (1-10)",
    "     * @param dept      Department name",
    "     * @param level     Seniority level (1-5)",
    "     * @param salary    Annual salary",
    "     * @param managerId Manager's ID or null for CEO",
    "     * @return true if added successfully",
    "     */",
    "    public boolean addEmployeeExtended(int id, String name, int rating,",
    "                                       String dept, int level, double salary,",
    "                                       Integer managerId) {",
    "        // Validate: no duplicate IDs",
    "        if (employees.containsKey(id)) {",
    "            return false;",
    "        }",
    "        ",
    "        // Validate: manager must exist (unless this is CEO)",
    "        if (managerId != null && !employees.containsKey(managerId)) {",
    "            return false;",
    "        }",
    "        ",
    "        // Create and store the employee",
    "        Employee employee = new Employee(id, name, rating, dept, level, salary, managerId);",
    "        employees.put(id, employee);",
    "        ",
    "        // Link to parent or set as root",
    "        if (managerId == null) {",
    "            root = employee;",
    "        } else {",
    "            employees.get(managerId).getSubordinates().add(employee);",
    "        }",
    "        ",
    "        return true;",
    "    }",
    "    ",
    "    /**",
    "     * Resolve key extractor from string field name or function.",
    "     */",
    "    private Function<Employee, String> resolveKeyFn(Object keyFn) {",
    "        if (keyFn instanceof String) {",
    "            String fieldName = (String) keyFn;",
    "            if (!KEY_EXTRACTORS.containsKey(fieldName)) {",
    "                throw new IllegalArgumentException(\"Unknown key field: \" + fieldName);",
    "            }",
    "            return KEY_EXTRACTORS.get(fieldName);",
    "        }",
    "        @SuppressWarnings(\"unchecked\")",
    "        Function<Employee, String> fn = (Function<Employee, String>) keyFn;",
    "        return fn;",
    "    }",
    "    ",
    "    /**",
    "     * Resolve value extractor from string field name or function.",
    "     */",
    "    private Function<Employee, Double> resolveValueFn(Object valueFn) {",
    "        if (valueFn instanceof String) {",
    "            String fieldName = (String) valueFn;",
    "            if (!VALUE_EXTRACTORS.containsKey(fieldName)) {",
    "                throw new IllegalArgumentException(\"Unknown value field: \" + fieldName);",
    "            }",
    "            return VALUE_EXTRACTORS.get(fieldName);",
    "        }",
    "        @SuppressWarnings(\"unchecked\")",
    "        Function<Employee, Double> fn = (Function<Employee, Double>) valueFn;",
    "        return fn;",
    "    }",
    "    ",
    "    /**",
    "     * Apply aggregation function to a list of values.",
    "     * ",
    "     * @param values  List of numeric values",
    "     * @param aggType Aggregation type (SUM, AVG, MIN, MAX, COUNT)",
    "     * @return Aggregated result",
    "     */",
    "    private double applyAggregation(List<Double> values, String aggType) {",
    "        if (values.isEmpty()) {",
    "            return 0.0;",
    "        }",
    "        ",
    "        switch (aggType.toUpperCase()) {",
    "            case \"SUM\":",
    "                return values.stream().mapToDouble(Double::doubleValue).sum();",
    "            case \"AVG\":",
    "                return values.stream().mapToDouble(Double::doubleValue).average().orElse(0.0);",
    "            case \"MIN\":",
    "                return values.stream().mapToDouble(Double::doubleValue).min().orElse(0.0);",
    "            case \"MAX\":",
    "                return values.stream().mapToDouble(Double::doubleValue).max().orElse(0.0);",
    "            case \"COUNT\":",
    "                return (double) values.size();",
    "            default:",
    "                throw new IllegalArgumentException(\"Unknown aggregation: \" + aggType);",
    "        }",
    "    }",
    "    ",
    "    /**",
    "     * Group all employees by key and aggregate values.",
    "     * ",
    "     * Equivalent SQL: SELECT key, AGG(value) FROM employees GROUP BY key",
    "     * ",
    "     * @param keyFn   Function or field name to extract grouping key",
    "     * @param valueFn Function or field name to extract numeric value",
    "     * @param aggType Aggregation type (SUM, AVG, MIN, MAX, COUNT)",
    "     * @return Map of group keys to aggregated values",
    "     */",
    "    public Map<String, Double> groupByAggregate(",
    "            Object keyFn,",
    "            Object valueFn,",
    "            String aggType) {",
    "        return filterGroupByAggregate(e -> true, keyFn, valueFn, aggType);",
    "    }",
    "    ",
    "    /**",
    "     * Filter employees, group by key, and aggregate values.",
    "     * ",
    "     * Implements pipeline: filter \u2192 groupBy \u2192 aggregate",
    "     * ",
    "     * @param filterFn Predicate to filter employees",
    "     * @param keyFn    Function or field name to extract grouping key",
    "     * @param valueFn  Function or field name to extract numeric value",
    "     * @param aggType  Aggregation type (SUM, AVG, MIN, MAX, COUNT)",
    "     * @return Map of group keys to aggregated values",
    "     */",
    "    public Map<String, Double> filterGroupByAggregate(",
    "            Predicate<Employee> filterFn,",
    "            Object keyFn,",
    "            Object valueFn,",
    "            String aggType) {",
    "        ",
    "        // Resolve string field names to actual functions",
    "        Function<Employee, String> resolvedKeyFn = resolveKeyFn(keyFn);",
    "        Function<Employee, Double> resolvedValueFn = resolveValueFn(valueFn);",
    "        ",
    "        // Phase 1: Collect values per group",
    "        Map<String, List<Double>> groups = new HashMap<>();",
    "        ",
    "        for (Employee employee : employees.values()) {",
    "            // Apply filter",
    "            if (!filterFn.test(employee)) {",
    "                continue;",
    "            }",
    "            ",
    "            // Extract key and value",
    "            String key = resolvedKeyFn.apply(employee);",
    "            double value = resolvedValueFn.apply(employee);",
    "            ",
    "            // Collect into group",
    "            groups.computeIfAbsent(key, k -> new ArrayList<>()).add(value);",
    "        }",
    "        ",
    "        // Phase 2: Apply aggregation to each group",
    "        Map<String, Double> result = new HashMap<>();",
    "        for (Map.Entry<String, List<Double>> entry : groups.entrySet()) {",
    "            result.put(entry.getKey(), applyAggregation(entry.getValue(), aggType));",
    "        }",
    "        ",
    "        return result;",
    "    }",
    "    ",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    // DEMO AND TESTING",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    ",
    "    public static void main(String[] args) {",
    "        System.out.println(\"\u2550\".repeat(70));",
    "        System.out.println(\"PART 3: Generic Aggregation & Filtering Demo\");",
    "        System.out.println(\"\u2550\".repeat(70));",
    "        ",
    "        OrgChart org = new OrgChart();",
    "        ",
    "        // Add employees from example",
    "        org.addEmployeeExtended(1, \"Alice\", 8, \"Engineering\", 5, 200000, null);",
    "        org.addEmployeeExtended(2, \"Bob\", 7, \"Engineering\", 3, 120000, 1);",
    "        org.addEmployeeExtended(3, \"Carol\", 6, \"Sales\", 4, 150000, 1);",
    "        org.addEmployeeExtended(4, \"Dave\", 5, \"Sales\", 2, 80000, 3);",
    "        ",
    "        System.out.println(\"\\n\ud83d\udcca Employees added: Alice, Bob, Carol, Dave\");",
    "        ",
    "        // Test 1: Total salary by department",
    "        System.out.println(\"\\n\" + \"\u2500\".repeat(70));",
    "        System.out.println(\"TEST 1: Total salary by department (SUM)\");",
    "        Map<String, Double> result1 = org.groupByAggregate(\"department\", \"salary\", \"SUM\");",
    "        System.out.println(\"  Result: \" + result1);",
    "        ",
    "        // Test 2: Average salary of seniors by department",
    "        System.out.println(\"\\n\" + \"\u2500\".repeat(70));",
    "        System.out.println(\"TEST 2: Avg salary of seniors (level >= 3)\");",
    "        Map<String, Double> result2 = org.filterGroupByAggregate(",
    "            e -> e.getLevel() >= 3,",
    "            Employee::getDepartment,",
    "            Employee::getSalary,",
    "            \"AVG\"",
    "        );",
    "        System.out.println(\"  Result: \" + result2);",
    "        ",
    "        // Test 3: Max salary by department",
    "        System.out.println(\"\\n\" + \"\u2500\".repeat(70));",
    "        System.out.println(\"TEST 3: Max salary by department\");",
    "        Map<String, Double> result3 = org.groupByAggregate(\"department\", \"salary\", \"MAX\");",
    "        System.out.println(\"  Result: \" + result3);",
    "        ",
    "        System.out.println(\"\\n\" + \"\u2550\".repeat(70));",
    "        System.out.println(\"All tests completed!\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-10",
      "explanation": "**Imports and module docstring**: Import typing for type hints, defaultdict for grouping, and dataclass for clean Employee definition."
    },
    {
      "lines": "12-35",
      "explanation": "**Employee dataclass**: Extended employee with new fields (department, level, salary). Using @dataclass eliminates boilerplate while providing clear structure."
    },
    {
      "lines": "38-65",
      "explanation": "**OrgChart class definition**: Class docstring explains the generic aggregation capability. KEY_EXTRACTORS and VALUE_EXTRACTORS maps enable string-based field access for testing."
    },
    {
      "lines": "67-103",
      "explanation": "**add_employee_extended()**: Validates no duplicate IDs and manager existence, creates Employee instance, adds to employees dict, and links to parent's subordinates list."
    },
    {
      "lines": "105-130",
      "explanation": "**_resolve_key_fn() and _resolve_value_fn()**: Flexible resolvers that accept either string field names OR lambda functions. This enables both clean API usage and test case serialization."
    },
    {
      "lines": "132-155",
      "explanation": "**_apply_aggregation()**: Central aggregation logic handling SUM, AVG, MIN, MAX, COUNT. Clean switch on agg_type with proper empty list handling."
    },
    {
      "lines": "157-185",
      "explanation": "**group_by_aggregate()**: Delegates to filter_group_by_aggregate with a pass-all filter. This DRY approach ensures consistent behavior."
    },
    {
      "lines": "187-240",
      "explanation": "**filter_group_by_aggregate()**: The core algorithm - resolves functions, iterates employees applying filter, groups values by key, then applies aggregation per group. Two-phase collect-then-reduce pattern."
    },
    {
      "lines": "245-305",
      "explanation": "**main() demo**: Comprehensive tests showing string-based access, lambda-based access, filtering with aggregation, and various aggregation types."
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "addEmployeeExtended": {
          "complexity": "O(1)",
          "explanation": "HashMap put and list append are O(1)"
        },
        "groupByAggregate": {
          "complexity": "O(n)",
          "explanation": "Single pass through n employees, O(k) aggregation per group where sum of k = n"
        },
        "filterGroupByAggregate": {
          "complexity": "O(n)",
          "explanation": "Same as groupByAggregate - filter is O(1) per employee"
        }
      },
      "overall_change": "Part 3 methods maintain O(n) time complexity. The functional approach doesn't add overhead compared to hard-coded methods."
    },
    "space": {
      "additional_space": "O(n)",
      "explanation": "The groups HashMap can hold up to n values (if all employees in one group). The intermediate List<Double> per group collectively holds n values. Result map holds k entries where k = number of unique groups."
    }
  },
  "dry_run": {
    "example_input": "4 employees: Alice(Eng,200k), Bob(Eng,120k), Carol(Sales,150k), Dave(Sales,80k). Query: groupByAggregate('department', 'salary', 'SUM')",
    "steps": [
      {
        "step": 1,
        "action": "Initialize groups = defaultdict(list)",
        "state": "groups = {}",
        "explanation": "Empty accumulator ready for collection phase"
      },
      {
        "step": 2,
        "action": "Process Alice: key='Engineering', value=200000",
        "state": "groups = {'Engineering': [200000]}",
        "explanation": "First employee creates Engineering group"
      },
      {
        "step": 3,
        "action": "Process Bob: key='Engineering', value=120000",
        "state": "groups = {'Engineering': [200000, 120000]}",
        "explanation": "Second Engineering employee appends to existing list"
      },
      {
        "step": 4,
        "action": "Process Carol: key='Sales', value=150000",
        "state": "groups = {'Engineering': [200000, 120000], 'Sales': [150000]}",
        "explanation": "First Sales employee creates new group"
      },
      {
        "step": 5,
        "action": "Process Dave: key='Sales', value=80000",
        "state": "groups = {'Engineering': [200000, 120000], 'Sales': [150000, 80000]}",
        "explanation": "Second Sales employee appends to Sales list"
      },
      {
        "step": 6,
        "action": "Aggregate Engineering: SUM([200000, 120000])",
        "state": "result = {'Engineering': 320000}",
        "explanation": "Apply SUM to Engineering values"
      },
      {
        "step": 7,
        "action": "Aggregate Sales: SUM([150000, 80000])",
        "state": "result = {'Engineering': 320000, 'Sales': 230000}",
        "explanation": "Apply SUM to Sales values"
      }
    ],
    "final_output": "{'Engineering': 320000.0, 'Sales': 230000.0}"
  },
  "edge_cases": [
    {
      "case": "Empty organization",
      "handling": "Returns empty dict {}",
      "gotcha": "Don't return None - empty dict is the correct empty result"
    },
    {
      "case": "Filter excludes all employees",
      "handling": "Returns empty dict - no groups to aggregate",
      "gotcha": "Ensure filter edge case doesn't cause division by zero for AVG"
    },
    {
      "case": "Single employee in group",
      "handling": "AVG returns the single value, MIN=MAX=value",
      "gotcha": "COUNT should return 1.0, not 0.0"
    },
    {
      "case": "Unknown aggregation type",
      "handling": "Raise ValueError with clear message",
      "gotcha": "Case-insensitive comparison (uppercase before switch)"
    },
    {
      "case": "Null/None values in fields",
      "handling": "Python handles None in comparisons; document expected behavior",
      "gotcha": "Grouping by None key creates a 'None' string key"
    },
    {
      "case": "Very large salary values",
      "handling": "Use double precision; document potential floating point issues",
      "gotcha": "For financial calculations, consider Decimal for exact precision"
    }
  ],
  "test_cases": [
    {
      "name": "Basic SUM by department",
      "input": "groupByAggregate('department', 'salary', 'SUM')",
      "expected": "{'Engineering': 320000.0, 'Sales': 230000.0}",
      "explanation": "Engineering: 200k+120k, Sales: 150k+80k"
    },
    {
      "name": "AVG with filtering",
      "input": "filterGroupByAggregate(level >= 3, 'department', 'salary', 'AVG')",
      "expected": "{'Engineering': 160000.0, 'Sales': 150000.0}",
      "explanation": "Seniors only: Eng=(200k+120k)/2, Sales=150k/1"
    },
    {
      "name": "COUNT by level",
      "input": "groupByAggregate(level, unused, 'COUNT')",
      "expected": "{'5': 1.0, '3': 1.0, '4': 1.0, '2': 1.0}",
      "explanation": "One employee at each level"
    },
    {
      "name": "MAX salary by department",
      "input": "groupByAggregate('department', 'salary', 'MAX')",
      "expected": "{'Engineering': 200000.0, 'Sales': 150000.0}",
      "explanation": "Highest salaries: Alice for Eng, Carol for Sales"
    },
    {
      "name": "Filter excludes all",
      "input": "filterGroupByAggregate(level > 10, 'department', 'salary', 'SUM')",
      "expected": "{}",
      "explanation": "No employees have level > 10, empty result"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Calculating AVG as sum divided by total employees instead of group size",
      "why_wrong": "AVG should be per-group, not global. Using len(all_employees) gives wrong result.",
      "correct_approach": "Track values per group in List, then compute sum(list)/len(list) for each group",
      "code_example_wrong": "# WRONG\navg = total_sum / len(self.employees)",
      "code_example_correct": "# CORRECT\nfor key, values in groups.items():\n    result[key] = sum(values) / len(values)"
    },
    {
      "mistake": "Using single accumulator instead of list per group",
      "why_wrong": "Can't compute AVG without knowing both sum and count. Single accumulator loses count info.",
      "correct_approach": "Use List<Double> per group OR track (sum, count) tuple per group",
      "code_example_wrong": "# WRONG - loses count for AVG\ngroups[key] += value",
      "code_example_correct": "# CORRECT - preserves all values\ngroups[key].append(value)"
    },
    {
      "mistake": "Not handling empty result case",
      "why_wrong": "If filter excludes all, result should be {} not crash",
      "correct_approach": "Empty groups dict naturally produces empty result dict",
      "code_example_wrong": "# WRONG - crashes on empty\nreturn min(values)",
      "code_example_correct": "# CORRECT\nif not values:\n    return 0.0\nreturn min(values)"
    },
    {
      "mistake": "Hard-coding field extractors instead of accepting functions",
      "why_wrong": "Defeats the purpose of generic aggregation - can't group by new fields",
      "correct_approach": "Accept Function<Employee, T> parameters, resolve strings to functions for flexibility",
      "code_example_wrong": "# WRONG - hard-coded\ndef group_by_department(self):\n    for e in emps:\n        groups[e.department].append(e.salary)",
      "code_example_correct": "# CORRECT - generic\ndef group_by_aggregate(self, key_fn, value_fn, agg):\n    for e in emps:\n        groups[key_fn(e)].append(value_fn(e))"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by recognizing this is a **SQL GROUP BY** problem. Mention the pipeline pattern (filter \u2192 map \u2192 groupBy \u2192 reduce) used in Spark, pandas, and Java Streams. Draw the visual flow showing how values collect into groups before aggregation. Emphasize the **composition over enumeration** insight - one generic method vs 25 specific ones.",
    "what_to_mention": [
      "This pattern mirrors SQL GROUP BY and MapReduce",
      "Two-phase approach (collect-then-reduce) is necessary for AVG",
      "Functional interfaces make the solution extensible",
      "Single pass O(n) achieves optimal time complexity",
      "Trade-off: O(n) space for intermediate storage vs streaming aggregation"
    ],
    "time_allocation": "15-20 minutes: 3 min understanding, 5 min design discussion, 8-10 min implementation, 2 min testing",
    "if_stuck": [
      "Think about SQL GROUP BY - how would you implement it?",
      "Start with the simplest case: just SUM by department, then generalize",
      "What data structure naturally groups values by key? (HashMap<K, List<V>>)",
      "For AVG, what do you need to track? (Both sum and count - hence the list)"
    ]
  },
  "connection_to_next_part": "Part 3's generic aggregation framework sets up for Part 4 which could add: (1) Multi-level grouping (GROUP BY dept, level), (2) Window functions (running totals, percentiles), (3) Caching/memoization for repeated queries, or (4) Real-time streaming updates. The functional interfaces make these extensions natural.",
  "generated_at": "2026-01-14T15:06:57.562470",
  "_meta": {
    "problem_id": "employee_hierarchy_org_tree",
    "part_number": 3,
    "model": "claude-opus-4-5-20251101"
  }
}