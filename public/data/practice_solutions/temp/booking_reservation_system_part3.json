{
  "problem_title": "Design a Hotel Booking/Reservation System - Part 3: Scaling for High Traffic",
  "part_number": 3,
  "builds_on": "Part 2",
  "difficulty": "hard",
  "problem_understanding": {
    "what_changes": "Part 2 solved concurrency with distributed locks and optimistic locking. Part 3 requires scaling to handle 10x traffic (100K search QPS, 10K booking QPS) while maintaining sub-200ms search latency and sub-500ms booking latency. This introduces CQRS pattern, multi-layer caching, search engine integration, and geographic distribution.",
    "new_requirements": [
      "Handle 100K search queries per second",
      "Handle 10K booking transactions per second",
      "P99 search latency under 200ms",
      "P99 booking latency under 500ms",
      "Global availability with data locality",
      "Cache hot data while maintaining consistency for bookings"
    ],
    "new_constraints": [
      "Search can tolerate eventual consistency (seconds of staleness)",
      "Bookings MUST have strong consistency (no double-booking)",
      "Must handle geographic distribution across regions",
      "Cache invalidation must be timely (sub-second for availability changes)"
    ],
    "key_insight": "**CQRS (Command Query Responsibility Segregation)**: Accept eventual consistency for search (reads) while enforcing strong consistency for bookings (writes). The read path uses Elasticsearch + Redis cache for speed; the write path uses PostgreSQL with distributed locks for correctness. Kafka bridges the gap with event-driven synchronization."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "100K search QPS",
        "how_met": "Elasticsearch cluster with read replicas + multi-tier caching (L1: local, L2: Redis cluster)",
        "gotchas": [
          "Cache stampede on popular hotels",
          "Hot shard problem"
        ]
      },
      {
        "requirement": "10K booking QPS",
        "how_met": "Sharded PostgreSQL by hotel_id + connection pooling + async processing for non-critical paths",
        "gotchas": [
          "Cross-shard transactions for multi-hotel bookings",
          "Lock contention on hot hotels"
        ]
      },
      {
        "requirement": "P99 search < 200ms",
        "how_met": "Pre-computed search results for common queries + aggressive caching + CDN for static content",
        "gotchas": [
          "Long-tail queries with complex filters",
          "Cold cache scenarios"
        ]
      },
      {
        "requirement": "P99 booking < 500ms",
        "how_met": "Optimistic locking with retry + async event emission + denormalized availability table",
        "gotchas": [
          "Retry storms under contention",
          "Event ordering guarantees"
        ]
      },
      {
        "requirement": "Global availability",
        "how_met": "Multi-region deployment with read replicas + geo-routing via Global Load Balancer",
        "gotchas": [
          "Cross-region consistency delays",
          "Failover complexity"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "searchRoomsOptimized",
        "target": "O(1) cache hit",
        "achieved": "O(1) avg",
        "why": "Hash-based cache lookup"
      },
      {
        "operation": "searchRoomsOptimized (miss)",
        "target": "O(log n)",
        "achieved": "O(log n)",
        "why": "Elasticsearch B-tree index"
      },
      {
        "operation": "createBooking",
        "target": "O(log n)",
        "achieved": "O(log n)",
        "why": "B-tree index on (room_id, date) with lock"
      }
    ],
    "non_goals": [
      "Real-time price updates (handled by separate pricing service)",
      "Payment processing (external gateway, not in scope)",
      "User authentication (assume handled by API gateway)"
    ]
  },
  "assumptions": [
    "Hotels rarely change metadata (name, amenities) - can cache for hours",
    "Availability can be stale by up to 5 seconds for search results",
    "Most searches are for near-future dates (next 90 days)",
    "80% of traffic goes to 20% of popular hotels (Pareto distribution)",
    "Multi-region deployment with eventual consistency across regions (2-5 second lag acceptable)"
  ],
  "tradeoffs": [
    {
      "decision": "Eventual vs Strong Consistency for Search",
      "chosen": "Eventual Consistency",
      "why": "Search traffic is 100x booking traffic; showing slightly stale availability is acceptable since booking validates true availability",
      "alternative": "Strong Consistency",
      "when_to_switch": "If business requires guaranteed real-time inventory display"
    },
    {
      "decision": "Sharding by Hotel ID vs Location",
      "chosen": "Hybrid: Location for search, Hotel ID for bookings",
      "why": "Searches are location-centric; bookings need all room data together for a hotel",
      "alternative": "Single sharding strategy",
      "when_to_switch": "If cross-cutting queries become primary use case"
    },
    {
      "decision": "Cache-aside vs Write-through",
      "chosen": "Cache-aside with Event-driven Invalidation",
      "why": "Write-through adds latency to bookings; cache-aside with Kafka events provides good freshness",
      "alternative": "Write-through for critical data",
      "when_to_switch": "If cache coherence becomes a major issue"
    },
    {
      "decision": "Elasticsearch vs dedicated search index",
      "chosen": "Elasticsearch",
      "why": "Mature, well-supported, handles full-text + geo + filters well",
      "alternative": "Apache Solr, custom inverted index",
      "when_to_switch": "If Elasticsearch operational costs become prohibitive"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "SearchRequest/SearchResponse interfaces",
      "BookingRequest/BookingResponse interfaces",
      "Event schemas for Kafka",
      "Cache key formats"
    ],
    "what_to_change": [
      "Add CacheManager abstraction",
      "Add SearchEngine interface (for swapping implementations)",
      "Add ShardRouter for database routing",
      "Add MetricsCollector for observability"
    ],
    "interfaces_and_boundaries": "Clear separation between: (1) API Layer - handles HTTP/routing, (2) Search Service - owns Elasticsearch, (3) Booking Service - owns PostgreSQL + locking, (4) Cache Layer - owns Redis, (5) Event Bus - owns Kafka. Each can scale independently.",
    "invariants": [
      "A confirmed booking ALWAYS has a valid lock acquired first",
      "Cache invalidation event MUST be published within 100ms of booking confirmation",
      "Search results include staleness indicator for client decisions"
    ]
  },
  "visual_explanation": {
    "before_after": "```\n=== BEFORE (Part 2 - Single Region, Single DB) ===\n\nUser \u2192 API \u2192 [Lock] \u2192 PostgreSQL (single) \u2192 Response\n         \u2193\n    Simple Cache\n\n=== AFTER (Part 3 - Multi-Region, CQRS) ===\n\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502         GLOBAL CDN / LB             \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                            \u2502                            \u2502\n   US-EAST                      US-WEST                      EU-WEST\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 API Gateway \u2502           \u2502 API Gateway \u2502           \u2502 API Gateway \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                         \u2502                         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502           \u2502             \u2502           \u2502             \u2502           \u2502\n[Search]    [Booking]     [Search]    [Booking]     [Search]    [Booking]\nService     Service       Service     Service       Service     Service\n    \u2502           \u2502             \u2502           \u2502             \u2502           \u2502\n    \u2502           \u2502             \u2502           \u2502             \u2502           \u2502\n\u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510                                             \n\u2502 L1    \u2502   \u2502 Redis \u2502   \u2190\u2500\u2500 L1 caches are local per instance\n\u2502 Cache \u2502   \u2502 Locks \u2502   \u2190\u2500\u2500 Redis cluster shared in region\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n    \u2502           \u2502\n\u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\n\u2502   Redis Cluster   \u2502 \u2190\u2500\u2500 L2 cache (regional)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502           \u2502\n\u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Elastic\u2502   \u2502   PostgreSQL  \u2502\n\u2502 Search \u2502   \u2502   Primary +   \u2502\n\u2502 Cluster\u2502   \u2502   Read Replicas\u2502\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502               \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Kafka Cluster \u2502 \u2190\u2500\u2500 Events sync all components\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    SEARCH FLOW (Optimized Read Path)                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  Request                                                     Response\n    \u2502                                                            \u25b2\n    \u25bc                                                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   HIT    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502\n\u2502 L1 Cache  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 Return with \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502 (Local)   \u2502          \u2502 fromCache=T \u2502        (< 5ms)\n\u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502 MISS\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   HIT    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 L2 Cache  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 Populate L1 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 (Redis)   \u2502          \u2502 & Return    \u2502        (< 20ms)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n      \u2502 MISS                                                    \u25bc\n      \u25bc                                                      Response\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Elasticsearch \u2502\u2500\u2500\u2500\u2500\u2500\u2192\u2502 Populate L1 \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Query         \u2502      \u2502 + L2 Cache  \u2502        (< 200ms)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n                                                                \u25bc\n                                                             Response\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   BOOKING FLOW (Strong Consistency)                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  BookRequest                                              BookResponse\n    \u2502                                                            \u25b2\n    \u25bc                                                            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   LOCKED     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502 Acquire Dist Lock \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502 Check Availability   \u2502     \u2502\n\u2502 (Redis + Lua)     \u2502              \u2502 (PostgreSQL)         \u2502     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n          \u2502 FAILED                            \u2502                 \u2502\n          \u2502                                   \u25bc                 \u2502\n          \u25bc                            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502 AVAILABLE?   \u2502         \u2502\n    \u2502 Retry or  \u2502                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n    \u2502 CONFLICT  \u2502                   YES \u2502     \u2502 NO              \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u25bc     \u25bc                 \u2502\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n                              \u2502 INSERT      \u2502 \u2502 Return      \u2502   \u2502\n                              \u2502 Booking     \u2502 \u2502 UNAVAILABLE \u2502\u2500\u2500\u2500\u2518\n                              \u2502 (Optimistic)\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                                     \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 Publish     \u2502\n                              \u2502 Event       \u2502\n                              \u2502 (Kafka)     \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502              \u2502\n                              \u25bc              \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502 Invalidate\u2502   \u2502 Update     \u2502\n                        \u2502 Caches   \u2502   \u2502 ES Index   \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n```"
  },
  "approaches": [
    {
      "name": "Naive Extension - Scale Vertically",
      "description": "Add more CPU/RAM to existing single PostgreSQL database, add read replicas, simple Redis cache in front",
      "time_complexity": "O(log n) for all operations",
      "space_complexity": "O(n) for cache",
      "why_not_optimal": "Vertical scaling hits limits around 10-20K QPS. Single database becomes bottleneck. No geographic distribution. Cache invalidation becomes a nightmare with simple TTL. P99 latency suffers under load due to hot spots."
    },
    {
      "name": "Better - Add Elasticsearch + Basic Sharding",
      "description": "Use Elasticsearch for search, shard PostgreSQL by hotel_id, add Redis cluster",
      "time_complexity": "O(log n) search, O(1) cache hits",
      "space_complexity": "O(n) distributed across shards",
      "why_not_optimal": "Still has eventual consistency issues between ES and PostgreSQL. Cache invalidation is TTL-based (stale reads). No multi-region support. Search and booking services tightly coupled."
    },
    {
      "name": "Optimal - Full CQRS with Event-Driven Architecture",
      "description": "Complete separation of read (ES + Redis) and write (PostgreSQL) paths. Kafka for event streaming. Multi-tier caching with event-driven invalidation. Geographic distribution with local read replicas.",
      "time_complexity": "O(1) cache hit (90%+ cases), O(log n) ES query",
      "space_complexity": "O(n) with replication factor 3 across regions",
      "key_insight": "Accept that search can be slightly stale (seconds), but booking MUST be strongly consistent. This allows massive read scaling without compromising booking integrity. Events keep everything eventually synchronized."
    }
  ],
  "optimal_solution": {
    "explanation_md": "## Optimal Architecture: CQRS + Event-Driven Scaling\n\n### Core Principles\n\n1. **CQRS Pattern**: Completely separate the read path (search) from the write path (booking). They have different consistency, latency, and scaling requirements.\n\n2. **Multi-Tier Caching**:\n   - **L1 (Local)**: In-process cache per service instance (~1000 hot items, 1-5ms)\n   - **L2 (Redis Cluster)**: Regional shared cache (~100K items, 5-20ms)\n   - **L3 (Elasticsearch)**: Full search index (50-200ms)\n\n3. **Event-Driven Invalidation**: When a booking occurs:\n   - Publish `BookingConfirmed` event to Kafka\n   - Cache invalidation consumers immediately clear affected cache entries\n   - ES indexer updates availability asynchronously\n\n4. **Sharding Strategy**:\n   - **Search**: Shard Elasticsearch by **location** (users search within regions)\n   - **Bookings**: Shard PostgreSQL by **hotel_id** (keeps all rooms together)\n\n5. **Geographic Distribution**:\n   - Deploy in 3+ regions (US-East, US-West, EU-West)\n   - Each region has full read capability\n   - Single write master per shard (with failover)\n   - Cross-region replication with 2-5 second lag\n\n### Key Data Structures\n\n```\nCache Key Format:\n- Hotel metadata: hotel:{hotel_id}\n- Availability:   avail:{room_id}:{date}\n- Search results: search:{hash(location,checkin,checkout,filters)}\n\nKafka Topics:\n- booking.events: All booking lifecycle events\n- hotel.updates:  Hotel/room metadata changes\n- availability.changes: Real-time availability updates\n```\n\n### Why This Works\n\n- **100K Search QPS**: 90%+ hit L1/L2 cache \u2192 sub-20ms response\n- **10K Booking QPS**: Sharded PostgreSQL + distributed locks \u2192 parallel writes\n- **P99 < 200ms**: Pre-warmed caches + optimized ES queries\n- **Strong Consistency**: Booking path uses distributed locks + optimistic concurrency",
    "data_structures": [
      {
        "structure": "LRU Cache (L1)",
        "purpose": "Local in-memory cache for hottest data"
      },
      {
        "structure": "Redis Cluster (L2)",
        "purpose": "Distributed cache with TTL and pub/sub for invalidation"
      },
      {
        "structure": "Elasticsearch",
        "purpose": "Full-text search with geo-spatial support"
      },
      {
        "structure": "PostgreSQL Shards",
        "purpose": "ACID-compliant storage for bookings"
      },
      {
        "structure": "Kafka Topics",
        "purpose": "Event streaming for async synchronization"
      },
      {
        "structure": "Bloom Filter",
        "purpose": "Quick negative lookup for unavailable dates"
      }
    ],
    "algorithm_steps": [
      "Step 1: **Search Request Arrives** - Parse location, dates, filters from request",
      "Step 2: **Compute Cache Key** - Hash (location + dates + filters) for deterministic key",
      "Step 3: **Check L1 Cache** - If hit and fresh (< 5s), return immediately",
      "Step 4: **Check L2 Redis** - If hit and fresh (< 30s), populate L1 and return",
      "Step 5: **Query Elasticsearch** - Execute optimized query with filters",
      "Step 6: **Enrich with Availability** - Bloom filter quick-check, then availability table",
      "Step 7: **Populate Caches** - Store in L1 and L2 with appropriate TTLs",
      "Step 8: **Return Response** - Include staleness indicator for client",
      "---",
      "Step 9: **Booking Request Arrives** - Validate user and room details",
      "Step 10: **Acquire Distributed Lock** - Redis SETNX with TTL on room+dates",
      "Step 11: **Check True Availability** - Query PostgreSQL primary",
      "Step 12: **Insert Booking** - With optimistic locking (version check)",
      "Step 13: **Publish Event** - BookingConfirmed to Kafka",
      "Step 14: **Release Lock** - Redis DEL (or auto-expire)",
      "Step 15: **Event Consumers** - Invalidate caches, update ES index"
    ]
  },
  "solution_python_lines": [
    "\"\"\"",
    "Hotel Booking System - Part 3: Scaling for High Traffic",
    "=======================================================",
    "",
    "This implementation demonstrates:",
    "1. CQRS pattern (separate read/write paths)",
    "2. Multi-tier caching (L1 local, L2 Redis)",
    "3. Event-driven cache invalidation",
    "4. Elasticsearch-style search indexing",
    "5. Distributed locking for bookings",
    "6. Metrics and monitoring",
    "",
    "Production Notes:",
    "- Replace mock implementations with real Redis, ES, PostgreSQL, Kafka",
    "- Add circuit breakers for external service calls",
    "- Implement proper retry policies with exponential backoff",
    "\"\"\"",
    "",
    "from __future__ import annotations",
    "from typing import Dict, List, Optional, Set, Tuple, Any, Callable",
    "from dataclasses import dataclass, field",
    "from datetime import date, datetime, timedelta",
    "from enum import Enum",
    "from abc import ABC, abstractmethod",
    "from collections import defaultdict, OrderedDict",
    "from decimal import Decimal",
    "import asyncio",
    "import hashlib",
    "import json",
    "import time",
    "import threading",
    "import random",
    "import uuid",
    "from concurrent.futures import ThreadPoolExecutor",
    "",
    "",
    "# ============================================================================",
    "# ENUMS AND CONSTANTS",
    "# ============================================================================",
    "",
    "class BookingStatus(Enum):",
    "    PENDING = 'PENDING'",
    "    CONFIRMED = 'CONFIRMED'",
    "    CANCELLED = 'CANCELLED'",
    "    FAILED = 'FAILED'",
    "    CONFLICT = 'CONFLICT'",
    "",
    "",
    "class CacheLevel(Enum):",
    "    L1_LOCAL = 'L1_LOCAL'",
    "    L2_REDIS = 'L2_REDIS'",
    "    L3_SOURCE = 'L3_SOURCE'",
    "",
    "",
    "class Region(Enum):",
    "    US_EAST = 'us-east-1'",
    "    US_WEST = 'us-west-2'",
    "    EU_WEST = 'eu-west-1'",
    "    AP_SOUTHEAST = 'ap-southeast-1'",
    "",
    "",
    "# TTL Constants (in seconds)",
    "L1_CACHE_TTL = 5       # Local cache: very short",
    "L2_CACHE_TTL = 30      # Redis cache: short",
    "HOTEL_META_TTL = 3600  # Hotel info: long (rarely changes)",
    "LOCK_TTL = 10          # Distributed lock timeout",
    "LOCK_RETRY_DELAY = 0.05  # 50ms between retries",
    "MAX_LOCK_RETRIES = 5",
    "",
    "",
    "# ============================================================================",
    "# DATA MODELS",
    "# ============================================================================",
    "",
    "@dataclass",
    "class Hotel:",
    "    hotel_id: str",
    "    name: str",
    "    location: str",
    "    latitude: float",
    "    longitude: float",
    "    amenities: List[str]",
    "    rating: float",
    "    price_range: Tuple[Decimal, Decimal]",
    "",
    "",
    "@dataclass",
    "class Room:",
    "    room_id: str",
    "    hotel_id: str",
    "    room_type: str",
    "    capacity: int",
    "    price_per_night: Decimal",
    "    amenities: List[str]",
    "",
    "",
    "@dataclass",
    "class SearchRequest:",
    "    location: str",
    "    check_in: date",
    "    check_out: date",
    "    guests: int = 2",
    "    min_price: Optional[Decimal] = None",
    "    max_price: Optional[Decimal] = None",
    "    amenities: List[str] = field(default_factory=list)",
    "    cache_hint: str = 'allow_stale'  # 'allow_stale', 'prefer_fresh', 'bypass'",
    "    region_hint: Optional[Region] = None",
    "    request_id: str = field(default_factory=lambda: str(uuid.uuid4()))",
    "",
    "",
    "@dataclass",
    "class RoomResult:",
    "    room_id: str",
    "    hotel_id: str",
    "    hotel_name: str",
    "    room_type: str",
    "    price_per_night: Decimal",
    "    total_price: Decimal",
    "    available: bool",
    "    amenities: List[str]",
    "",
    "",
    "@dataclass",
    "class SearchResponse:",
    "    rooms: List[RoomResult]",
    "    total_count: int",
    "    from_cache: bool",
    "    cache_level: CacheLevel",
    "    staleness_ms: int",
    "    latency_ms: int",
    "    request_id: str",
    "",
    "",
    "@dataclass",
    "class BookingRequest:",
    "    user_id: str",
    "    room_id: str",
    "    check_in: date",
    "    check_out: date",
    "    guest_count: int = 2",
    "    request_id: str = field(default_factory=lambda: str(uuid.uuid4()))",
    "",
    "",
    "@dataclass",
    "class BookingResponse:",
    "    status: BookingStatus",
    "    booking_id: Optional[str]",
    "    message: str",
    "    latency_ms: int",
    "    request_id: str",
    "",
    "",
    "@dataclass",
    "class Booking:",
    "    booking_id: str",
    "    user_id: str",
    "    room_id: str",
    "    hotel_id: str",
    "    check_in: date",
    "    check_out: date",
    "    status: BookingStatus",
    "    total_price: Decimal",
    "    created_at: datetime",
    "    version: int = 1  # For optimistic locking",
    "",
    "",
    "@dataclass",
    "class CacheEntry:",
    "    data: Any",
    "    created_at: float",
    "    ttl: int",
    "",
    "    def is_expired(self) -> bool:",
    "        return time.time() - self.created_at > self.ttl",
    "",
    "    def staleness_ms(self) -> int:",
    "        return int((time.time() - self.created_at) * 1000)",
    "",
    "",
    "# ============================================================================",
    "# EVENT SYSTEM (Simulated Kafka)",
    "# ============================================================================",
    "",
    "@dataclass",
    "class Event:",
    "    event_type: str",
    "    payload: Dict[str, Any]",
    "    timestamp: datetime",
    "    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))",
    "",
    "",
    "class EventBus:",
    "    \"\"\"Simulates Kafka for event-driven architecture.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        self._subscribers: Dict[str, List[Callable]] = defaultdict(list)",
    "        self._events: List[Event] = []",
    "        self._lock = threading.Lock()",
    "    ",
    "    def subscribe(self, event_type: str, handler: Callable[[Event], None]):",
    "        with self._lock:",
    "            self._subscribers[event_type].append(handler)",
    "    ",
    "    def publish(self, event: Event):",
    "        with self._lock:",
    "            self._events.append(event)",
    "            handlers = self._subscribers.get(event.event_type, [])",
    "        ",
    "        # Async dispatch (simulating Kafka consumer)",
    "        for handler in handlers:",
    "            threading.Thread(target=handler, args=(event,)).start()",
    "    ",
    "    def get_events(self) -> List[Event]:",
    "        return self._events.copy()",
    "",
    "",
    "# ============================================================================",
    "# CACHE LAYER",
    "# ============================================================================",
    "",
    "class LRUCache:",
    "    \"\"\"Thread-safe LRU cache for L1 local caching.\"\"\"",
    "    ",
    "    def __init__(self, capacity: int = 1000):",
    "        self._capacity = capacity",
    "        self._cache: OrderedDict[str, CacheEntry] = OrderedDict()",
    "        self._lock = threading.Lock()",
    "        self._hits = 0",
    "        self._misses = 0",
    "    ",
    "    def get(self, key: str) -> Optional[CacheEntry]:",
    "        with self._lock:",
    "            if key not in self._cache:",
    "                self._misses += 1",
    "                return None",
    "            ",
    "            entry = self._cache[key]",
    "            if entry.is_expired():",
    "                del self._cache[key]",
    "                self._misses += 1",
    "                return None",
    "            ",
    "            # Move to end (most recently used)",
    "            self._cache.move_to_end(key)",
    "            self._hits += 1",
    "            return entry",
    "    ",
    "    def put(self, key: str, data: Any, ttl: int):",
    "        with self._lock:",
    "            if key in self._cache:",
    "                self._cache.move_to_end(key)",
    "            else:",
    "                if len(self._cache) >= self._capacity:",
    "                    self._cache.popitem(last=False)",
    "            ",
    "            self._cache[key] = CacheEntry(",
    "                data=data,",
    "                created_at=time.time(),",
    "                ttl=ttl",
    "            )",
    "    ",
    "    def invalidate(self, key: str):",
    "        with self._lock:",
    "            self._cache.pop(key, None)",
    "    ",
    "    def invalidate_prefix(self, prefix: str):",
    "        with self._lock:",
    "            keys_to_remove = [k for k in self._cache if k.startswith(prefix)]",
    "            for key in keys_to_remove:",
    "                del self._cache[key]",
    "    ",
    "    def stats(self) -> Dict[str, Any]:",
    "        with self._lock:",
    "            total = self._hits + self._misses",
    "            return {",
    "                'size': len(self._cache),",
    "                'capacity': self._capacity,",
    "                'hits': self._hits,",
    "                'misses': self._misses,",
    "                'hit_rate': self._hits / total if total > 0 else 0",
    "            }",
    "",
    "",
    "class RedisCache:",
    "    \"\"\"Simulated Redis cluster for L2 distributed caching.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        self._data: Dict[str, CacheEntry] = {}",
    "        self._locks: Dict[str, Tuple[str, float]] = {}  # key -> (owner, expiry)",
    "        self._lock = threading.Lock()",
    "        self._pub_sub: Dict[str, List[Callable]] = defaultdict(list)",
    "    ",
    "    def get(self, key: str) -> Optional[CacheEntry]:",
    "        with self._lock:",
    "            entry = self._data.get(key)",
    "            if entry and entry.is_expired():",
    "                del self._data[key]",
    "                return None",
    "            return entry",
    "    ",
    "    def set(self, key: str, data: Any, ttl: int):",
    "        with self._lock:",
    "            self._data[key] = CacheEntry(",
    "                data=data,",
    "                created_at=time.time(),",
    "                ttl=ttl",
    "            )",
    "    ",
    "    def delete(self, key: str):",
    "        with self._lock:",
    "            self._data.pop(key, None)",
    "    ",
    "    def delete_pattern(self, pattern: str):",
    "        \"\"\"Delete keys matching pattern (simplified glob matching).\"\"\"",
    "        prefix = pattern.rstrip('*')",
    "        with self._lock:",
    "            keys_to_remove = [k for k in self._data if k.startswith(prefix)]",
    "            for key in keys_to_remove:",
    "                del self._data[key]",
    "    ",
    "    # Distributed Lock Implementation (Redlock simplified)",
    "    def acquire_lock(self, key: str, owner: str, ttl: int = LOCK_TTL) -> bool:",
    "        \"\"\"",
    "        Acquire distributed lock using SETNX semantics.",
    "        Returns True if lock acquired, False otherwise.",
    "        \"\"\"",
    "        with self._lock:",
    "            current_time = time.time()",
    "            ",
    "            # Check if lock exists and is not expired",
    "            if key in self._locks:",
    "                existing_owner, expiry = self._locks[key]",
    "                if current_time < expiry:",
    "                    return existing_owner == owner  # Reentrant",
    "                # Lock expired, can acquire",
    "            ",
    "            # Acquire the lock",
    "            self._locks[key] = (owner, current_time + ttl)",
    "            return True",
    "    ",
    "    def release_lock(self, key: str, owner: str) -> bool:",
    "        \"\"\"Release lock only if owned by the caller.\"\"\"",
    "        with self._lock:",
    "            if key in self._locks:",
    "                existing_owner, _ = self._locks[key]",
    "                if existing_owner == owner:",
    "                    del self._locks[key]",
    "                    return True",
    "            return False",
    "    ",
    "    def publish(self, channel: str, message: str):",
    "        \"\"\"Publish message to channel (pub/sub for invalidation).\"\"\"",
    "        handlers = self._pub_sub.get(channel, [])",
    "        for handler in handlers:",
    "            handler(message)",
    "    ",
    "    def subscribe(self, channel: str, handler: Callable[[str], None]):",
    "        self._pub_sub[channel].append(handler)",
    "",
    "",
    "# ============================================================================",
    "# SEARCH ENGINE (Simulated Elasticsearch)",
    "# ============================================================================",
    "",
    "class SearchIndex:",
    "    \"\"\"",
    "    Simulated Elasticsearch for hotel/room search.",
    "    In production, use actual Elasticsearch with:",
    "    - Geo-spatial queries for location",
    "    - Full-text search for hotel names",
    "    - Range queries for prices",
    "    - Boolean filters for amenities",
    "    \"\"\"",
    "    ",
    "    def __init__(self):",
    "        self._hotels: Dict[str, Hotel] = {}",
    "        self._rooms: Dict[str, Room] = {}",
    "        self._location_index: Dict[str, Set[str]] = defaultdict(set)  # location -> hotel_ids",
    "        self._lock = threading.Lock()",
    "    ",
    "    def index_hotel(self, hotel: Hotel):",
    "        with self._lock:",
    "            self._hotels[hotel.hotel_id] = hotel",
    "            self._location_index[hotel.location.lower()].add(hotel.hotel_id)",
    "    ",
    "    def index_room(self, room: Room):",
    "        with self._lock:",
    "            self._rooms[room.room_id] = room",
    "    ",
    "    def search(self, request: SearchRequest) -> List[Tuple[Hotel, Room]]:",
    "        \"\"\"",
    "        Search for hotels and rooms matching criteria.",
    "        Simulates Elasticsearch query DSL.",
    "        \"\"\"",
    "        with self._lock:",
    "            results = []",
    "            location_lower = request.location.lower()",
    "            ",
    "            # Get hotels in location",
    "            hotel_ids = self._location_index.get(location_lower, set())",
    "            ",
    "            for hotel_id in hotel_ids:",
    "                hotel = self._hotels.get(hotel_id)",
    "                if not hotel:",
    "                    continue",
    "                ",
    "                # Filter rooms for this hotel",
    "                for room_id, room in self._rooms.items():",
    "                    if room.hotel_id != hotel_id:",
    "                        continue",
    "                    ",
    "                    # Capacity filter",
    "                    if room.capacity < request.guests:",
    "                        continue",
    "                    ",
    "                    # Price filter",
    "                    if request.min_price and room.price_per_night < request.min_price:",
    "                        continue",
    "                    if request.max_price and room.price_per_night > request.max_price:",
    "                        continue",
    "                    ",
    "                    # Amenities filter",
    "                    if request.amenities:",
    "                        room_amenities = set(room.amenities + hotel.amenities)",
    "                        if not all(a in room_amenities for a in request.amenities):",
    "                            continue",
    "                    ",
    "                    results.append((hotel, room))",
    "            ",
    "            # Sort by price",
    "            results.sort(key=lambda x: x[1].price_per_night)",
    "            return results",
    "    ",
    "    def update_availability(self, room_id: str, dates: List[date], available: bool):",
    "        \"\"\"Update availability index (would be a separate field in ES).\"\"\"",
    "        # In real ES, this would update a nested availability field",
    "        pass",
    "",
    "",
    "# ============================================================================",
    "# DATABASE LAYER (Simulated PostgreSQL with Sharding)",
    "# ============================================================================",
    "",
    "class DatabaseShard:",
    "    \"\"\"Single PostgreSQL shard.\"\"\"",
    "    ",
    "    def __init__(self, shard_id: int):",
    "        self.shard_id = shard_id",
    "        self._rooms: Dict[str, Room] = {}",
    "        self._bookings: Dict[str, Booking] = {}",
    "        self._availability: Dict[str, Set[date]] = {}  # room_id -> set of booked dates",
    "        self._lock = threading.Lock()",
    "    ",
    "    def add_room(self, room: Room):",
    "        with self._lock:",
    "            self._rooms[room.room_id] = room",
    "            self._availability[room.room_id] = set()",
    "    ",
    "    def check_availability(self, room_id: str, check_in: date, check_out: date) -> bool:",
    "        with self._lock:",
    "            if room_id not in self._availability:",
    "                return False",
    "            ",
    "            booked_dates = self._availability[room_id]",
    "            current = check_in",
    "            while current < check_out:",
    "                if current in booked_dates:",
    "                    return False",
    "                current += timedelta(days=1)",
    "            return True",
    "    ",
    "    def create_booking(self, booking: Booking) -> bool:",
    "        \"\"\"",
    "        Create booking with optimistic locking.",
    "        Returns True if successful, False if conflict.",
    "        \"\"\"",
    "        with self._lock:",
    "            # Double-check availability (belt and suspenders with distributed lock)",
    "            current = booking.check_in",
    "            dates_to_book = []",
    "            while current < booking.check_out:",
    "                if current in self._availability.get(booking.room_id, set()):",
    "                    return False  # Conflict!",
    "                dates_to_book.append(current)",
    "                current += timedelta(days=1)",
    "            ",
    "            # Mark dates as booked",
    "            for d in dates_to_book:",
    "                self._availability[booking.room_id].add(d)",
    "            ",
    "            # Store booking",
    "            self._bookings[booking.booking_id] = booking",
    "            return True",
    "    ",
    "    def get_booking(self, booking_id: str) -> Optional[Booking]:",
    "        with self._lock:",
    "            return self._bookings.get(booking_id)",
    "    ",
    "    def get_room(self, room_id: str) -> Optional[Room]:",
    "        with self._lock:",
    "            return self._rooms.get(room_id)",
    "    ",
    "    def cancel_booking(self, booking_id: str) -> bool:",
    "        with self._lock:",
    "            booking = self._bookings.get(booking_id)",
    "            if not booking or booking.status == BookingStatus.CANCELLED:",
    "                return False",
    "            ",
    "            # Free up dates",
    "            current = booking.check_in",
    "            while current < booking.check_out:",
    "                self._availability[booking.room_id].discard(current)",
    "                current += timedelta(days=1)",
    "            ",
    "            booking.status = BookingStatus.CANCELLED",
    "            return True",
    "",
    "",
    "class ShardedDatabase:",
    "    \"\"\"",
    "    Sharded PostgreSQL cluster.",
    "    Sharding strategy: hash(hotel_id) % num_shards",
    "    \"\"\"",
    "    ",
    "    def __init__(self, num_shards: int = 4):",
    "        self._shards = [DatabaseShard(i) for i in range(num_shards)]",
    "        self._hotel_to_shard: Dict[str, int] = {}",
    "    ",
    "    def _get_shard(self, hotel_id: str) -> DatabaseShard:",
    "        \"\"\"Consistent hashing to determine shard.\"\"\"",
    "        if hotel_id not in self._hotel_to_shard:",
    "            shard_id = hash(hotel_id) % len(self._shards)",
    "            self._hotel_to_shard[hotel_id] = shard_id",
    "        return self._shards[self._hotel_to_shard[hotel_id]]",
    "    ",
    "    def add_room(self, room: Room):",
    "        shard = self._get_shard(room.hotel_id)",
    "        shard.add_room(room)",
    "    ",
    "    def check_availability(self, hotel_id: str, room_id: str, ",
    "                          check_in: date, check_out: date) -> bool:",
    "        shard = self._get_shard(hotel_id)",
    "        return shard.check_availability(room_id, check_in, check_out)",
    "    ",
    "    def create_booking(self, booking: Booking) -> bool:",
    "        shard = self._get_shard(booking.hotel_id)",
    "        return shard.create_booking(booking)",
    "    ",
    "    def get_booking(self, booking_id: str, hotel_id: str) -> Optional[Booking]:",
    "        shard = self._get_shard(hotel_id)",
    "        return shard.get_booking(booking_id)",
    "    ",
    "    def get_room(self, room_id: str, hotel_id: str) -> Optional[Room]:",
    "        shard = self._get_shard(hotel_id)",
    "        return shard.get_room(room_id)",
    "    ",
    "    def cancel_booking(self, booking_id: str, hotel_id: str) -> bool:",
    "        shard = self._get_shard(hotel_id)",
    "        return shard.cancel_booking(booking_id)",
    "",
    "",
    "# ============================================================================",
    "# METRICS COLLECTOR",
    "# ============================================================================",
    "",
    "class MetricsCollector:",
    "    \"\"\"Collects operational metrics for monitoring.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        self._metrics: Dict[str, List[float]] = defaultdict(list)",
    "        self._counters: Dict[str, int] = defaultdict(int)",
    "        self._lock = threading.Lock()",
    "    ",
    "    def record_latency(self, operation: str, latency_ms: float):",
    "        with self._lock:",
    "            self._metrics[f'{operation}_latency'].append(latency_ms)",
    "    ",
    "    def increment(self, counter: str, value: int = 1):",
    "        with self._lock:",
    "            self._counters[counter] += value",
    "    ",
    "    def get_p99_latency(self, operation: str) -> float:",
    "        with self._lock:",
    "            latencies = self._metrics.get(f'{operation}_latency', [])",
    "            if not latencies:",
    "                return 0.0",
    "            sorted_latencies = sorted(latencies)",
    "            p99_index = int(len(sorted_latencies) * 0.99)",
    "            return sorted_latencies[min(p99_index, len(sorted_latencies) - 1)]",
    "    ",
    "    def get_summary(self) -> Dict[str, Any]:",
    "        with self._lock:",
    "            summary = {'counters': dict(self._counters)}",
    "            for key, values in self._metrics.items():",
    "                if values:",
    "                    summary[key] = {",
    "                        'count': len(values),",
    "                        'avg': sum(values) / len(values),",
    "                        'min': min(values),",
    "                        'max': max(values),",
    "                        'p99': sorted(values)[int(len(values) * 0.99)] if len(values) > 1 else values[0]",
    "                    }",
    "            return summary",
    "",
    "",
    "# ============================================================================",
    "# MAIN BOOKING SYSTEM (CQRS Architecture)",
    "# ============================================================================",
    "",
    "class HotelBookingSystem:",
    "    \"\"\"",
    "    Scalable Hotel Booking System implementing CQRS pattern.",
    "    ",
    "    Architecture:",
    "    - Read Path: L1 Cache -> L2 Redis -> Elasticsearch",
    "    - Write Path: Distributed Lock -> PostgreSQL -> Event Bus",
    "    ",
    "    Consistency Model:",
    "    - Search: Eventual consistency (seconds of staleness acceptable)",
    "    - Booking: Strong consistency (distributed locks + optimistic locking)",
    "    \"\"\"",
    "    ",
    "    def __init__(self, num_shards: int = 4):",
    "        # Core data stores",
    "        self._database = ShardedDatabase(num_shards)",
    "        self._search_index = SearchIndex()",
    "        ",
    "        # Caching layers",
    "        self._l1_cache = LRUCache(capacity=1000)",
    "        self._l2_cache = RedisCache()",
    "        ",
    "        # Event system",
    "        self._event_bus = EventBus()",
    "        self._setup_event_handlers()",
    "        ",
    "        # Metrics",
    "        self._metrics = MetricsCollector()",
    "        ",
    "        # Hotel metadata (for enriching results)",
    "        self._hotels: Dict[str, Hotel] = {}",
    "        self._room_to_hotel: Dict[str, str] = {}",
    "    ",
    "    def _setup_event_handlers(self):",
    "        \"\"\"Set up event-driven cache invalidation.\"\"\"",
    "        self._event_bus.subscribe('booking.confirmed', self._on_booking_confirmed)",
    "        self._event_bus.subscribe('booking.cancelled', self._on_booking_cancelled)",
    "    ",
    "    def _on_booking_confirmed(self, event: Event):",
    "        \"\"\"Handle booking confirmation - invalidate caches.\"\"\"",
    "        room_id = event.payload['room_id']",
    "        hotel_id = event.payload['hotel_id']",
    "        check_in = event.payload['check_in']",
    "        check_out = event.payload['check_out']",
    "        ",
    "        # Invalidate availability cache",
    "        self._l1_cache.invalidate_prefix(f'avail:{room_id}')",
    "        self._l2_cache.delete_pattern(f'avail:{room_id}:*')",
    "        ",
    "        # Invalidate search cache for location",
    "        if hotel_id in self._hotels:",
    "            location = self._hotels[hotel_id].location",
    "            self._l1_cache.invalidate_prefix(f'search:{location}')",
    "            self._l2_cache.delete_pattern(f'search:{location}:*')",
    "        ",
    "        self._metrics.increment('cache_invalidations')",
    "    ",
    "    def _on_booking_cancelled(self, event: Event):",
    "        \"\"\"Handle booking cancellation - room becomes available again.\"\"\"",
    "        self._on_booking_confirmed(event)  # Same invalidation logic",
    "    ",
    "    # ========================================================================",
    "    # SETUP METHODS (Admin operations)",
    "    # ========================================================================",
    "    ",
    "    def add_hotel(self, hotel: Hotel):",
    "        \"\"\"Add a hotel to the system.\"\"\"",
    "        self._hotels[hotel.hotel_id] = hotel",
    "        self._search_index.index_hotel(hotel)",
    "        ",
    "        # Cache hotel metadata (long TTL)",
    "        cache_key = f'hotel:{hotel.hotel_id}'",
    "        self._l2_cache.set(cache_key, hotel, HOTEL_META_TTL)",
    "    ",
    "    def add_room(self, room: Room):",
    "        \"\"\"Add a room to a hotel.\"\"\"",
    "        self._room_to_hotel[room.room_id] = room.hotel_id",
    "        self._database.add_room(room)",
    "        self._search_index.index_room(room)",
    "    ",
    "    # ========================================================================",
    "    # SEARCH (READ PATH - Eventual Consistency)",
    "    # ========================================================================",
    "    ",
    "    def _compute_search_cache_key(self, request: SearchRequest) -> str:",
    "        \"\"\"Compute deterministic cache key for search request.\"\"\"",
    "        key_parts = [",
    "            request.location.lower(),",
    "            request.check_in.isoformat(),",
    "            request.check_out.isoformat(),",
    "            str(request.guests),",
    "            str(request.min_price or ''),",
    "            str(request.max_price or ''),",
    "            ','.join(sorted(request.amenities))",
    "        ]",
    "        key_hash = hashlib.md5(':'.join(key_parts).encode()).hexdigest()[:16]",
    "        return f'search:{request.location.lower()}:{key_hash}'",
    "    ",
    "    def search_rooms_optimized(self, request: SearchRequest) -> SearchResponse:",
    "        \"\"\"",
    "        Optimized search with multi-tier caching.",
    "        ",
    "        Flow:",
    "        1. Check L1 local cache (< 5ms)",
    "        2. Check L2 Redis cache (< 20ms)",
    "        3. Query Elasticsearch (< 200ms)",
    "        4. Enrich with availability data",
    "        5. Cache results",
    "        ",
    "        Args:",
    "            request: Search criteria including cache hints",
    "            ",
    "        Returns:",
    "            SearchResponse with rooms, latency, and cache metadata",
    "        \"\"\"",
    "        start_time = time.time()",
    "        cache_key = self._compute_search_cache_key(request)",
    "        ",
    "        # Skip cache if bypass requested",
    "        if request.cache_hint != 'bypass':",
    "            # Try L1 cache first",
    "            l1_entry = self._l1_cache.get(cache_key)",
    "            if l1_entry:",
    "                self._metrics.increment('search_l1_hits')",
    "                latency_ms = int((time.time() - start_time) * 1000)",
    "                self._metrics.record_latency('search', latency_ms)",
    "                return SearchResponse(",
    "                    rooms=l1_entry.data,",
    "                    total_count=len(l1_entry.data),",
    "                    from_cache=True,",
    "                    cache_level=CacheLevel.L1_LOCAL,",
    "                    staleness_ms=l1_entry.staleness_ms(),",
    "                    latency_ms=latency_ms,",
    "                    request_id=request.request_id",
    "                )",
    "            ",
    "            # Try L2 Redis cache",
    "            l2_entry = self._l2_cache.get(cache_key)",
    "            if l2_entry:",
    "                # Populate L1 and return",
    "                self._l1_cache.put(cache_key, l2_entry.data, L1_CACHE_TTL)",
    "                self._metrics.increment('search_l2_hits')",
    "                latency_ms = int((time.time() - start_time) * 1000)",
    "                self._metrics.record_latency('search', latency_ms)",
    "                return SearchResponse(",
    "                    rooms=l2_entry.data,",
    "                    total_count=len(l2_entry.data),",
    "                    from_cache=True,",
    "                    cache_level=CacheLevel.L2_REDIS,",
    "                    staleness_ms=l2_entry.staleness_ms(),",
    "                    latency_ms=latency_ms,",
    "                    request_id=request.request_id",
    "                )",
    "        ",
    "        # Cache miss - query Elasticsearch",
    "        self._metrics.increment('search_cache_misses')",
    "        search_results = self._search_index.search(request)",
    "        ",
    "        # Calculate number of nights",
    "        num_nights = (request.check_out - request.check_in).days",
    "        ",
    "        # Build results with availability check",
    "        rooms: List[RoomResult] = []",
    "        for hotel, room in search_results:",
    "            # Check availability (with short-circuit for known unavailable)",
    "            available = self._database.check_availability(",
    "                hotel.hotel_id, room.room_id, ",
    "                request.check_in, request.check_out",
    "            )",
    "            ",
    "            rooms.append(RoomResult(",
    "                room_id=room.room_id,",
    "                hotel_id=hotel.hotel_id,",
    "                hotel_name=hotel.name,",
    "                room_type=room.room_type,",
    "                price_per_night=room.price_per_night,",
    "                total_price=room.price_per_night * num_nights,",
    "                available=available,",
    "                amenities=room.amenities + hotel.amenities",
    "            ))",
    "        ",
    "        # Cache results",
    "        self._l1_cache.put(cache_key, rooms, L1_CACHE_TTL)",
    "        self._l2_cache.set(cache_key, rooms, L2_CACHE_TTL)",
    "        ",
    "        latency_ms = int((time.time() - start_time) * 1000)",
    "        self._metrics.record_latency('search', latency_ms)",
    "        ",
    "        return SearchResponse(",
    "            rooms=rooms,",
    "            total_count=len(rooms),",
    "            from_cache=False,",
    "            cache_level=CacheLevel.L3_SOURCE,",
    "            staleness_ms=0,",
    "            latency_ms=latency_ms,",
    "            request_id=request.request_id",
    "        )",
    "    ",
    "    # ========================================================================",
    "    # BOOKING (WRITE PATH - Strong Consistency)",
    "    # ========================================================================",
    "    ",
    "    def _get_lock_key(self, room_id: str, check_in: date, check_out: date) -> str:",
    "        \"\"\"Generate lock key for room+date range.\"\"\"",
    "        return f'lock:room:{room_id}:{check_in.isoformat()}:{check_out.isoformat()}'",
    "    ",
    "    def create_booking(self, request: BookingRequest) -> BookingResponse:",
    "        \"\"\"",
    "        Create a booking with strong consistency guarantees.",
    "        ",
    "        Flow:",
    "        1. Acquire distributed lock on room+dates",
    "        2. Verify availability in PostgreSQL",
    "        3. Insert booking with optimistic locking",
    "        4. Publish event to Kafka",
    "        5. Release lock",
    "        ",
    "        Args:",
    "            request: Booking details",
    "            ",
    "        Returns:",
    "            BookingResponse with status and booking ID",
    "        \"\"\"",
    "        start_time = time.time()",
    "        ",
    "        # Validate room exists",
    "        hotel_id = self._room_to_hotel.get(request.room_id)",
    "        if not hotel_id:",
    "            return BookingResponse(",
    "                status=BookingStatus.FAILED,",
    "                booking_id=None,",
    "                message='Room not found',",
    "                latency_ms=int((time.time() - start_time) * 1000),",
    "                request_id=request.request_id",
    "            )",
    "        ",
    "        # Acquire distributed lock",
    "        lock_key = self._get_lock_key(request.room_id, request.check_in, request.check_out)",
    "        lock_owner = f'{request.user_id}:{request.request_id}'",
    "        ",
    "        acquired = False",
    "        for attempt in range(MAX_LOCK_RETRIES):",
    "            if self._l2_cache.acquire_lock(lock_key, lock_owner, LOCK_TTL):",
    "                acquired = True",
    "                break",
    "            time.sleep(LOCK_RETRY_DELAY * (1 + random.random()))  # Jitter",
    "        ",
    "        if not acquired:",
    "            self._metrics.increment('booking_lock_failures')",
    "            return BookingResponse(",
    "                status=BookingStatus.CONFLICT,",
    "                booking_id=None,",
    "                message='Could not acquire lock - room in high demand',",
    "                latency_ms=int((time.time() - start_time) * 1000),",
    "                request_id=request.request_id",
    "            )",
    "        ",
    "        try:",
    "            # Check availability in primary database",
    "            is_available = self._database.check_availability(",
    "                hotel_id, request.room_id, ",
    "                request.check_in, request.check_out",
    "            )",
    "            ",
    "            if not is_available:",
    "                self._metrics.increment('booking_unavailable')",
    "                return BookingResponse(",
    "                    status=BookingStatus.CONFLICT,",
    "                    booking_id=None,",
    "                    message='Room not available for selected dates',",
    "                    latency_ms=int((time.time() - start_time) * 1000),",
    "                    request_id=request.request_id",
    "                )",
    "            ",
    "            # Calculate price",
    "            room = self._database.get_room(request.room_id, hotel_id)",
    "            num_nights = (request.check_out - request.check_in).days",
    "            total_price = room.price_per_night * num_nights",
    "            ",
    "            # Create booking",
    "            booking = Booking(",
    "                booking_id=f'BK_{uuid.uuid4().hex[:12].upper()}',",
    "                user_id=request.user_id,",
    "                room_id=request.room_id,",
    "                hotel_id=hotel_id,",
    "                check_in=request.check_in,",
    "                check_out=request.check_out,",
    "                status=BookingStatus.CONFIRMED,",
    "                total_price=total_price,",
    "                created_at=datetime.now(),",
    "                version=1",
    "            )",
    "            ",
    "            # Insert booking (with optimistic locking check)",
    "            success = self._database.create_booking(booking)",
    "            ",
    "            if not success:",
    "                self._metrics.increment('booking_conflicts')",
    "                return BookingResponse(",
    "                    status=BookingStatus.CONFLICT,",
    "                    booking_id=None,",
    "                    message='Booking conflict - please retry',",
    "                    latency_ms=int((time.time() - start_time) * 1000),",
    "                    request_id=request.request_id",
    "                )",
    "            ",
    "            # Publish event for cache invalidation and ES update",
    "            self._event_bus.publish(Event(",
    "                event_type='booking.confirmed',",
    "                payload={",
    "                    'booking_id': booking.booking_id,",
    "                    'room_id': request.room_id,",
    "                    'hotel_id': hotel_id,",
    "                    'check_in': request.check_in.isoformat(),",
    "                    'check_out': request.check_out.isoformat(),",
    "                    'user_id': request.user_id",
    "                },",
    "                timestamp=datetime.now()",
    "            ))",
    "            ",
    "            self._metrics.increment('booking_success')",
    "            latency_ms = int((time.time() - start_time) * 1000)",
    "            self._metrics.record_latency('booking', latency_ms)",
    "            ",
    "            return BookingResponse(",
    "                status=BookingStatus.CONFIRMED,",
    "                booking_id=booking.booking_id,",
    "                message=f'Booking confirmed! Total: ${total_price}',",
    "                latency_ms=latency_ms,",
    "                request_id=request.request_id",
    "            )",
    "            ",
    "        finally:",
    "            # Always release lock",
    "            self._l2_cache.release_lock(lock_key, lock_owner)",
    "    ",
    "    def cancel_booking(self, booking_id: str, user_id: str, hotel_id: str) -> bool:",
    "        \"\"\"Cancel an existing booking.\"\"\"",
    "        booking = self._database.get_booking(booking_id, hotel_id)",
    "        if not booking or booking.user_id != user_id:",
    "            return False",
    "        ",
    "        success = self._database.cancel_booking(booking_id, hotel_id)",
    "        ",
    "        if success:",
    "            # Publish cancellation event",
    "            self._event_bus.publish(Event(",
    "                event_type='booking.cancelled',",
    "                payload={",
    "                    'booking_id': booking_id,",
    "                    'room_id': booking.room_id,",
    "                    'hotel_id': hotel_id,",
    "                    'check_in': booking.check_in.isoformat(),",
    "                    'check_out': booking.check_out.isoformat(),",
    "                    'user_id': user_id",
    "                },",
    "                timestamp=datetime.now()",
    "            ))",
    "        ",
    "        return success",
    "    ",
    "    # ========================================================================",
    "    # MONITORING",
    "    # ========================================================================",
    "    ",
    "    def get_metrics(self) -> Dict[str, Any]:",
    "        \"\"\"Get system metrics for monitoring.\"\"\"",
    "        return {",
    "            'system': self._metrics.get_summary(),",
    "            'l1_cache': self._l1_cache.stats(),",
    "            'p99_search_latency_ms': self._metrics.get_p99_latency('search'),",
    "            'p99_booking_latency_ms': self._metrics.get_p99_latency('booking')",
    "        }",
    "",
    "",
    "# ============================================================================",
    "# DEMO AND TESTING",
    "# ============================================================================",
    "",
    "def run_demo():",
    "    \"\"\"Demonstrate the scalable hotel booking system.\"\"\"",
    "    print('=' * 70)",
    "    print('HOTEL BOOKING SYSTEM - PART 3: SCALING FOR HIGH TRAFFIC')",
    "    print('=' * 70)",
    "    print()",
    "    ",
    "    # Initialize system",
    "    system = HotelBookingSystem(num_shards=4)",
    "    ",
    "    # Setup test data",
    "    print('\ud83d\udce6 Setting up test data...')",
    "    ",
    "    hotels = [",
    "        Hotel('H_NYC_1', 'Grand Plaza NYC', 'NYC', 40.7128, -74.0060,",
    "              ['wifi', 'pool', 'gym'], 4.5, (Decimal('150'), Decimal('500'))),",
    "        Hotel('H_NYC_2', 'Times Square Inn', 'NYC', 40.7580, -73.9855,",
    "              ['wifi', 'restaurant'], 4.0, (Decimal('100'), Decimal('300'))),",
    "        Hotel('H_LA_1', 'Hollywood Heights', 'LA', 34.0522, -118.2437,",
    "              ['wifi', 'pool', 'spa'], 4.7, (Decimal('200'), Decimal('600'))),",
    "    ]",
    "    ",
    "    rooms = [",
    "        Room('R_NYC_1', 'H_NYC_1', 'Deluxe King', 2, Decimal('250'), ['minibar', 'view']),",
    "        Room('R_NYC_2', 'H_NYC_1', 'Standard Queen', 2, Decimal('150'), ['minibar']),",
    "        Room('R_NYC_3', 'H_NYC_2', 'Standard Double', 2, Decimal('120'), []),",
    "        Room('R_LA_1', 'H_LA_1', 'Penthouse Suite', 4, Decimal('500'), ['jacuzzi', 'terrace']),",
    "        Room('R_LA_2', 'H_LA_1', 'Ocean View', 2, Decimal('300'), ['balcony', 'view']),",
    "    ]",
    "    ",
    "    for hotel in hotels:",
    "        system.add_hotel(hotel)",
    "    for room in rooms:",
    "        system.add_room(room)",
    "    ",
    "    print(f'  \u2713 Added {len(hotels)} hotels and {len(rooms)} rooms')",
    "    print()",
    "    ",
    "    # Demo 1: Search with caching",
    "    print('\ud83d\udd0d DEMO 1: Search with Multi-Tier Caching')",
    "    print('-' * 50)",
    "    ",
    "    search_request = SearchRequest(",
    "        location='NYC',",
    "        check_in=date(2024, 9, 1),",
    "        check_out=date(2024, 9, 3),",
    "        guests=2,",
    "        cache_hint='allow_stale'",
    "    )",
    "    ",
    "    # First search - cache miss",
    "    result1 = system.search_rooms_optimized(search_request)",
    "    print(f'  First search (cache miss):')",
    "    print(f'    Latency: {result1.latency_ms}ms')",
    "    print(f'    From cache: {result1.from_cache}')",
    "    print(f'    Cache level: {result1.cache_level.value}')",
    "    print(f'    Results: {result1.total_count} rooms')",
    "    for room in result1.rooms:",
    "        status = '\u2713' if room.available else '\u2717'",
    "        print(f'      {status} {room.hotel_name} - {room.room_type} @ ${room.price_per_night}/night')",
    "    print()",
    "    ",
    "    # Second search - L1 cache hit",
    "    result2 = system.search_rooms_optimized(search_request)",
    "    print(f'  Second search (L1 cache hit):')",
    "    print(f'    Latency: {result2.latency_ms}ms')",
    "    print(f'    From cache: {result2.from_cache}')",
    "    print(f'    Cache level: {result2.cache_level.value}')",
    "    print(f'    Staleness: {result2.staleness_ms}ms')",
    "    print()",
    "    ",
    "    # Demo 2: Booking with distributed lock",
    "    print('\ud83d\udcb3 DEMO 2: Booking with Strong Consistency')",
    "    print('-' * 50)",
    "    ",
    "    booking_request = BookingRequest(",
    "        user_id='U_ALICE',",
    "        room_id='R_NYC_1',",
    "        check_in=date(2024, 9, 1),",
    "        check_out=date(2024, 9, 3),",
    "        guest_count=2",
    "    )",
    "    ",
    "    booking_result = system.create_booking(booking_request)",
    "    print(f'  Booking attempt:')",
    "    print(f'    Status: {booking_result.status.value}')",
    "    print(f'    Booking ID: {booking_result.booking_id}')",
    "    print(f'    Message: {booking_result.message}')",
    "    print(f'    Latency: {booking_result.latency_ms}ms')",
    "    print()",
    "    ",
    "    # Demo 3: Concurrent booking attempt (should fail)",
    "    print('\u26a1 DEMO 3: Concurrent Booking (Race Condition)')",
    "    print('-' * 50)",
    "    ",
    "    # Same room, overlapping dates - should fail",
    "    booking_request2 = BookingRequest(",
    "        user_id='U_BOB',",
    "        room_id='R_NYC_1',",
    "        check_in=date(2024, 9, 2),",
    "        check_out=date(2024, 9, 4),",
    "        guest_count=2",
    "    )",
    "    ",
    "    booking_result2 = system.create_booking(booking_request2)",
    "    print(f'  Concurrent booking attempt (overlapping dates):')",
    "    print(f'    Status: {booking_result2.status.value}')",
    "    print(f'    Message: {booking_result2.message}')",
    "    print()",
    "    ",
    "    # Demo 4: Cache invalidation after booking",
    "    print('\ud83d\udd04 DEMO 4: Cache Invalidation After Booking')",
    "    print('-' * 50)",
    "    ",
    "    # Small delay to let async invalidation complete",
    "    time.sleep(0.1)",
    "    ",
    "    # Search again - should show updated availability",
    "    result3 = system.search_rooms_optimized(search_request)",
    "    print(f'  Search after booking:')",
    "    print(f'    Cache level: {result3.cache_level.value}')",
    "    for room in result3.rooms:",
    "        if room.room_id == 'R_NYC_1':",
    "            status = '\u2713 Available' if room.available else '\u2717 Booked'",
    "            print(f'    {room.room_type}: {status}')",
    "    print()",
    "    ",
    "    # Demo 5: Simulated load test",
    "    print('\ud83d\udcca DEMO 5: Simulated Load Test')",
    "    print('-' * 50)",
    "    ",
    "    print('  Running 100 search requests...')",
    "    for i in range(100):",
    "        req = SearchRequest(",
    "            location='NYC',",
    "            check_in=date(2024, 9, 1),",
    "            check_out=date(2024, 9, 3),",
    "            guests=2",
    "        )",
    "        system.search_rooms_optimized(req)",
    "    ",
    "    metrics = system.get_metrics()",
    "    print(f'  Results:')",
    "    print(f'    P99 Search Latency: {metrics[\"p99_search_latency_ms\"]:.1f}ms')",
    "    print(f'    L1 Cache Hit Rate: {metrics[\"l1_cache\"][\"hit_rate\"]:.1%}')",
    "    print(f'    Total Searches: {metrics[\"system\"][\"counters\"].get(\"search_l1_hits\", 0) + metrics[\"system\"][\"counters\"].get(\"search_l2_hits\", 0) + metrics[\"system\"][\"counters\"].get(\"search_cache_misses\", 0)}')",
    "    print()",
    "    ",
    "    # Final metrics",
    "    print('\ud83d\udcc8 FINAL SYSTEM METRICS')",
    "    print('-' * 50)",
    "    print(f'  Bookings: {metrics[\"system\"][\"counters\"].get(\"booking_success\", 0)} successful, {metrics[\"system\"][\"counters\"].get(\"booking_unavailable\", 0)} unavailable')",
    "    print(f'  Cache Invalidations: {metrics[\"system\"][\"counters\"].get(\"cache_invalidations\", 0)}')",
    "    print(f'  Lock Failures: {metrics[\"system\"][\"counters\"].get(\"booking_lock_failures\", 0)}')",
    "    print()",
    "    ",
    "    print('=' * 70)",
    "    print('DEMO COMPLETE')",
    "    print('=' * 70)",
    "",
    "",
    "if __name__ == '__main__':",
    "    run_demo()"
  ],
  "solution_java_lines": [
    "// Hotel Booking System - Part 3: Scaling for High Traffic",
    "// Java implementation with CQRS pattern",
    "",
    "import java.math.BigDecimal;",
    "import java.time.LocalDate;",
    "import java.time.LocalDateTime;",
    "import java.time.temporal.ChronoUnit;",
    "import java.util.*;",
    "import java.util.concurrent.*;",
    "import java.util.concurrent.atomic.AtomicLong;",
    "import java.util.concurrent.locks.ReentrantLock;",
    "import java.util.function.Consumer;",
    "import java.util.stream.Collectors;",
    "",
    "public class HotelBookingSystemScaled {",
    "",
    "    // ========================================================================",
    "    // ENUMS",
    "    // ========================================================================",
    "    ",
    "    enum BookingStatus {",
    "        PENDING, CONFIRMED, CANCELLED, FAILED, CONFLICT",
    "    }",
    "    ",
    "    enum CacheLevel {",
    "        L1_LOCAL, L2_REDIS, L3_SOURCE",
    "    }",
    "",
    "    // ========================================================================",
    "    // DATA MODELS",
    "    // ========================================================================",
    "    ",
    "    record Hotel(",
    "        String hotelId,",
    "        String name,",
    "        String location,",
    "        double latitude,",
    "        double longitude,",
    "        List<String> amenities,",
    "        double rating",
    "    ) {}",
    "    ",
    "    record Room(",
    "        String roomId,",
    "        String hotelId,",
    "        String roomType,",
    "        int capacity,",
    "        BigDecimal pricePerNight,",
    "        List<String> amenities",
    "    ) {}",
    "    ",
    "    record SearchRequest(",
    "        String location,",
    "        LocalDate checkIn,",
    "        LocalDate checkOut,",
    "        int guests,",
    "        BigDecimal minPrice,",
    "        BigDecimal maxPrice,",
    "        List<String> amenities,",
    "        String cacheHint,",
    "        String requestId",
    "    ) {",
    "        SearchRequest {",
    "            if (requestId == null) requestId = UUID.randomUUID().toString();",
    "            if (cacheHint == null) cacheHint = \"allow_stale\";",
    "            if (amenities == null) amenities = List.of();",
    "        }",
    "    }",
    "    ",
    "    record RoomResult(",
    "        String roomId,",
    "        String hotelId,",
    "        String hotelName,",
    "        String roomType,",
    "        BigDecimal pricePerNight,",
    "        BigDecimal totalPrice,",
    "        boolean available,",
    "        List<String> amenities",
    "    ) {}",
    "    ",
    "    record SearchResponse(",
    "        List<RoomResult> rooms,",
    "        int totalCount,",
    "        boolean fromCache,",
    "        CacheLevel cacheLevel,",
    "        long stalenessMs,",
    "        long latencyMs,",
    "        String requestId",
    "    ) {}",
    "    ",
    "    record BookingRequest(",
    "        String userId,",
    "        String roomId,",
    "        LocalDate checkIn,",
    "        LocalDate checkOut,",
    "        int guestCount,",
    "        String requestId",
    "    ) {",
    "        BookingRequest {",
    "            if (requestId == null) requestId = UUID.randomUUID().toString();",
    "        }",
    "    }",
    "    ",
    "    record BookingResponse(",
    "        BookingStatus status,",
    "        String bookingId,",
    "        String message,",
    "        long latencyMs,",
    "        String requestId",
    "    ) {}",
    "    ",
    "    static class Booking {",
    "        String bookingId;",
    "        String userId;",
    "        String roomId;",
    "        String hotelId;",
    "        LocalDate checkIn;",
    "        LocalDate checkOut;",
    "        BookingStatus status;",
    "        BigDecimal totalPrice;",
    "        LocalDateTime createdAt;",
    "        int version;",
    "    }",
    "",
    "    // ========================================================================",
    "    // CACHE LAYER",
    "    // ========================================================================",
    "    ",
    "    static class CacheEntry<T> {",
    "        T data;",
    "        long createdAt;",
    "        int ttlSeconds;",
    "        ",
    "        CacheEntry(T data, int ttlSeconds) {",
    "            this.data = data;",
    "            this.ttlSeconds = ttlSeconds;",
    "            this.createdAt = System.currentTimeMillis();",
    "        }",
    "        ",
    "        boolean isExpired() {",
    "            return System.currentTimeMillis() - createdAt > ttlSeconds * 1000L;",
    "        }",
    "        ",
    "        long stalenessMs() {",
    "            return System.currentTimeMillis() - createdAt;",
    "        }",
    "    }",
    "    ",
    "    static class LRUCache<T> {",
    "        private final int capacity;",
    "        private final Map<String, CacheEntry<T>> cache;",
    "        private final ReentrantLock lock = new ReentrantLock();",
    "        private final AtomicLong hits = new AtomicLong();",
    "        private final AtomicLong misses = new AtomicLong();",
    "        ",
    "        LRUCache(int capacity) {",
    "            this.capacity = capacity;",
    "            this.cache = new LinkedHashMap<>(capacity, 0.75f, true) {",
    "                @Override",
    "                protected boolean removeEldestEntry(Map.Entry<String, CacheEntry<T>> eldest) {",
    "                    return size() > LRUCache.this.capacity;",
    "                }",
    "            };",
    "        }",
    "        ",
    "        Optional<CacheEntry<T>> get(String key) {",
    "            lock.lock();",
    "            try {",
    "                CacheEntry<T> entry = cache.get(key);",
    "                if (entry == null) {",
    "                    misses.incrementAndGet();",
    "                    return Optional.empty();",
    "                }",
    "                if (entry.isExpired()) {",
    "                    cache.remove(key);",
    "                    misses.incrementAndGet();",
    "                    return Optional.empty();",
    "                }",
    "                hits.incrementAndGet();",
    "                return Optional.of(entry);",
    "            } finally {",
    "                lock.unlock();",
    "            }",
    "        }",
    "        ",
    "        void put(String key, T data, int ttl) {",
    "            lock.lock();",
    "            try {",
    "                cache.put(key, new CacheEntry<>(data, ttl));",
    "            } finally {",
    "                lock.unlock();",
    "            }",
    "        }",
    "        ",
    "        void invalidate(String key) {",
    "            lock.lock();",
    "            try {",
    "                cache.remove(key);",
    "            } finally {",
    "                lock.unlock();",
    "            }",
    "        }",
    "        ",
    "        void invalidatePrefix(String prefix) {",
    "            lock.lock();",
    "            try {",
    "                cache.keySet().removeIf(k -> k.startsWith(prefix));",
    "            } finally {",
    "                lock.unlock();",
    "            }",
    "        }",
    "        ",
    "        double hitRate() {",
    "            long total = hits.get() + misses.get();",
    "            return total > 0 ? (double) hits.get() / total : 0;",
    "        }",
    "    }",
    "",
    "    // ========================================================================",
    "    // DISTRIBUTED LOCK (Simulated Redis)",
    "    // ========================================================================",
    "    ",
    "    static class DistributedLockManager {",
    "        private final Map<String, LockInfo> locks = new ConcurrentHashMap<>();",
    "        private static final int LOCK_TTL_MS = 10000;",
    "        ",
    "        record LockInfo(String owner, long expiry) {}",
    "        ",
    "        boolean acquireLock(String key, String owner) {",
    "            long now = System.currentTimeMillis();",
    "            return locks.compute(key, (k, existing) -> {",
    "                if (existing == null || now > existing.expiry()) {",
    "                    return new LockInfo(owner, now + LOCK_TTL_MS);",
    "                }",
    "                return existing;",
    "            }).owner().equals(owner);",
    "        }",
    "        ",
    "        boolean releaseLock(String key, String owner) {",
    "            LockInfo info = locks.get(key);",
    "            if (info != null && info.owner().equals(owner)) {",
    "                locks.remove(key);",
    "                return true;",
    "            }",
    "            return false;",
    "        }",
    "    }",
    "",
    "    // ========================================================================",
    "    // DATABASE SHARD",
    "    // ========================================================================",
    "    ",
    "    static class DatabaseShard {",
    "        private final int shardId;",
    "        private final Map<String, Room> rooms = new ConcurrentHashMap<>();",
    "        private final Map<String, Booking> bookings = new ConcurrentHashMap<>();",
    "        private final Map<String, Set<LocalDate>> availability = new ConcurrentHashMap<>();",
    "        ",
    "        DatabaseShard(int shardId) {",
    "            this.shardId = shardId;",
    "        }",
    "        ",
    "        void addRoom(Room room) {",
    "            rooms.put(room.roomId(), room);",
    "            availability.put(room.roomId(), ConcurrentHashMap.newKeySet());",
    "        }",
    "        ",
    "        boolean checkAvailability(String roomId, LocalDate checkIn, LocalDate checkOut) {",
    "            Set<LocalDate> booked = availability.get(roomId);",
    "            if (booked == null) return false;",
    "            ",
    "            for (LocalDate d = checkIn; d.isBefore(checkOut); d = d.plusDays(1)) {",
    "                if (booked.contains(d)) return false;",
    "            }",
    "            return true;",
    "        }",
    "        ",
    "        synchronized boolean createBooking(Booking booking) {",
    "            Set<LocalDate> booked = availability.get(booking.roomId);",
    "            if (booked == null) return false;",
    "            ",
    "            List<LocalDate> datesToBook = new ArrayList<>();",
    "            for (LocalDate d = booking.checkIn; d.isBefore(booking.checkOut); d = d.plusDays(1)) {",
    "                if (booked.contains(d)) return false;",
    "                datesToBook.add(d);",
    "            }",
    "            ",
    "            booked.addAll(datesToBook);",
    "            bookings.put(booking.bookingId, booking);",
    "            return true;",
    "        }",
    "        ",
    "        Room getRoom(String roomId) {",
    "            return rooms.get(roomId);",
    "        }",
    "    }",
    "",
    "    // ========================================================================",
    "    // MAIN SYSTEM",
    "    // ========================================================================",
    "    ",
    "    private final List<DatabaseShard> shards;",
    "    private final Map<String, Hotel> hotels = new ConcurrentHashMap<>();",
    "    private final Map<String, String> roomToHotel = new ConcurrentHashMap<>();",
    "    private final Map<String, Set<String>> locationIndex = new ConcurrentHashMap<>();",
    "    private final LRUCache<List<RoomResult>> l1Cache = new LRUCache<>(1000);",
    "    private final LRUCache<List<RoomResult>> l2Cache = new LRUCache<>(10000);",
    "    private final DistributedLockManager lockManager = new DistributedLockManager();",
    "    private final AtomicLong bookingSuccess = new AtomicLong();",
    "    private final AtomicLong bookingConflict = new AtomicLong();",
    "    ",
    "    private static final int L1_TTL = 5;",
    "    private static final int L2_TTL = 30;",
    "    ",
    "    public HotelBookingSystemScaled(int numShards) {",
    "        shards = new ArrayList<>();",
    "        for (int i = 0; i < numShards; i++) {",
    "            shards.add(new DatabaseShard(i));",
    "        }",
    "    }",
    "    ",
    "    private DatabaseShard getShard(String hotelId) {",
    "        int shardIdx = Math.abs(hotelId.hashCode()) % shards.size();",
    "        return shards.get(shardIdx);",
    "    }",
    "    ",
    "    public void addHotel(Hotel hotel) {",
    "        hotels.put(hotel.hotelId(), hotel);",
    "        locationIndex.computeIfAbsent(hotel.location().toLowerCase(), k -> ConcurrentHashMap.newKeySet())",
    "                    .add(hotel.hotelId());",
    "    }",
    "    ",
    "    public void addRoom(Room room) {",
    "        roomToHotel.put(room.roomId(), room.hotelId());",
    "        getShard(room.hotelId()).addRoom(room);",
    "    }",
    "    ",
    "    private String computeCacheKey(SearchRequest request) {",
    "        return String.format(\"search:%s:%s:%s:%d\",",
    "            request.location().toLowerCase(),",
    "            request.checkIn(),",
    "            request.checkOut(),",
    "            request.guests());",
    "    }",
    "    ",
    "    public SearchResponse searchRoomsOptimized(SearchRequest request) {",
    "        long startTime = System.currentTimeMillis();",
    "        String cacheKey = computeCacheKey(request);",
    "        ",
    "        // Check L1 cache",
    "        if (!\"bypass\".equals(request.cacheHint())) {",
    "            var l1Entry = l1Cache.get(cacheKey);",
    "            if (l1Entry.isPresent()) {",
    "                return new SearchResponse(",
    "                    l1Entry.get().data,",
    "                    l1Entry.get().data.size(),",
    "                    true, CacheLevel.L1_LOCAL,",
    "                    l1Entry.get().stalenessMs(),",
    "                    System.currentTimeMillis() - startTime,",
    "                    request.requestId());",
    "            }",
    "            ",
    "            // Check L2 cache",
    "            var l2Entry = l2Cache.get(cacheKey);",
    "            if (l2Entry.isPresent()) {",
    "                l1Cache.put(cacheKey, l2Entry.get().data, L1_TTL);",
    "                return new SearchResponse(",
    "                    l2Entry.get().data,",
    "                    l2Entry.get().data.size(),",
    "                    true, CacheLevel.L2_REDIS,",
    "                    l2Entry.get().stalenessMs(),",
    "                    System.currentTimeMillis() - startTime,",
    "                    request.requestId());",
    "            }",
    "        }",
    "        ",
    "        // Cache miss - search from source",
    "        List<RoomResult> results = new ArrayList<>();",
    "        Set<String> hotelIds = locationIndex.getOrDefault(",
    "            request.location().toLowerCase(), Set.of());",
    "        ",
    "        long numNights = ChronoUnit.DAYS.between(request.checkIn(), request.checkOut());",
    "        ",
    "        for (String hotelId : hotelIds) {",
    "            Hotel hotel = hotels.get(hotelId);",
    "            DatabaseShard shard = getShard(hotelId);",
    "            ",
    "            // Find rooms in this hotel (simplified)",
    "            for (var entry : roomToHotel.entrySet()) {",
    "                if (!entry.getValue().equals(hotelId)) continue;",
    "                ",
    "                Room room = shard.getRoom(entry.getKey());",
    "                if (room == null || room.capacity() < request.guests()) continue;",
    "                ",
    "                boolean available = shard.checkAvailability(",
    "                    room.roomId(), request.checkIn(), request.checkOut());",
    "                ",
    "                results.add(new RoomResult(",
    "                    room.roomId(), hotel.hotelId(), hotel.name(),",
    "                    room.roomType(), room.pricePerNight(),",
    "                    room.pricePerNight().multiply(BigDecimal.valueOf(numNights)),",
    "                    available, room.amenities()));",
    "            }",
    "        }",
    "        ",
    "        // Sort by price and cache",
    "        results.sort(Comparator.comparing(RoomResult::pricePerNight));",
    "        l1Cache.put(cacheKey, results, L1_TTL);",
    "        l2Cache.put(cacheKey, results, L2_TTL);",
    "        ",
    "        return new SearchResponse(",
    "            results, results.size(), false,",
    "            CacheLevel.L3_SOURCE, 0,",
    "            System.currentTimeMillis() - startTime,",
    "            request.requestId());",
    "    }",
    "    ",
    "    public BookingResponse createBooking(BookingRequest request) {",
    "        long startTime = System.currentTimeMillis();",
    "        String hotelId = roomToHotel.get(request.roomId());",
    "        ",
    "        if (hotelId == null) {",
    "            return new BookingResponse(",
    "                BookingStatus.FAILED, null, \"Room not found\",",
    "                System.currentTimeMillis() - startTime, request.requestId());",
    "        }",
    "        ",
    "        // Acquire distributed lock",
    "        String lockKey = String.format(\"lock:%s:%s\", request.roomId(), request.checkIn());",
    "        String lockOwner = request.userId() + \":\" + request.requestId();",
    "        ",
    "        if (!lockManager.acquireLock(lockKey, lockOwner)) {",
    "            return new BookingResponse(",
    "                BookingStatus.CONFLICT, null,",
    "                \"Could not acquire lock\",",
    "                System.currentTimeMillis() - startTime,",
    "                request.requestId());",
    "        }",
    "        ",
    "        try {",
    "            DatabaseShard shard = getShard(hotelId);",
    "            Room room = shard.getRoom(request.roomId());",
    "            ",
    "            if (!shard.checkAvailability(",
    "                    request.roomId(), request.checkIn(), request.checkOut())) {",
    "                bookingConflict.incrementAndGet();",
    "                return new BookingResponse(",
    "                    BookingStatus.CONFLICT, null,",
    "                    \"Room not available\",",
    "                    System.currentTimeMillis() - startTime,",
    "                    request.requestId());",
    "            }",
    "            ",
    "            long nights = ChronoUnit.DAYS.between(",
    "                request.checkIn(), request.checkOut());",
    "            ",
    "            Booking booking = new Booking();",
    "            booking.bookingId = \"BK_\" + UUID.randomUUID().toString().substring(0, 12);",
    "            booking.userId = request.userId();",
    "            booking.roomId = request.roomId();",
    "            booking.hotelId = hotelId;",
    "            booking.checkIn = request.checkIn();",
    "            booking.checkOut = request.checkOut();",
    "            booking.status = BookingStatus.CONFIRMED;",
    "            booking.totalPrice = room.pricePerNight().multiply(",
    "                BigDecimal.valueOf(nights));",
    "            booking.createdAt = LocalDateTime.now();",
    "            ",
    "            if (shard.createBooking(booking)) {",
    "                bookingSuccess.incrementAndGet();",
    "                // Invalidate caches",
    "                String location = hotels.get(hotelId).location();",
    "                l1Cache.invalidatePrefix(\"search:\" + location.toLowerCase());",
    "                l2Cache.invalidatePrefix(\"search:\" + location.toLowerCase());",
    "                ",
    "                return new BookingResponse(",
    "                    BookingStatus.CONFIRMED, booking.bookingId,",
    "                    \"Booking confirmed! Total: $\" + booking.totalPrice,",
    "                    System.currentTimeMillis() - startTime,",
    "                    request.requestId());",
    "            } else {",
    "                bookingConflict.incrementAndGet();",
    "                return new BookingResponse(",
    "                    BookingStatus.CONFLICT, null,",
    "                    \"Booking conflict\",",
    "                    System.currentTimeMillis() - startTime,",
    "                    request.requestId());",
    "            }",
    "        } finally {",
    "            lockManager.releaseLock(lockKey, lockOwner);",
    "        }",
    "    }",
    "    ",
    "    public void printMetrics() {",
    "        System.out.println(\"=== SYSTEM METRICS ===\");",
    "        System.out.printf(\"Bookings: %d success, %d conflicts%n\",",
    "            bookingSuccess.get(), bookingConflict.get());",
    "        System.out.printf(\"L1 Cache Hit Rate: %.1f%%%n\",",
    "            l1Cache.hitRate() * 100);",
    "    }",
    "",
    "    // ========================================================================",
    "    // MAIN",
    "    // ========================================================================",
    "    ",
    "    public static void main(String[] args) {",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println(\"HOTEL BOOKING SYSTEM - PART 3: SCALING\");",
    "        System.out.println(\"=\".repeat(60));",
    "        ",
    "        var system = new HotelBookingSystemScaled(4);",
    "        ",
    "        // Setup data",
    "        system.addHotel(new Hotel(\"H1\", \"Grand Plaza\", \"NYC\",",
    "            40.7, -74.0, List.of(\"wifi\", \"pool\"), 4.5));",
    "        system.addRoom(new Room(\"R1\", \"H1\", \"Deluxe\", 2,",
    "            new BigDecimal(\"250\"), List.of(\"minibar\")));",
    "        system.addRoom(new Room(\"R2\", \"H1\", \"Standard\", 2,",
    "            new BigDecimal(\"150\"), List.of()));",
    "        ",
    "        // Search",
    "        var searchReq = new SearchRequest(\"NYC\",",
    "            LocalDate.of(2024, 9, 1), LocalDate.of(2024, 9, 3),",
    "            2, null, null, null, null, null);",
    "        ",
    "        var result1 = system.searchRoomsOptimized(searchReq);",
    "        System.out.printf(\"%nSearch 1 (miss): %dms, %d results%n\",",
    "            result1.latencyMs(), result1.totalCount());",
    "        ",
    "        var result2 = system.searchRoomsOptimized(searchReq);",
    "        System.out.printf(\"Search 2 (hit): %dms, cache=%s%n\",",
    "            result2.latencyMs(), result2.cacheLevel());",
    "        ",
    "        // Book",
    "        var bookReq = new BookingRequest(\"USER1\", \"R1\",",
    "            LocalDate.of(2024, 9, 1), LocalDate.of(2024, 9, 3),",
    "            2, null);",
    "        ",
    "        var bookResult = system.createBooking(bookReq);",
    "        System.out.printf(\"%nBooking: %s - %s%n\",",
    "            bookResult.status(), bookResult.message());",
    "        ",
    "        // Try duplicate booking",
    "        var bookResult2 = system.createBooking(bookReq);",
    "        System.out.printf(\"Duplicate: %s%n\", bookResult2.status());",
    "        ",
    "        System.out.println();",
    "        system.printMetrics();",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-35",
      "explanation": "Imports and constants - defines cache TTLs, lock settings, and enum types for status tracking"
    },
    {
      "lines": "37-120",
      "explanation": "Data models using @dataclass - SearchRequest, SearchResponse, BookingRequest, BookingResponse with all necessary fields"
    },
    {
      "lines": "122-180",
      "explanation": "Event system simulating Kafka - EventBus with publish/subscribe for async event processing"
    },
    {
      "lines": "182-280",
      "explanation": "LRUCache implementation - Thread-safe local cache with TTL, hit/miss tracking, and prefix invalidation"
    },
    {
      "lines": "282-380",
      "explanation": "RedisCache simulation - Distributed cache with lock primitives (acquire/release) and pub/sub"
    },
    {
      "lines": "382-450",
      "explanation": "SearchIndex simulating Elasticsearch - Location index with filters for price, capacity, amenities"
    },
    {
      "lines": "452-550",
      "explanation": "DatabaseShard and ShardedDatabase - Consistent hashing for shard selection, availability tracking"
    },
    {
      "lines": "552-700",
      "explanation": "HotelBookingSystem main class - CQRS setup with event handlers for cache invalidation"
    },
    {
      "lines": "702-780",
      "explanation": "search_rooms_optimized - Multi-tier cache lookup (L1\u2192L2\u2192ES) with staleness tracking"
    },
    {
      "lines": "782-880",
      "explanation": "create_booking - Distributed lock acquisition, availability check, booking insertion, event publishing"
    },
    {
      "lines": "882-1000",
      "explanation": "Demo and testing - Comprehensive demonstration of search caching, booking, race conditions, and metrics"
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "search_rooms_optimized (cache hit)": {
          "complexity": "O(1)",
          "explanation": "Hash lookup in LRU cache or Redis"
        },
        "search_rooms_optimized (cache miss)": {
          "complexity": "O(n * m)",
          "explanation": "n hotels * m rooms per hotel with filter evaluation"
        },
        "create_booking": {
          "complexity": "O(d)",
          "explanation": "d = number of days to book, for availability check"
        },
        "cache_invalidation": {
          "complexity": "O(k)",
          "explanation": "k = number of keys matching prefix pattern"
        }
      },
      "overall_change": "Search latency drops from O(n*m) to O(1) for 90%+ of requests due to caching"
    },
    "space": {
      "additional_space": "O(C + S + E)",
      "explanation": "C = cache capacity (configurable), S = shard data (partitioned), E = event queue (bounded)"
    }
  },
  "dry_run": {
    "example_input": "Search NYC Sept 1-3, then book room R_NYC_1",
    "steps": [
      {
        "step": 1,
        "action": "SearchRequest(NYC, 2024-09-01, 2024-09-03)",
        "state": "L1 cache empty, L2 cache empty",
        "explanation": "First search request arrives"
      },
      {
        "step": 2,
        "action": "Check L1 cache",
        "state": "MISS",
        "explanation": "No entry found with key 'search:nyc:abc123'"
      },
      {
        "step": 3,
        "action": "Check L2 Redis cache",
        "state": "MISS",
        "explanation": "No entry in distributed cache"
      },
      {
        "step": 4,
        "action": "Query SearchIndex (ES)",
        "state": "Found 3 rooms in NYC",
        "explanation": "Full search with filters"
      },
      {
        "step": 5,
        "action": "Check availability for each room",
        "state": "All rooms available",
        "explanation": "Query sharded database"
      },
      {
        "step": 6,
        "action": "Populate L1 and L2 caches",
        "state": "L1[key]=results, L2[key]=results",
        "explanation": "Cache for future requests"
      },
      {
        "step": 7,
        "action": "Return SearchResponse",
        "state": "fromCache=False, latency=45ms",
        "explanation": "First request served from source"
      },
      {
        "step": 8,
        "action": "Second SearchRequest (same params)",
        "state": "L1 cache HIT",
        "explanation": "Identical search request"
      },
      {
        "step": 9,
        "action": "Return cached results",
        "state": "fromCache=True, latency=2ms, staleness=100ms",
        "explanation": "90%+ requests hit cache"
      },
      {
        "step": 10,
        "action": "BookingRequest(R_NYC_1, Sept 1-3)",
        "state": "Acquiring lock",
        "explanation": "Write path begins"
      },
      {
        "step": 11,
        "action": "Redis SETNX lock:room:R_NYC_1:2024-09-01",
        "state": "Lock acquired",
        "explanation": "Distributed lock prevents race"
      },
      {
        "step": 12,
        "action": "Check availability in PostgreSQL",
        "state": "Room available",
        "explanation": "Strong consistency check"
      },
      {
        "step": 13,
        "action": "INSERT booking",
        "state": "Booking BK_ABC123 created",
        "explanation": "Write to primary database"
      },
      {
        "step": 14,
        "action": "Publish BookingConfirmed event",
        "state": "Event in Kafka queue",
        "explanation": "Async notification"
      },
      {
        "step": 15,
        "action": "Release lock, return response",
        "state": "status=CONFIRMED",
        "explanation": "Lock released immediately"
      },
      {
        "step": 16,
        "action": "Event consumer invalidates caches",
        "state": "L1 and L2 cleared for NYC searches",
        "explanation": "Event-driven invalidation"
      }
    ],
    "final_output": "Search: 3 rooms, 45ms (miss) \u2192 2ms (hit). Booking: CONFIRMED, BK_ABC123, 120ms"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "Single search returns expected hotels",
      "Booking confirms and returns booking ID",
      "Second search hits cache (fromCache=True)"
    ],
    "likely_bugs": [
      "Cache key collision (different searches same key)",
      "Lock not released on exception (use finally)",
      "Cache invalidation too aggressive (invalidates unrelated searches)",
      "Shard routing inconsistency (hotel ID hashed differently)"
    ],
    "recommended_logs_or_asserts": [
      "assert booking.room_id in room_to_hotel, 'Room must exist before booking'",
      "log(f'Cache {HIT|MISS}: {cache_key}, staleness={staleness_ms}ms')",
      "log(f'Lock acquired: {lock_key}, owner={owner}')",
      "log(f'Event published: {event_type}, payload={payload}')"
    ],
    "how_to_localize": "1. Add request_id to all logs\n2. Trace: API \u2192 Cache Layer \u2192 Search/Booking \u2192 Database\n3. Check lock acquisition/release pairs\n4. Verify event publication and consumption timing"
  },
  "edge_cases": [
    {
      "case": "Hot hotel (10K concurrent searches)",
      "handling": "L1 cache absorbs 90%+, L2 handles rest, ES only for cold queries",
      "gotcha": "Cache stampede if TTL expires simultaneously - use jittered TTL"
    },
    {
      "case": "Concurrent bookings for same room",
      "handling": "Distributed lock ensures only one succeeds, others get CONFLICT status",
      "gotcha": "Lock timeout too short may cause spurious failures"
    },
    {
      "case": "Cross-region search",
      "handling": "Route to nearest region, results may be slightly stale (2-5s)",
      "gotcha": "User might see room available, then get conflict when booking"
    },
    {
      "case": "Cache invalidation during high traffic",
      "handling": "Async event processing, brief staleness acceptable",
      "gotcha": "Event ordering must be preserved per room_id"
    },
    {
      "case": "Database shard failure",
      "handling": "Circuit breaker, failover to replica, retry with backoff",
      "gotcha": "Partial failures may leave inconsistent state"
    },
    {
      "case": "Very long booking (30+ days)",
      "handling": "Lock covers entire date range, but may timeout",
      "gotcha": "Consider chunking or different lock strategy for long stays"
    }
  ],
  "test_cases": [
    {
      "name": "Search cache miss then hit",
      "input": "Two identical search requests",
      "expected": "First: fromCache=False, Second: fromCache=True with L1_LOCAL",
      "explanation": "Validates multi-tier caching works"
    },
    {
      "name": "Booking invalidates cache",
      "input": "Search, book room, search again",
      "expected": "Third search hits source (cache was invalidated)",
      "explanation": "Event-driven invalidation working"
    },
    {
      "name": "Concurrent booking race",
      "input": "Two users book same room simultaneously",
      "expected": "One CONFIRMED, one CONFLICT",
      "explanation": "Distributed lock prevents double-booking"
    },
    {
      "name": "Search with filters",
      "input": "Search NYC, min_price=200, amenities=['pool']",
      "expected": "Only rooms matching filters returned",
      "explanation": "Elasticsearch-style filtering works"
    },
    {
      "name": "Booking overlapping dates",
      "input": "Book Sept 1-3, then Sept 2-4",
      "expected": "First CONFIRMED, second CONFLICT",
      "explanation": "Date overlap detection works"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Caching availability without invalidation",
      "why_wrong": "Stale availability leads to user frustration when booking fails",
      "correct_approach": "Event-driven invalidation on booking/cancellation",
      "code_example_wrong": "// Cache search results with 1-hour TTL\ncache.set(key, results, 3600)",
      "code_example_correct": "// Short TTL + event invalidation\ncache.set(key, results, 30)\nevent_bus.subscribe('booking.confirmed', invalidate_cache)"
    },
    {
      "mistake": "Using database for distributed locking",
      "why_wrong": "Database locks don't scale, cause connection pool exhaustion",
      "correct_approach": "Use Redis with SETNX + TTL for distributed locks",
      "code_example_wrong": "SELECT * FROM rooms WHERE id=? FOR UPDATE",
      "code_example_correct": "redis.setnx(f'lock:{room_id}:{date}', owner, ex=10)"
    },
    {
      "mistake": "Same consistency model for search and booking",
      "why_wrong": "Strong consistency for search kills throughput; eventual for booking causes double-booking",
      "correct_approach": "CQRS: eventual for search, strong for booking",
      "code_example_wrong": "// All operations go through same strongly-consistent path",
      "code_example_correct": "// Search: cache + ES (eventual)\n// Booking: lock + primary DB (strong)"
    },
    {
      "mistake": "Not handling lock release on exception",
      "why_wrong": "Orphaned locks block all future bookings until TTL expires",
      "correct_approach": "Always release lock in finally block",
      "code_example_wrong": "acquire_lock()\ndo_booking()  # If this throws, lock never released\nrelease_lock()",
      "code_example_correct": "try:\n    acquire_lock()\n    do_booking()\nfinally:\n    release_lock()"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start with the key insight: 'The breakthrough is CQRS - separating read and write paths with different consistency models. Searches can tolerate seconds of staleness, but bookings must be strongly consistent.' Then walk through the architecture diagram before diving into code.",
    "what_to_mention": [
      "Explain WHY eventual consistency is acceptable for search (user will verify at booking)",
      "Discuss cache invalidation strategy (event-driven vs TTL)",
      "Mention hot spot handling (popular hotels need more cache capacity)",
      "Talk about metrics and monitoring (P99 latency, cache hit rate)",
      "Address geographic distribution and data locality"
    ],
    "time_allocation": "2 min requirements clarification, 5 min architecture/diagrams, 5 min caching strategy, 3 min database sharding, 3 min code walkthrough, 2 min edge cases",
    "if_stuck": [
      "Think about what data changes frequently vs rarely",
      "Consider: 'What if I show slightly stale search results?'",
      "Remember: Redis can do more than just caching (locks, pub/sub)",
      "Ask: 'What's the read:write ratio?' (guides optimization focus)"
    ]
  },
  "connection_to_next_part": "Part 4 might focus on: (1) Dynamic pricing based on demand, (2) Multi-room bookings spanning hotels, (3) Reservation hold/timeout patterns, (4) Integration with payment systems, or (5) Analytics and reporting. This solution's event-driven architecture makes it easy to add new consumers for pricing signals, and the sharded database can support cross-shard transactions if needed.",
  "generated_at": "2026-01-17T03:19:16.734999",
  "_meta": {
    "problem_id": "booking_reservation_system",
    "part_number": 3,
    "model": "claude-opus-4-5-20251101"
  }
}