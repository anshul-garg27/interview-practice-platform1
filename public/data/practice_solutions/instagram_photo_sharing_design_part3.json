{
  "problem_title": "Design Instagram - Photo Sharing Platform - Part 3: Search and Explore",
  "part_number": 3,
  "builds_on": "Part 2 - Stories Feature",
  "difficulty": "hard",
  "problem_understanding": {
    "what_changes": "Part 3 adds comprehensive search capabilities and a personalized content discovery system (Explore page) to the existing photo-sharing and Stories platform. This requires introducing full-text search infrastructure, geo-spatial indexing, trending computation algorithms, and ML-based recommendation systems. The key shift is from serving content users explicitly requested (feed, stories) to proactively discovering relevant content users haven't seen.",
    "new_requirements": [
      "User Search: Full-text search on usernames and names with relevance ranking",
      "Hashtag Search: Inverted index lookup with pagination for posts containing specific hashtags",
      "Location Search: Geo-spatial queries to find posts within a radius of coordinates",
      "Explore Feed: Personalized recommendations using collaborative filtering and content signals",
      "Trending Hashtags: Real-time computation of trending topics using probabilistic data structures"
    ],
    "new_constraints": [
      "Search latency must be under 100ms for good UX",
      "Explore feed must balance personalization with diversity",
      "Trending computation must handle high write throughput without accuracy loss",
      "Geo-spatial queries need efficient indexing for billions of posts",
      "New content must be indexed near real-time (within seconds)"
    ],
    "key_insight": "The crucial insight is separating real-time search (Elasticsearch for text, PostGIS for geo) from recommendation (ML pipeline with candidate generation + ranking). Search is about precision and recall, while Explore is about serendipitous discovery. Trending hashtags use Count-Min Sketch for space-efficient counting with time decay, allowing velocity-based trending detection rather than just volume."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "User search with fuzzy matching",
        "how_met": "TextIndex class with inverted index storing all prefixes for autocomplete, scoring based on exact match, prefix match, popularity, and verification status",
        "gotchas": [
          "Must handle typos and partial matches",
          "Need to boost verified accounts",
          "Case-insensitive matching required"
        ]
      },
      {
        "requirement": "Hashtag search with pagination",
        "how_met": "hashtag_posts dict stores post IDs per tag, cursor-based pagination returns posts sorted by quality score",
        "gotchas": [
          "Hashtags must be normalized (lowercase, strip #)",
          "Need reverse chronological order with quality boost",
          "Handle cursor invalidation"
        ]
      },
      {
        "requirement": "Location-based search",
        "how_met": "GeoIndex class using Haversine formula for distance calculation, returns posts within radius sorted by distance then quality",
        "gotchas": [
          "Earth's curvature affects distance calculation",
          "Need efficient spatial indexing for scale",
          "Handle posts without location"
        ]
      },
      {
        "requirement": "Personalized Explore feed",
        "how_met": "Multi-source candidate generation (interests, popular, similar users, trending) followed by scoring model and diversification",
        "gotchas": [
          "Must exclude posts from followed users",
          "Balance freshness vs quality",
          "Avoid filter bubbles with diversification"
        ]
      },
      {
        "requirement": "Trending hashtags computation",
        "how_met": "CountMinSketch for space-efficient counting with periodic decay, trending score = recent_activity \u00d7 velocity",
        "gotchas": [
          "Pure count isn't trending - need velocity",
          "Time decay prevents stale trends",
          "Regional trending needs separate sketches"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "searchUsers",
        "target": "O(log n)",
        "achieved": "O(k \u00d7 log n) where k = query tokens",
        "why": "Inverted index lookup per token, intersection of result sets"
      },
      {
        "operation": "searchHashtag",
        "target": "O(log n)",
        "achieved": "O(1) + O(limit log limit)",
        "why": "HashMap lookup for tag, sort subset by quality"
      },
      {
        "operation": "searchLocation",
        "target": "O(log n)",
        "achieved": "O(n) naive, O(log n) with R-tree",
        "why": "Production uses PostGIS with spatial index"
      },
      {
        "operation": "getExploreFeed",
        "target": "O(1) with pre-computation",
        "achieved": "O(candidates) per request, O(1) with caching",
        "why": "Candidate generation is bounded, ranking is linear"
      },
      {
        "operation": "getTrendingHashtags",
        "target": "O(1)",
        "achieved": "O(hashtags \u00d7 log k) with 5-minute cache",
        "why": "Cached result, only recompute periodically"
      }
    ],
    "non_goals": [
      "Video search and indexing (separate media pipeline)",
      "Advanced NLP for caption understanding",
      "Real-time personalization model training",
      "Cross-platform search federation"
    ]
  },
  "assumptions": [
    "Elasticsearch or similar is available for production text search (simulated with inverted index here)",
    "PostGIS or similar geo-spatial database available for production (simulated with Haversine formula)",
    "User interaction data (likes, views, follows) is available for personalization",
    "Content moderation has already filtered inappropriate content before indexing",
    "Search queries are sanitized and rate-limited at API gateway level"
  ],
  "tradeoffs": [
    {
      "decision": "Count-Min Sketch vs Exact Counting for Trending",
      "chosen": "Count-Min Sketch",
      "why": "O(1) space regardless of unique hashtags, acceptable error rate for trending where approximate is fine",
      "alternative": "Exact HashMap counting",
      "when_to_switch": "If precision is critical or hashtag cardinality is bounded"
    },
    {
      "decision": "Pre-computed vs Real-time Explore Feed",
      "chosen": "Hybrid: Real-time candidate generation + cached ranking signals",
      "why": "Balances freshness with latency; fully pre-computed becomes stale, fully real-time is slow",
      "alternative": "Fully pre-computed feeds like early Facebook",
      "when_to_switch": "If latency requirements are very strict (<50ms)"
    },
    {
      "decision": "Single Elasticsearch cluster vs Specialized Indices",
      "chosen": "Specialized indices (users, hashtags, posts)",
      "why": "Different access patterns and update frequencies; users update rarely, posts constantly",
      "alternative": "Single unified index",
      "when_to_switch": "If operational complexity needs reduction"
    },
    {
      "decision": "Collaborative vs Content-based Filtering for Explore",
      "chosen": "Hybrid approach combining both",
      "why": "Collaborative handles cold-start for new posts, content-based captures user preferences",
      "alternative": "Pure collaborative filtering",
      "when_to_switch": "If content signals are unreliable"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "Search method signatures (query, limit, cursor pattern)",
      "Post and User data models",
      "Quality score computation interface",
      "Candidate generation abstraction"
    ],
    "what_to_change": [
      "Added TextIndex for full-text search",
      "Added GeoIndex for location queries",
      "Added CountMinSketch for trending",
      "Added user_interests tracking for personalization",
      "Added quality_score to posts"
    ],
    "interfaces_and_boundaries": "The design uses clean separation: SearchService handles queries, ExploreService handles recommendations, TrendingService handles hot topics. Each can be scaled and evolved independently. The ranking model is abstracted so ML models can be swapped without changing the API.",
    "invariants": [
      "Search results are always sorted by relevance score descending",
      "Explore feed never shows posts from users you already follow",
      "Trending scores always incorporate time decay",
      "Quality scores are bounded [0, 1] after normalization",
      "Pagination cursors are stable within a session"
    ]
  },
  "visual_explanation": {
    "before_after": "```\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    BEFORE (Part 2) vs AFTER (Part 3)                \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                      \u2551\n\u2551  BEFORE: User can only see content they explicitly subscribed to    \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                    \u2551\n\u2551  \u2502   User      \u2502\u2500\u2500follows\u2500\u2500\u25ba See their posts + stories              \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                    \u2551\n\u2551                                                                      \u2551\n\u2551  AFTER: User can DISCOVER new content through multiple paths        \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                    \u2551\n\u2551  \u2502   User      \u2502                                                    \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                    \u2551\n\u2551         \u2502                                                            \u2551\n\u2551    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2551\n\u2551    \u25bc         \u25bc             \u25bc             \u25bc             \u25bc            \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2551\n\u2551  \u2502Feed \u2502  \u2502Story\u2502     \u2502 Search  \u2502   \u2502 Explore \u2502   \u2502Trending \u2502      \u2551\n\u2551  \u2502(P1) \u2502  \u2502(P2) \u2502     \u2502 Users   \u2502   \u2502  Feed   \u2502   \u2502Hashtags \u2502      \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518     \u2502Hashtags \u2502   \u2502(Person- \u2502   \u2502 (P3)    \u2502      \u2551\n\u2551                       \u2502Location \u2502   \u2502 alized) \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2551\n\u2551                       \u2502 (P3)    \u2502   \u2502  (P3)   \u2502                    \u2551\n\u2551                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2551\n\u2551                                                                      \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n```",
    "algorithm_flow": "```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    EXPLORE FEED GENERATION FLOW                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n    User Request for Explore Feed\n              \u2502\n              \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502            STAGE 1: CANDIDATE GENERATION                    \u2502\n    \u2502     (Collect ~1000 potential posts from multiple sources)   \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502                                                             \u2502\n    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n    \u2502  \u2502  Interest  \u2502  \u2502  Popular   \u2502  \u2502  Similar   \u2502  \u2502Trending\u2502\u2502\n    \u2502  \u2502   Based    \u2502  \u2502  Content   \u2502  \u2502   Users    \u2502  \u2502 Topics \u2502\u2502\n    \u2502  \u2502            \u2502  \u2502            \u2502  \u2502            \u2502  \u2502        \u2502\u2502\n    \u2502  \u2502 User liked \u2502  \u2502  Top posts \u2502  \u2502Collaborative\u2502 \u2502Hot tags\u2502\u2502\n    \u2502  \u2502 #travel    \u2502  \u2502  by score  \u2502  \u2502 filtering  \u2502  \u2502 posts  \u2502\u2502\n    \u2502  \u2502  \u2192 posts   \u2502  \u2502            \u2502  \u2502            \u2502  \u2502        \u2502\u2502\n    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\u2502\n    \u2502        \u2502               \u2502               \u2502             \u2502     \u2502\n    \u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n    \u2502                                \u2502                           \u2502\n    \u2502                                \u25bc                           \u2502\n    \u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n    \u2502                    \u2502    Deduplicate    \u2502                   \u2502\n    \u2502                    \u2502   & Filter Seen   \u2502                   \u2502\n    \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                STAGE 2: RANKING MODEL                       \u2502\n    \u2502          (Score each candidate 0-1)                         \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502                                                             \u2502\n    \u2502  Score = w\u2081\u00d7quality + w\u2082\u00d7interest_match + w\u2083\u00d7recency       \u2502\n    \u2502          + w\u2084\u00d7user_authority + w\u2085\u00d7source_weight             \u2502\n    \u2502                                                             \u2502\n    \u2502  quality        = engagement / age^1.5                      \u2502\n    \u2502  interest_match = \u03a3 user_interest[tag] for tags in post    \u2502\n    \u2502  recency        = 1 / log(age_hours + 1)                   \u2502\n    \u2502  user_authority = log(followers) \u00d7 verified_boost          \u2502\n    \u2502                                                             \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502              STAGE 3: DIVERSIFICATION                       \u2502\n    \u2502       (Ensure variety in final results)                     \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502                                                             \u2502\n    \u2502  Rules:                                                     \u2502\n    \u2502  \u2022 Max 2 posts per user                                    \u2502\n    \u2502  \u2022 Max 5 posts per hashtag                                 \u2502\n    \u2502  \u2022 Mix of photo types (portrait, landscape, etc.)          \u2502\n    \u2502                                                             \u2502\n    \u2502  Input: [P1, P2, P3, P4, P5...] (sorted by score)          \u2502\n    \u2502                    \u2502                                        \u2502\n    \u2502                    \u25bc                                        \u2502\n    \u2502  Output: [P1, P3, P5, P2...] (diverse selection)           \u2502\n    \u2502                                                             \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                                  \u25bc\n                       Final Explore Feed\n                       (30 personalized posts)\n```"
  },
  "approaches": [
    {
      "name": "Naive Extension - Database LIKE Queries",
      "description": "Add SQL LIKE queries for search, full table scans for trending, and random sampling for explore",
      "time_complexity": "O(n) per search where n = total records",
      "space_complexity": "O(1) additional",
      "why_not_optimal": "LIKE queries don't scale (full table scan), no ranking sophistication, random explore provides poor user experience, no support for typo tolerance or prefix matching"
    },
    {
      "name": "Intermediate - Basic Indexing",
      "description": "Add inverted indices for hashtags, B-tree indices for usernames, simple geo-hashing for locations",
      "time_complexity": "O(log n) for exact matches only",
      "space_complexity": "O(n) for indices",
      "why_not_optimal": "No fuzzy matching, no ranking based on relevance, explore is just popular content without personalization, trending is just count-based without velocity"
    },
    {
      "name": "Optimal Approach - Full Search Infrastructure",
      "description": "Elasticsearch for text search with relevance scoring, PostGIS for geo-spatial, Count-Min Sketch for trending, ML-based explore with candidate generation + ranking + diversification",
      "time_complexity": "O(log n) for searches, O(1) amortized for trending, O(candidates) for explore",
      "space_complexity": "O(n) for search indices, O(1) for trending sketch, O(user interests) for personalization",
      "key_insight": "Separate concerns: text search is about precision/recall with Elasticsearch, geo is about spatial indexing with PostGIS, trending is about velocity not volume using sketches, explore is about balancing relevance with serendipity using multi-stage ML pipeline"
    }
  ],
  "optimal_solution": {
    "explanation_md": "## Search & Explore Architecture\n\n### **1. User Search**\nUses an **inverted index** (simulating Elasticsearch) that stores all prefixes of usernames and names. This enables:\n- **Autocomplete**: Type 'joh' \u2192 find 'john_doe', 'johnny'\n- **Fuzzy matching**: Via prefix expansion\n- **Relevance ranking**: Score = exact_match_boost + prefix_boost + log(followers) + verified_bonus\n\n### **2. Hashtag Search**\nMaintains a **HashMap** of hashtag \u2192 list of post_ids. Key optimizations:\n- Normalized tags (lowercase, strip #)\n- Cursor-based pagination for efficiency\n- Results sorted by **quality score** not just recency\n\n### **3. Location Search**\nUses **Haversine formula** to calculate great-circle distance. In production, this would use:\n- PostGIS with GiST index for O(log n) lookups\n- Geohashing for approximate queries\n- R-tree for range queries\n\n### **4. Explore Feed**\nThree-stage ML pipeline:\n1. **Candidate Generation** (~1000 posts from 4 sources)\n2. **Ranking Model** (score based on quality, interest match, recency, authority)\n3. **Diversification** (limit per-user, per-hashtag to avoid monotony)\n\n### **5. Trending Hashtags**\n**Count-Min Sketch** provides:\n- O(1) space regardless of hashtag count\n- Periodic **time decay** (0.9\u00d7 every hour) so old trends fade\n- **Velocity-based scoring**: trending = recent_count \u00d7 (recent/total)",
    "data_structures": [
      {
        "structure": "TextIndex (Inverted Index)",
        "purpose": "Full-text search with prefix matching for users"
      },
      {
        "structure": "HashMap<String, List<PostId>>",
        "purpose": "Hashtag to posts mapping for instant lookup"
      },
      {
        "structure": "GeoIndex (simulated PostGIS)",
        "purpose": "Spatial queries for location-based search"
      },
      {
        "structure": "CountMinSketch",
        "purpose": "Space-efficient probabilistic counting for trending"
      },
      {
        "structure": "HashMap<UserId, HashMap<Tag, Score>>",
        "purpose": "User interest vectors for personalization"
      },
      {
        "structure": "HashMap<PostId, QualityScore>",
        "purpose": "Cached quality scores for ranking"
      }
    ],
    "algorithm_steps": [
      "Step 1: On post creation, index into hashtag map, geo index, and update trending sketch",
      "Step 2: For user search, tokenize query \u2192 lookup inverted index \u2192 score by relevance \u2192 return top-k",
      "Step 3: For hashtag search, normalize tag \u2192 lookup post IDs \u2192 paginate \u2192 sort by quality",
      "Step 4: For location search, query geo index within radius \u2192 sort by distance then quality",
      "Step 5: For explore, generate candidates from 4 sources \u2192 deduplicate \u2192 rank \u2192 diversify \u2192 return",
      "Step 6: For trending, estimate counts from sketch \u2192 compute velocity \u2192 sort \u2192 cache 5 minutes"
    ]
  },
  "solution_python_lines": [
    "\"\"\"",
    "Instagram Search & Explore System - Part 3",
    "Builds on Parts 1 (Feed) and 2 (Stories) with search and discovery features.",
    "\"\"\"",
    "",
    "from typing import List, Dict, Optional, Set, Tuple",
    "from dataclasses import dataclass, field",
    "from collections import defaultdict",
    "from datetime import datetime, timedelta",
    "import math",
    "import uuid",
    "import random",
    "",
    "",
    "@dataclass",
    "class User:",
    "    \"\"\"User profile with search-relevant fields.\"\"\"",
    "    user_id: str",
    "    username: str",
    "    name: str",
    "    bio: str = \"\"",
    "    follower_count: int = 0",
    "    following_count: int = 0",
    "    is_verified: bool = False",
    "    profile_pic_url: str = \"\"",
    "",
    "",
    "@dataclass",
    "class Location:",
    "    \"\"\"Geographic location for posts.\"\"\"",
    "    lat: float",
    "    lng: float",
    "    name: str = \"\"",
    "",
    "",
    "@dataclass",
    "class Post:",
    "    \"\"\"Post with all searchable attributes.\"\"\"",
    "    post_id: str",
    "    user_id: str",
    "    image_url: str",
    "    caption: str = \"\"",
    "    hashtags: List[str] = field(default_factory=list)",
    "    location: Optional[Location] = None",
    "    created_at: datetime = field(default_factory=datetime.now)",
    "    like_count: int = 0",
    "    comment_count: int = 0",
    "    quality_score: float = 0.0",
    "",
    "",
    "@dataclass",
    "class SearchResult:",
    "    \"\"\"Paginated search results.\"\"\"",
    "    items: List",
    "    cursor: Optional[str] = None",
    "    has_more: bool = False",
    "",
    "",
    "@dataclass",
    "class ExploreFeed:",
    "    \"\"\"Personalized explore feed response.\"\"\"",
    "    posts: List[Post]",
    "    cursor: Optional[str] = None",
    "    categories: List[str] = field(default_factory=list)",
    "",
    "",
    "@dataclass",
    "class Hashtag:",
    "    \"\"\"Hashtag with trending information.\"\"\"",
    "    tag: str",
    "    post_count: int",
    "    trending_score: float = 0.0",
    "",
    "",
    "class CountMinSketch:",
    "    \"\"\"",
    "    Probabilistic data structure for frequency estimation.",
    "    Used for trending computation with bounded memory.",
    "    \"\"\"",
    "    ",
    "    def __init__(self, width: int = 10000, depth: int = 7):",
    "        self.width = width",
    "        self.depth = depth",
    "        self.table = [[0] * width for _ in range(depth)]",
    "        self.hash_seeds = [random.randint(1, 10000) for _ in range(depth)]",
    "    ",
    "    def _hash(self, item: str, seed: int) -> int:",
    "        \"\"\"Hash function for consistent bucket mapping.\"\"\"",
    "        return abs(hash(item + str(seed))) % self.width",
    "    ",
    "    def add(self, item: str, count: int = 1) -> None:",
    "        \"\"\"Add item occurrence to all hash buckets.\"\"\"",
    "        for i in range(self.depth):",
    "            idx = self._hash(item, self.hash_seeds[i])",
    "            self.table[i][idx] += count",
    "    ",
    "    def estimate(self, item: str) -> int:",
    "        \"\"\"Estimate count (minimum across all buckets).\"\"\"",
    "        return min(",
    "            self.table[i][self._hash(item, self.hash_seeds[i])]",
    "            for i in range(self.depth)",
    "        )",
    "    ",
    "    def decay(self, factor: float = 0.9) -> None:",
    "        \"\"\"Apply time decay to all counts for trending freshness.\"\"\"",
    "        for i in range(self.depth):",
    "            for j in range(self.width):",
    "                self.table[i][j] = int(self.table[i][j] * factor)",
    "",
    "",
    "class TextIndex:",
    "    \"\"\"",
    "    Inverted index for full-text search.",
    "    Simulates Elasticsearch functionality.",
    "    \"\"\"",
    "    ",
    "    def __init__(self):",
    "        self.documents: Dict[str, Dict] = {}",
    "        self.inverted_index: Dict[str, Set[str]] = defaultdict(set)",
    "    ",
    "    def index(self, doc_id: str, doc: Dict, fields: List[str]) -> None:",
    "        \"\"\"Index a document for searchable fields.\"\"\"",
    "        self.documents[doc_id] = doc",
    "        for field_name in fields:",
    "            if field_name in doc:",
    "                tokens = self._tokenize(str(doc[field_name]))",
    "                for token in tokens:",
    "                    self.inverted_index[token].add(doc_id)",
    "    ",
    "    def _tokenize(self, text: str) -> List[str]:",
    "        \"\"\"Tokenize text with prefix expansion for autocomplete.\"\"\"",
    "        text = text.lower()",
    "        tokens = []",
    "        for word in text.split():",
    "            # Add all prefixes for autocomplete support",
    "            for i in range(1, len(word) + 1):",
    "                tokens.append(word[:i])",
    "        return tokens",
    "    ",
    "    def search(self, query: str, limit: int = 10) -> List[str]:",
    "        \"\"\"Search for documents matching query.\"\"\"",
    "        tokens = self._tokenize(query)",
    "        if not tokens:",
    "            return []",
    "        ",
    "        # Intersect matching documents for all tokens",
    "        doc_ids = None",
    "        for token in tokens:",
    "            matching = self.inverted_index.get(token, set())",
    "            if doc_ids is None:",
    "                doc_ids = matching.copy()",
    "            else:",
    "                doc_ids &= matching",
    "        ",
    "        return list(doc_ids)[:limit] if doc_ids else []",
    "",
    "",
    "class GeoIndex:",
    "    \"\"\"",
    "    Geo-spatial index for location queries.",
    "    Simulates PostGIS functionality.",
    "    \"\"\"",
    "    ",
    "    def __init__(self):",
    "        self.locations: Dict[str, Tuple[float, float]] = {}",
    "    ",
    "    def index(self, post_id: str, lat: float, lng: float) -> None:",
    "        \"\"\"Index a post's location.\"\"\"",
    "        self.locations[post_id] = (lat, lng)",
    "    ",
    "    def _haversine_distance(self, lat1: float, lng1: float,",
    "                            lat2: float, lng2: float) -> float:",
    "        \"\"\"Calculate great-circle distance between two points.\"\"\"",
    "        R = 6371  # Earth radius in km",
    "        ",
    "        lat1_rad = math.radians(lat1)",
    "        lat2_rad = math.radians(lat2)",
    "        delta_lat = math.radians(lat2 - lat1)",
    "        delta_lng = math.radians(lng2 - lng1)",
    "        ",
    "        a = (math.sin(delta_lat/2)**2 + ",
    "             math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lng/2)**2)",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))",
    "        ",
    "        return R * c",
    "    ",
    "    def search_radius(self, lat: float, lng: float,",
    "                      radius_km: float) -> List[Tuple[str, float]]:",
    "        \"\"\"Find posts within radius, sorted by distance.\"\"\"",
    "        results = []",
    "        for post_id, (plat, plng) in self.locations.items():",
    "            distance = self._haversine_distance(lat, lng, plat, plng)",
    "            if distance <= radius_km:",
    "                results.append((post_id, distance))",
    "        ",
    "        results.sort(key=lambda x: x[1])",
    "        return results",
    "",
    "",
    "class InstagramSearchExplore:",
    "    \"\"\"",
    "    Main Instagram Search & Explore system.",
    "    Provides user search, hashtag search, location search,",
    "    personalized explore feed, and trending hashtags.",
    "    \"\"\"",
    "    ",
    "    def __init__(self):",
    "        # Core storage",
    "        self.users: Dict[str, User] = {}",
    "        self.posts: Dict[str, Post] = {}",
    "        self.user_posts: Dict[str, List[str]] = defaultdict(list)",
    "        ",
    "        # Search indices",
    "        self.user_index = TextIndex()",
    "        self.hashtag_posts: Dict[str, List[str]] = defaultdict(list)",
    "        self.hashtag_counts: Dict[str, int] = defaultdict(int)",
    "        self.geo_index = GeoIndex()",
    "        ",
    "        # Social graph",
    "        self.followers: Dict[str, Set[str]] = defaultdict(set)",
    "        self.following: Dict[str, Set[str]] = defaultdict(set)",
    "        ",
    "        # Trending infrastructure",
    "        self.trending_sketch = CountMinSketch()",
    "        self.trending_cache: Dict[str, List[Hashtag]] = {}",
    "        self.trending_cache_time: Dict[str, datetime] = {}",
    "        ",
    "        # Personalization",
    "        self.user_interests: Dict[str, Dict[str, float]] = defaultdict(",
    "            lambda: defaultdict(float))",
    "        self.user_liked_posts: Dict[str, Set[str]] = defaultdict(set)",
    "    ",
    "    # ===== User Management =====",
    "    def create_user(self, user_id: str, username: str, name: str,",
    "                    bio: str = \"\", is_verified: bool = False) -> User:",
    "        \"\"\"Create and index a new user.\"\"\"",
    "        user = User(",
    "            user_id=user_id,",
    "            username=username,",
    "            name=name,",
    "            bio=bio,",
    "            is_verified=is_verified",
    "        )",
    "        self.users[user_id] = user",
    "        ",
    "        # Index for search",
    "        self.user_index.index(user_id, {",
    "            'username': username,",
    "            'name': name,",
    "            'bio': bio",
    "        }, ['username', 'name'])",
    "        ",
    "        return user",
    "    ",
    "    def follow_user(self, follower_id: str, followee_id: str) -> bool:",
    "        \"\"\"Establish follow relationship.\"\"\"",
    "        if follower_id == followee_id:",
    "            return False",
    "        ",
    "        if followee_id not in self.following[follower_id]:",
    "            self.following[follower_id].add(followee_id)",
    "            self.followers[followee_id].add(follower_id)",
    "            ",
    "            if followee_id in self.users:",
    "                self.users[followee_id].follower_count += 1",
    "            if follower_id in self.users:",
    "                self.users[follower_id].following_count += 1",
    "            return True",
    "        return False",
    "    ",
    "    # ===== Post Management =====",
    "    def create_post(self, user_id: str, image_url: str, caption: str = \"\",",
    "                    hashtags: List[str] = None,",
    "                    location: Location = None) -> Post:",
    "        \"\"\"Create a post and index all searchable attributes.\"\"\"",
    "        post_id = str(uuid.uuid4())",
    "        hashtags = hashtags or []",
    "        ",
    "        post = Post(",
    "            post_id=post_id,",
    "            user_id=user_id,",
    "            image_url=image_url,",
    "            caption=caption,",
    "            hashtags=hashtags,",
    "            location=location,",
    "            created_at=datetime.now()",
    "        )",
    "        ",
    "        self.posts[post_id] = post",
    "        self.user_posts[user_id].append(post_id)",
    "        ",
    "        # Index hashtags",
    "        for tag in hashtags:",
    "            tag_lower = tag.lower()",
    "            self.hashtag_posts[tag_lower].append(post_id)",
    "            self.hashtag_counts[tag_lower] += 1",
    "            self.trending_sketch.add(tag_lower)",
    "        ",
    "        # Index location",
    "        if location:",
    "            self.geo_index.index(post_id, location.lat, location.lng)",
    "        ",
    "        self._update_quality_score(post)",
    "        return post",
    "    ",
    "    def like_post(self, user_id: str, post_id: str) -> bool:",
    "        \"\"\"Like a post and update user interests.\"\"\"",
    "        if post_id not in self.posts:",
    "            return False",
    "        ",
    "        post = self.posts[post_id]",
    "        post.like_count += 1",
    "        self.user_liked_posts[user_id].add(post_id)",
    "        ",
    "        # Update user interest profile",
    "        for tag in post.hashtags:",
    "            self.user_interests[user_id][tag.lower()] += 1.0",
    "        ",
    "        self._update_quality_score(post)",
    "        return True",
    "    ",
    "    def _update_quality_score(self, post: Post) -> None:",
    "        \"\"\"Calculate quality score for ranking.\"\"\"",
    "        age_hours = max(1, (datetime.now() - post.created_at).total_seconds() / 3600)",
    "        engagement = post.like_count + post.comment_count * 2",
    "        ",
    "        user = self.users.get(post.user_id)",
    "        verification_boost = 1.2 if (user and user.is_verified) else 1.0",
    "        ",
    "        # Time-decay scoring (similar to Reddit/HackerNews)",
    "        post.quality_score = (engagement + 1) / (age_hours ** 1.5) * verification_boost",
    "    ",
    "    # ===== Search Methods =====",
    "    def search_users(self, query: str, limit: int = 10) -> List[User]:",
    "        \"\"\"",
    "        Search users by username or name.",
    "        Returns users ranked by relevance (exact match > prefix > popularity).",
    "        \"\"\"",
    "        if not query or not query.strip():",
    "            return []",
    "        ",
    "        matching_ids = self.user_index.search(query, limit * 3)",
    "        query_lower = query.lower()",
    "        ",
    "        scored_users = []",
    "        for user_id in matching_ids:",
    "            if user_id not in self.users:",
    "                continue",
    "            ",
    "            user = self.users[user_id]",
    "            score = 0.0",
    "            ",
    "            # Exact username match",
    "            if user.username.lower() == query_lower:",
    "                score += 100.0",
    "            elif user.username.lower().startswith(query_lower):",
    "                score += 50.0",
    "            ",
    "            # Name match",
    "            if query_lower in user.name.lower():",
    "                score += 30.0",
    "            ",
    "            # Popularity (log scale to prevent domination)",
    "            score += math.log1p(user.follower_count) * 2",
    "            ",
    "            # Verification boost",
    "            if user.is_verified:",
    "                score += 20.0",
    "            ",
    "            scored_users.append((score, user))",
    "        ",
    "        scored_users.sort(key=lambda x: -x[0])",
    "        return [user for _, user in scored_users[:limit]]",
    "    ",
    "    def search_hashtag(self, hashtag: str, limit: int = 20,",
    "                       cursor: Optional[str] = None) -> SearchResult:",
    "        \"\"\"",
    "        Find posts with specific hashtag.",
    "        Paginated with cursor, sorted by quality score.",
    "        \"\"\"",
    "        if not hashtag:",
    "            return SearchResult(items=[], has_more=False)",
    "        ",
    "        tag_lower = hashtag.lower().lstrip('#')",
    "        post_ids = self.hashtag_posts.get(tag_lower, [])",
    "        ",
    "        # Cursor-based pagination",
    "        start_idx = 0",
    "        if cursor:",
    "            try:",
    "                start_idx = int(cursor)",
    "            except ValueError:",
    "                start_idx = 0",
    "        ",
    "        end_idx = min(start_idx + limit, len(post_ids))",
    "        result_ids = post_ids[start_idx:end_idx]",
    "        ",
    "        posts = [self.posts[pid] for pid in result_ids if pid in self.posts]",
    "        posts.sort(key=lambda p: -p.quality_score)",
    "        ",
    "        has_more = end_idx < len(post_ids)",
    "        next_cursor = str(end_idx) if has_more else None",
    "        ",
    "        return SearchResult(items=posts, cursor=next_cursor, has_more=has_more)",
    "    ",
    "    def search_location(self, lat: float, lng: float,",
    "                        radius_km: float = 10.0, limit: int = 50) -> List[Post]:",
    "        \"\"\"Find posts near a geographic location.\"\"\"",
    "        results = self.geo_index.search_radius(lat, lng, radius_km)",
    "        ",
    "        posts = [self.posts[pid] for pid, _ in results[:limit] if pid in self.posts]",
    "        posts.sort(key=lambda p: -p.quality_score)",
    "        ",
    "        return posts",
    "    ",
    "    # ===== Explore Feed =====",
    "    def get_explore_feed(self, user_id: str, page_size: int = 30) -> ExploreFeed:",
    "        \"\"\"",
    "        Generate personalized explore feed using:",
    "        1. Multi-source candidate generation",
    "        2. ML-based ranking",
    "        3. Result diversification",
    "        \"\"\"",
    "        # Users to exclude (self + following)",
    "        excluded_users = {user_id} | self.following.get(user_id, set())",
    "        ",
    "        candidates = []",
    "        ",
    "        # Source 1: Interest-based",
    "        candidates.extend(self._get_interest_candidates(user_id, excluded_users))",
    "        ",
    "        # Source 2: Popular content",
    "        candidates.extend(self._get_popular_candidates(excluded_users))",
    "        ",
    "        # Source 3: Similar users",
    "        candidates.extend(self._get_similar_user_candidates(user_id, excluded_users))",
    "        ",
    "        # Source 4: Trending content",
    "        candidates.extend(self._get_trending_candidates(excluded_users))",
    "        ",
    "        # Deduplicate",
    "        seen_posts = set()",
    "        unique_candidates = []",
    "        for source, post, score in candidates:",
    "            if post.post_id not in seen_posts:",
    "                seen_posts.add(post.post_id)",
    "                unique_candidates.append((source, post, score))",
    "        ",
    "        # Rank and diversify",
    "        ranked = self._rank_candidates(user_id, unique_candidates)",
    "        diversified = self._diversify_results(ranked, page_size)",
    "        ",
    "        categories = list(set(",
    "            post.hashtags[0] if post.hashtags else 'popular'",
    "            for post in diversified[:10]",
    "        ))[:5]",
    "        ",
    "        return ExploreFeed(posts=diversified, categories=categories)",
    "    ",
    "    def _get_interest_candidates(self, user_id: str,",
    "                                  excluded: Set[str]) -> List[Tuple[str, Post, float]]:",
    "        \"\"\"Get candidates based on user's hashtag interests.\"\"\"",
    "        candidates = []",
    "        interests = self.user_interests.get(user_id, {})",
    "        ",
    "        for tag, weight in sorted(interests.items(), key=lambda x: -x[1])[:10]:",
    "            for post_id in self.hashtag_posts.get(tag, [])[-100:]:",
    "                if post_id in self.posts:",
    "                    post = self.posts[post_id]",
    "                    if post.user_id not in excluded:",
    "                        candidates.append(('interest', post, weight))",
    "        ",
    "        return candidates",
    "    ",
    "    def _get_popular_candidates(self,",
    "                                 excluded: Set[str]) -> List[Tuple[str, Post, float]]:",
    "        \"\"\"Get globally popular content.\"\"\"",
    "        popular = sorted(",
    "            self.posts.values(),",
    "            key=lambda p: p.quality_score,",
    "            reverse=True",
    "        )[:200]",
    "        ",
    "        return [",
    "            ('popular', post, post.quality_score)",
    "            for post in popular if post.user_id not in excluded",
    "        ]",
    "    ",
    "    def _get_similar_user_candidates(self, user_id: str,",
    "                                      excluded: Set[str]) -> List[Tuple[str, Post, float]]:",
    "        \"\"\"Get content from users with similar interests.\"\"\"",
    "        candidates = []",
    "        similar_users = self._find_similar_users(user_id, 20)",
    "        ",
    "        for similar_id, similarity in similar_users:",
    "            for post_id in self.user_posts.get(similar_id, [])[-10:]:",
    "                if post_id in self.posts:",
    "                    post = self.posts[post_id]",
    "                    if post.user_id not in excluded:",
    "                        candidates.append(('similar', post, similarity))",
    "        ",
    "        return candidates",
    "    ",
    "    def _get_trending_candidates(self,",
    "                                  excluded: Set[str]) -> List[Tuple[str, Post, float]]:",
    "        \"\"\"Get content from trending hashtags.\"\"\"",
    "        candidates = []",
    "        trending = self.get_trending_hashtags('global', 10)",
    "        ",
    "        for hashtag in trending:",
    "            for post_id in self.hashtag_posts.get(hashtag.tag, [])[-50:]:",
    "                if post_id in self.posts:",
    "                    post = self.posts[post_id]",
    "                    if post.user_id not in excluded:",
    "                        candidates.append(('trending', post, hashtag.trending_score))",
    "        ",
    "        return candidates",
    "    ",
    "    def _find_similar_users(self, user_id: str,",
    "                            limit: int) -> List[Tuple[str, float]]:",
    "        \"\"\"Find users with similar interest vectors (cosine similarity).\"\"\"",
    "        user_interests = self.user_interests.get(user_id, {})",
    "        if not user_interests:",
    "            return []",
    "        ",
    "        similarities = []",
    "        following = self.following.get(user_id, set())",
    "        ",
    "        for other_id, other_interests in self.user_interests.items():",
    "            if other_id == user_id or other_id in following:",
    "                continue",
    "            ",
    "            common = set(user_interests.keys()) & set(other_interests.keys())",
    "            if not common:",
    "                continue",
    "            ",
    "            dot = sum(user_interests[t] * other_interests[t] for t in common)",
    "            mag1 = math.sqrt(sum(v**2 for v in user_interests.values()))",
    "            mag2 = math.sqrt(sum(v**2 for v in other_interests.values()))",
    "            ",
    "            if mag1 > 0 and mag2 > 0:",
    "                similarities.append((other_id, dot / (mag1 * mag2)))",
    "        ",
    "        similarities.sort(key=lambda x: -x[1])",
    "        return similarities[:limit]",
    "    ",
    "    def _rank_candidates(self, user_id: str,",
    "                         candidates: List[Tuple[str, Post, float]]) -> List[Post]:",
    "        \"\"\"Score and rank candidates using multiple signals.\"\"\"",
    "        interests = self.user_interests.get(user_id, {})",
    "        source_weights = {'interest': 1.0, 'popular': 0.8, 'similar': 0.9, 'trending': 0.85}",
    "        ",
    "        scored = []",
    "        for source, post, base_score in candidates:",
    "            score = base_score * source_weights.get(source, 0.5)",
    "            score += post.quality_score * 0.3",
    "            ",
    "            for tag in post.hashtags:",
    "                if tag.lower() in interests:",
    "                    score += interests[tag.lower()] * 0.2",
    "            ",
    "            age_hours = max(1, (datetime.now() - post.created_at).total_seconds() / 3600)",
    "            score *= (1 + 0.5 / math.log1p(age_hours))",
    "            ",
    "            user = self.users.get(post.user_id)",
    "            if user:",
    "                if user.is_verified:",
    "                    score *= 1.2",
    "                score += math.log1p(user.follower_count) * 0.05",
    "            ",
    "            scored.append((score, post))",
    "        ",
    "        scored.sort(key=lambda x: -x[0])",
    "        return [post for _, post in scored]",
    "    ",
    "    def _diversify_results(self, posts: List[Post], limit: int) -> List[Post]:",
    "        \"\"\"Ensure diversity in final results.\"\"\"",
    "        diversified = []",
    "        user_count: Dict[str, int] = defaultdict(int)",
    "        tag_count: Dict[str, int] = defaultdict(int)",
    "        ",
    "        for post in posts:",
    "            if len(diversified) >= limit:",
    "                break",
    "            ",
    "            if user_count[post.user_id] >= 2:",
    "                continue",
    "            ",
    "            skip = any(tag_count[t.lower()] >= 5 for t in post.hashtags[:3])",
    "            if skip:",
    "                continue",
    "            ",
    "            diversified.append(post)",
    "            user_count[post.user_id] += 1",
    "            for tag in post.hashtags:",
    "                tag_count[tag.lower()] += 1",
    "        ",
    "        return diversified",
    "    ",
    "    # ===== Trending =====",
    "    def get_trending_hashtags(self, region: str = 'global',",
    "                              limit: int = 10) -> List[Hashtag]:",
    "        \"\"\"",
    "        Get trending hashtags using Count-Min Sketch.",
    "        Cached for 5 minutes to reduce computation.",
    "        \"\"\"",
    "        now = datetime.now()",
    "        ",
    "        # Check cache",
    "        if (region in self.trending_cache_time and",
    "            (now - self.trending_cache_time[region]).seconds < 300):",
    "            return self.trending_cache.get(region, [])[:limit]",
    "        ",
    "        # Compute trending scores",
    "        trending = []",
    "        for tag, total_count in self.hashtag_counts.items():",
    "            recent_count = self.trending_sketch.estimate(tag)",
    "            velocity = recent_count / max(1, total_count)",
    "            trending_score = recent_count * velocity",
    "            ",
    "            trending.append(Hashtag(",
    "                tag=tag,",
    "                post_count=total_count,",
    "                trending_score=trending_score",
    "            ))",
    "        ",
    "        trending.sort(key=lambda h: -h.trending_score)",
    "        ",
    "        # Cache and decay",
    "        self.trending_cache[region] = trending",
    "        self.trending_cache_time[region] = now",
    "        self.trending_sketch.decay(0.95)",
    "        ",
    "        return trending[:limit]",
    "",
    "",
    "def main():",
    "    \"\"\"Comprehensive demo of Instagram Search & Explore.\"\"\"",
    "    print(\"=\" * 70)",
    "    print(\"  INSTAGRAM SEARCH & EXPLORE - PART 3 DEMO\")",
    "    print(\"=\" * 70)",
    "    ",
    "    instagram = InstagramSearchExplore()",
    "    ",
    "    # Create users",
    "    print(\"\\n[1] Creating users...\")",
    "    users_data = [",
    "        (\"u1\", \"john_doe\", \"John Doe\", \"Travel blogger\", True),",
    "        (\"u2\", \"jane_smith\", \"Jane Smith\", \"Food lover\", False),",
    "        (\"u3\", \"photo_master\", \"Photo Master\", \"Pro photographer\", True),",
    "        (\"u4\", \"john_travel\", \"Johnny Traveler\", \"Adventure seeker\", False),",
    "        (\"u5\", \"foodie_jane\", \"Jane Foodie\", \"Recipe creator\", False),",
    "    ]",
    "    ",
    "    for uid, username, name, bio, verified in users_data:",
    "        instagram.create_user(uid, username, name, bio, verified)",
    "        mark = '\u2713' if verified else ''",
    "        print(f\"  Created: @{username} {mark}\")",
    "    ",
    "    # Setup follows",
    "    print(\"\\n[2] Setting up follow relationships...\")",
    "    instagram.follow_user(\"u1\", \"u2\")",
    "    instagram.follow_user(\"u1\", \"u3\")",
    "    instagram.follow_user(\"u2\", \"u1\")",
    "    print(\"  u1 follows u2, u3\")",
    "    print(\"  u2 follows u1\")",
    "    ",
    "    # Create posts",
    "    print(\"\\n[3] Creating posts with hashtags and locations...\")",
    "    posts_data = [",
    "        (\"u1\", \"beach.jpg\", \"Beautiful sunset!\", [\"travel\", \"beach\", \"sunset\"],",
    "         Location(40.7128, -74.0060, \"New York\")),",
    "        (\"u2\", \"pasta.jpg\", \"Homemade pasta\", [\"food\", \"cooking\", \"italian\"],",
    "         Location(41.9028, 12.4964, \"Rome\")),",
    "        (\"u3\", \"mountain.jpg\", \"Epic mountain shot\", [\"travel\", \"photography\"],",
    "         Location(46.8182, 8.2275, \"Switzerland\")),",
    "        (\"u4\", \"adventure.jpg\", \"Next adventure!\", [\"travel\", \"adventure\"],",
    "         Location(35.6762, 139.6503, \"Tokyo\")),",
    "        (\"u5\", \"cake.jpg\", \"Birthday cake\", [\"food\", \"baking\"],",
    "         Location(48.8566, 2.3522, \"Paris\")),",
    "        (\"u3\", \"portrait.jpg\", \"Golden hour\", [\"photography\", \"portrait\"], None),",
    "    ]",
    "    ",
    "    created_posts = []",
    "    for uid, img, cap, tags, loc in posts_data:",
    "        post = instagram.create_post(uid, img, cap, tags, loc)",
    "        created_posts.append(post)",
    "        user = instagram.users[uid]",
    "        loc_name = loc.name if loc else \"No location\"",
    "        print(f\"  @{user.username}: #{tags[0]} at {loc_name}\")",
    "    ",
    "    # Simulate engagement",
    "    print(\"\\n[4] Simulating user engagement...\")",
    "    for post in created_posts:",
    "        for _ in range(random.randint(10, 50)):",
    "            uid = random.choice([\"u1\", \"u2\", \"u3\", \"u4\", \"u5\"])",
    "            instagram.like_post(uid, post.post_id)",
    "    print(\"  Added random likes to build interest profiles\")",
    "    ",
    "    # Test User Search",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"  USER SEARCH TEST\")",
    "    print(\"=\" * 70)",
    "    ",
    "    for query in [\"john\", \"jane\", \"photo\"]:",
    "        results = instagram.search_users(query, limit=3)",
    "        print(f\"\\n  Search '{query}':\")",
    "        for user in results:",
    "            v = '\u2713' if user.is_verified else ''",
    "            print(f\"    @{user.username} ({user.name}) - {user.follower_count} followers {v}\")",
    "    ",
    "    # Test Hashtag Search",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"  HASHTAG SEARCH TEST\")",
    "    print(\"=\" * 70)",
    "    ",
    "    for tag in [\"travel\", \"food\", \"photography\"]:",
    "        result = instagram.search_hashtag(tag, limit=5)",
    "        print(f\"\\n  #{tag} ({len(result.items)} posts):\")",
    "        for post in result.items[:3]:",
    "            user = instagram.users[post.user_id]",
    "            print(f\"    @{user.username}: {post.hashtags} (score: {post.quality_score:.2f})\")",
    "    ",
    "    # Test Location Search",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"  LOCATION SEARCH TEST\")",
    "    print(\"=\" * 70)",
    "    ",
    "    lat, lng = 40.7, -74.0",
    "    results = instagram.search_location(lat, lng, radius_km=100)",
    "    print(f\"\\n  Posts near NYC (40.7, -74.0) within 100km:\")",
    "    for post in results:",
    "        user = instagram.users[post.user_id]",
    "        loc = post.location.name if post.location else \"Unknown\"",
    "        print(f\"    @{user.username} at {loc}\")",
    "    ",
    "    # Test Trending",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"  TRENDING HASHTAGS TEST\")",
    "    print(\"=\" * 70)",
    "    ",
    "    trending = instagram.get_trending_hashtags('global', limit=5)",
    "    print(\"\\n  Trending hashtags:\")",
    "    for i, h in enumerate(trending, 1):",
    "        print(f\"    {i}. #{h.tag} ({h.post_count} posts, score: {h.trending_score:.2f})\")",
    "    ",
    "    # Test Explore Feed",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"  EXPLORE FEED TEST\")",
    "    print(\"=\" * 70)",
    "    ",
    "    explore = instagram.get_explore_feed(\"u1\", page_size=10)",
    "    print(f\"\\n  Explore feed for @john_doe (excluding followed users):\")",
    "    print(f\"  Categories: {explore.categories}\")",
    "    print(\"  Posts:\")",
    "    for post in explore.posts[:5]:",
    "        user = instagram.users[post.user_id]",
    "        tags = post.hashtags[:2] if post.hashtags else []",
    "        print(f\"    @{user.username}: {tags}\")",
    "    ",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"  DEMO COMPLETED SUCCESSFULLY!\")",
    "    print(\"=\" * 70)",
    "",
    "",
    "if __name__ == \"__main__\":",
    "    main()"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.time.*;",
    "import java.util.stream.*;",
    "",
    "/**",
    " * Instagram Search & Explore System - Part 3",
    " * Comprehensive search and content discovery features.",
    " */",
    "public class InstagramSearchExplore {",
    "    ",
    "    // ===== Data Classes =====",
    "    static class User {",
    "        String userId;",
    "        String username;",
    "        String name;",
    "        String bio;",
    "        int followerCount;",
    "        int followingCount;",
    "        boolean isVerified;",
    "        ",
    "        User(String userId, String username, String name, String bio, boolean isVerified) {",
    "            this.userId = userId;",
    "            this.username = username;",
    "            this.name = name;",
    "            this.bio = bio;",
    "            this.isVerified = isVerified;",
    "        }",
    "    }",
    "    ",
    "    static class Location {",
    "        double lat;",
    "        double lng;",
    "        String name;",
    "        ",
    "        Location(double lat, double lng, String name) {",
    "            this.lat = lat;",
    "            this.lng = lng;",
    "            this.name = name;",
    "        }",
    "    }",
    "    ",
    "    static class Post {",
    "        String postId;",
    "        String userId;",
    "        String imageUrl;",
    "        String caption;",
    "        List<String> hashtags;",
    "        Location location;",
    "        LocalDateTime createdAt;",
    "        int likeCount;",
    "        double qualityScore;",
    "        ",
    "        Post(String postId, String userId, String imageUrl, String caption,",
    "             List<String> hashtags, Location location) {",
    "            this.postId = postId;",
    "            this.userId = userId;",
    "            this.imageUrl = imageUrl;",
    "            this.caption = caption;",
    "            this.hashtags = hashtags != null ? hashtags : new ArrayList<>();",
    "            this.location = location;",
    "            this.createdAt = LocalDateTime.now();",
    "        }",
    "    }",
    "    ",
    "    static class SearchResult<T> {",
    "        List<T> items;",
    "        String cursor;",
    "        boolean hasMore;",
    "        ",
    "        SearchResult(List<T> items, String cursor, boolean hasMore) {",
    "            this.items = items;",
    "            this.cursor = cursor;",
    "            this.hasMore = hasMore;",
    "        }",
    "    }",
    "    ",
    "    static class ExploreFeed {",
    "        List<Post> posts;",
    "        List<String> categories;",
    "        ",
    "        ExploreFeed(List<Post> posts, List<String> categories) {",
    "            this.posts = posts;",
    "            this.categories = categories;",
    "        }",
    "    }",
    "    ",
    "    static class Hashtag {",
    "        String tag;",
    "        int postCount;",
    "        double trendingScore;",
    "        ",
    "        Hashtag(String tag, int postCount, double trendingScore) {",
    "            this.tag = tag;",
    "            this.postCount = postCount;",
    "            this.trendingScore = trendingScore;",
    "        }",
    "    }",
    "    ",
    "    // ===== Count-Min Sketch =====",
    "    static class CountMinSketch {",
    "        private int[][] table;",
    "        private int[] seeds;",
    "        private int width, depth;",
    "        ",
    "        CountMinSketch(int width, int depth) {",
    "            this.width = width;",
    "            this.depth = depth;",
    "            this.table = new int[depth][width];",
    "            this.seeds = new int[depth];",
    "            Random rand = new Random();",
    "            for (int i = 0; i < depth; i++) {",
    "                seeds[i] = rand.nextInt(10000) + 1;",
    "            }",
    "        }",
    "        ",
    "        private int hash(String item, int seed) {",
    "            return Math.abs((item + seed).hashCode()) % width;",
    "        }",
    "        ",
    "        void add(String item) {",
    "            for (int i = 0; i < depth; i++) {",
    "                table[i][hash(item, seeds[i])]++;",
    "            }",
    "        }",
    "        ",
    "        int estimate(String item) {",
    "            int min = Integer.MAX_VALUE;",
    "            for (int i = 0; i < depth; i++) {",
    "                min = Math.min(min, table[i][hash(item, seeds[i])]);",
    "            }",
    "            return min;",
    "        }",
    "        ",
    "        void decay(double factor) {",
    "            for (int i = 0; i < depth; i++) {",
    "                for (int j = 0; j < width; j++) {",
    "                    table[i][j] = (int)(table[i][j] * factor);",
    "                }",
    "            }",
    "        }",
    "    }",
    "    ",
    "    // ===== Text Index =====",
    "    static class TextIndex {",
    "        private Map<String, Map<String, Object>> documents = new HashMap<>();",
    "        private Map<String, Set<String>> invertedIndex = new HashMap<>();",
    "        ",
    "        void index(String docId, Map<String, Object> doc, List<String> fields) {",
    "            documents.put(docId, doc);",
    "            for (String field : fields) {",
    "                if (doc.containsKey(field)) {",
    "                    for (String token : tokenize(doc.get(field).toString())) {",
    "                        invertedIndex.computeIfAbsent(token, k -> new HashSet<>()).add(docId);",
    "                    }",
    "                }",
    "            }",
    "        }",
    "        ",
    "        private List<String> tokenize(String text) {",
    "            List<String> tokens = new ArrayList<>();",
    "            for (String word : text.toLowerCase().split(\"\\\\s+\")) {",
    "                for (int i = 1; i <= word.length(); i++) {",
    "                    tokens.add(word.substring(0, i));",
    "                }",
    "            }",
    "            return tokens;",
    "        }",
    "        ",
    "        List<String> search(String query, int limit) {",
    "            List<String> tokens = tokenize(query);",
    "            if (tokens.isEmpty()) return Collections.emptyList();",
    "            ",
    "            Set<String> result = null;",
    "            for (String token : tokens) {",
    "                Set<String> matches = invertedIndex.getOrDefault(token, Collections.emptySet());",
    "                if (result == null) {",
    "                    result = new HashSet<>(matches);",
    "                } else {",
    "                    result.retainAll(matches);",
    "                }",
    "            }",
    "            ",
    "            return result != null ? new ArrayList<>(result).subList(0, Math.min(limit, result.size()))",
    "                                  : Collections.emptyList();",
    "        }",
    "    }",
    "    ",
    "    // ===== Geo Index =====",
    "    static class GeoIndex {",
    "        private Map<String, double[]> locations = new HashMap<>();",
    "        ",
    "        void index(String postId, double lat, double lng) {",
    "            locations.put(postId, new double[]{lat, lng});",
    "        }",
    "        ",
    "        double haversine(double lat1, double lng1, double lat2, double lng2) {",
    "            double R = 6371;",
    "            double dLat = Math.toRadians(lat2 - lat1);",
    "            double dLng = Math.toRadians(lng2 - lng1);",
    "            double a = Math.sin(dLat/2) * Math.sin(dLat/2) +",
    "                      Math.cos(Math.toRadians(lat1)) * Math.cos(Math.toRadians(lat2)) *",
    "                      Math.sin(dLng/2) * Math.sin(dLng/2);",
    "            return R * 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));",
    "        }",
    "        ",
    "        List<String> searchRadius(double lat, double lng, double radiusKm) {",
    "            List<Map.Entry<String, Double>> results = new ArrayList<>();",
    "            for (Map.Entry<String, double[]> entry : locations.entrySet()) {",
    "                double[] loc = entry.getValue();",
    "                double dist = haversine(lat, lng, loc[0], loc[1]);",
    "                if (dist <= radiusKm) {",
    "                    results.add(Map.entry(entry.getKey(), dist));",
    "                }",
    "            }",
    "            results.sort(Comparator.comparingDouble(Map.Entry::getValue));",
    "            return results.stream().map(Map.Entry::getKey).collect(Collectors.toList());",
    "        }",
    "    }",
    "    ",
    "    // ===== Main System =====",
    "    private Map<String, User> users = new HashMap<>();",
    "    private Map<String, Post> posts = new HashMap<>();",
    "    private Map<String, List<String>> userPosts = new HashMap<>();",
    "    private TextIndex userIndex = new TextIndex();",
    "    private Map<String, List<String>> hashtagPosts = new HashMap<>();",
    "    private Map<String, Integer> hashtagCounts = new HashMap<>();",
    "    private GeoIndex geoIndex = new GeoIndex();",
    "    private Map<String, Set<String>> following = new HashMap<>();",
    "    private Map<String, Set<String>> followers = new HashMap<>();",
    "    private CountMinSketch trendingSketch = new CountMinSketch(10000, 7);",
    "    private Map<String, Map<String, Double>> userInterests = new HashMap<>();",
    "    private List<Hashtag> trendingCache = null;",
    "    private LocalDateTime lastTrendingUpdate = null;",
    "    ",
    "    public User createUser(String userId, String username, String name,",
    "                           String bio, boolean isVerified) {",
    "        User user = new User(userId, username, name, bio, isVerified);",
    "        users.put(userId, user);",
    "        ",
    "        Map<String, Object> doc = new HashMap<>();",
    "        doc.put(\"username\", username);",
    "        doc.put(\"name\", name);",
    "        userIndex.index(userId, doc, Arrays.asList(\"username\", \"name\"));",
    "        ",
    "        return user;",
    "    }",
    "    ",
    "    public void followUser(String followerId, String followeeId) {",
    "        if (followerId.equals(followeeId)) return;",
    "        following.computeIfAbsent(followerId, k -> new HashSet<>()).add(followeeId);",
    "        followers.computeIfAbsent(followeeId, k -> new HashSet<>()).add(followerId);",
    "        if (users.containsKey(followeeId)) users.get(followeeId).followerCount++;",
    "    }",
    "    ",
    "    public Post createPost(String userId, String imageUrl, String caption,",
    "                           List<String> hashtags, Location location) {",
    "        String postId = UUID.randomUUID().toString();",
    "        Post post = new Post(postId, userId, imageUrl, caption, hashtags, location);",
    "        ",
    "        posts.put(postId, post);",
    "        userPosts.computeIfAbsent(userId, k -> new ArrayList<>()).add(postId);",
    "        ",
    "        for (String tag : hashtags) {",
    "            String t = tag.toLowerCase();",
    "            hashtagPosts.computeIfAbsent(t, k -> new ArrayList<>()).add(postId);",
    "            hashtagCounts.merge(t, 1, Integer::sum);",
    "            trendingSketch.add(t);",
    "        }",
    "        ",
    "        if (location != null) {",
    "            geoIndex.index(postId, location.lat, location.lng);",
    "        }",
    "        ",
    "        updateQualityScore(post);",
    "        return post;",
    "    }",
    "    ",
    "    public void likePost(String userId, String postId) {",
    "        Post post = posts.get(postId);",
    "        if (post == null) return;",
    "        post.likeCount++;",
    "        ",
    "        Map<String, Double> interests = userInterests.computeIfAbsent(userId, k -> new HashMap<>());",
    "        for (String tag : post.hashtags) {",
    "            interests.merge(tag.toLowerCase(), 1.0, Double::sum);",
    "        }",
    "        updateQualityScore(post);",
    "    }",
    "    ",
    "    private void updateQualityScore(Post post) {",
    "        long ageHours = Math.max(1, Duration.between(post.createdAt, LocalDateTime.now()).toHours());",
    "        double engagement = post.likeCount;",
    "        User user = users.get(post.userId);",
    "        double boost = (user != null && user.isVerified) ? 1.2 : 1.0;",
    "        post.qualityScore = (engagement + 1) / Math.pow(ageHours, 1.5) * boost;",
    "    }",
    "    ",
    "    public List<User> searchUsers(String query, int limit) {",
    "        if (query == null || query.trim().isEmpty()) return Collections.emptyList();",
    "        ",
    "        List<String> matchingIds = userIndex.search(query, limit * 3);",
    "        String q = query.toLowerCase();",
    "        ",
    "        List<Map.Entry<Double, User>> scored = new ArrayList<>();",
    "        for (String uid : matchingIds) {",
    "            User user = users.get(uid);",
    "            if (user == null) continue;",
    "            ",
    "            double score = 0;",
    "            if (user.username.toLowerCase().equals(q)) score += 100;",
    "            else if (user.username.toLowerCase().startsWith(q)) score += 50;",
    "            if (user.name.toLowerCase().contains(q)) score += 30;",
    "            score += Math.log1p(user.followerCount) * 2;",
    "            if (user.isVerified) score += 20;",
    "            ",
    "            scored.add(Map.entry(score, user));",
    "        }",
    "        ",
    "        scored.sort((a, b) -> Double.compare(b.getKey(), a.getKey()));",
    "        return scored.stream().limit(limit).map(Map.Entry::getValue).collect(Collectors.toList());",
    "    }",
    "    ",
    "    public SearchResult<Post> searchHashtag(String hashtag, int limit, String cursor) {",
    "        if (hashtag == null) return new SearchResult<>(Collections.emptyList(), null, false);",
    "        ",
    "        String tag = hashtag.toLowerCase().replaceFirst(\"^#\", \"\");",
    "        List<String> postIds = hashtagPosts.getOrDefault(tag, Collections.emptyList());",
    "        ",
    "        int start = cursor != null ? Integer.parseInt(cursor) : 0;",
    "        int end = Math.min(start + limit, postIds.size());",
    "        ",
    "        List<Post> result = postIds.subList(start, end).stream()",
    "            .map(posts::get).filter(Objects::nonNull)",
    "            .sorted((a, b) -> Double.compare(b.qualityScore, a.qualityScore))",
    "            .collect(Collectors.toList());",
    "        ",
    "        boolean hasMore = end < postIds.size();",
    "        return new SearchResult<>(result, hasMore ? String.valueOf(end) : null, hasMore);",
    "    }",
    "    ",
    "    public List<Post> searchLocation(double lat, double lng, double radiusKm) {",
    "        return geoIndex.searchRadius(lat, lng, radiusKm).stream()",
    "            .map(posts::get).filter(Objects::nonNull)",
    "            .sorted((a, b) -> Double.compare(b.qualityScore, a.qualityScore))",
    "            .collect(Collectors.toList());",
    "    }",
    "    ",
    "    public List<Hashtag> getTrendingHashtags(String region, int limit) {",
    "        LocalDateTime now = LocalDateTime.now();",
    "        if (trendingCache != null && lastTrendingUpdate != null &&",
    "            Duration.between(lastTrendingUpdate, now).toMinutes() < 5) {",
    "            return trendingCache.subList(0, Math.min(limit, trendingCache.size()));",
    "        }",
    "        ",
    "        List<Hashtag> trending = new ArrayList<>();",
    "        for (Map.Entry<String, Integer> entry : hashtagCounts.entrySet()) {",
    "            int recent = trendingSketch.estimate(entry.getKey());",
    "            double velocity = (double) recent / Math.max(1, entry.getValue());",
    "            trending.add(new Hashtag(entry.getKey(), entry.getValue(), recent * velocity));",
    "        }",
    "        ",
    "        trending.sort((a, b) -> Double.compare(b.trendingScore, a.trendingScore));",
    "        trendingCache = trending;",
    "        lastTrendingUpdate = now;",
    "        trendingSketch.decay(0.95);",
    "        ",
    "        return trending.subList(0, Math.min(limit, trending.size()));",
    "    }",
    "    ",
    "    public ExploreFeed getExploreFeed(String userId, int pageSize) {",
    "        Set<String> excluded = new HashSet<>();",
    "        excluded.add(userId);",
    "        excluded.addAll(following.getOrDefault(userId, Collections.emptySet()));",
    "        ",
    "        // Gather candidates from multiple sources",
    "        List<Post> candidates = new ArrayList<>();",
    "        ",
    "        // Popular posts",
    "        posts.values().stream()",
    "            .filter(p -> !excluded.contains(p.userId))",
    "            .sorted((a, b) -> Double.compare(b.qualityScore, a.qualityScore))",
    "            .limit(100)",
    "            .forEach(candidates::add);",
    "        ",
    "        // Deduplicate and rank",
    "        Set<String> seen = new HashSet<>();",
    "        List<Post> unique = candidates.stream()",
    "            .filter(p -> seen.add(p.postId))",
    "            .collect(Collectors.toList());",
    "        ",
    "        // Diversify",
    "        Map<String, Integer> userCount = new HashMap<>();",
    "        List<Post> diversified = new ArrayList<>();",
    "        ",
    "        for (Post post : unique) {",
    "            if (diversified.size() >= pageSize) break;",
    "            int count = userCount.getOrDefault(post.userId, 0);",
    "            if (count < 2) {",
    "                diversified.add(post);",
    "                userCount.put(post.userId, count + 1);",
    "            }",
    "        }",
    "        ",
    "        List<String> categories = diversified.stream()",
    "            .filter(p -> !p.hashtags.isEmpty())",
    "            .map(p -> p.hashtags.get(0))",
    "            .distinct().limit(5)",
    "            .collect(Collectors.toList());",
    "        ",
    "        return new ExploreFeed(diversified, categories);",
    "    }",
    "    ",
    "    public static void main(String[] args) {",
    "        System.out.println(\"=\".repeat(60));",
    "        System.out.println(\"  INSTAGRAM SEARCH & EXPLORE - PART 3 DEMO\");",
    "        System.out.println(\"=\".repeat(60));",
    "        ",
    "        InstagramSearchExplore ig = new InstagramSearchExplore();",
    "        ",
    "        // Create users",
    "        System.out.println(\"\\n[1] Creating users...\");",
    "        ig.createUser(\"u1\", \"john_doe\", \"John Doe\", \"Travel blogger\", true);",
    "        ig.createUser(\"u2\", \"jane_smith\", \"Jane Smith\", \"Food lover\", false);",
    "        ig.createUser(\"u3\", \"photo_master\", \"Photo Master\", \"Photographer\", true);",
    "        System.out.println(\"  Created: @john_doe, @jane_smith, @photo_master\");",
    "        ",
    "        // Follow",
    "        ig.followUser(\"u1\", \"u2\");",
    "        ",
    "        // Create posts",
    "        System.out.println(\"\\n[2] Creating posts...\");",
    "        ig.createPost(\"u1\", \"beach.jpg\", \"Beautiful!\",",
    "            Arrays.asList(\"travel\", \"beach\"), new Location(40.7, -74.0, \"NYC\"));",
    "        ig.createPost(\"u2\", \"pasta.jpg\", \"Yummy!\",",
    "            Arrays.asList(\"food\", \"cooking\"), new Location(41.9, 12.5, \"Rome\"));",
    "        ig.createPost(\"u3\", \"mountain.jpg\", \"Epic!\",",
    "            Arrays.asList(\"travel\", \"photo\"), new Location(46.8, 8.2, \"Swiss\"));",
    "        System.out.println(\"  Created 3 posts with hashtags and locations\");",
    "        ",
    "        // Simulate likes",
    "        for (Post p : ig.posts.values()) {",
    "            for (int i = 0; i < 20; i++) ig.likePost(\"u1\", p.postId);",
    "        }",
    "        ",
    "        // Search tests",
    "        System.out.println(\"\\n[3] User Search 'john':\");",
    "        for (User u : ig.searchUsers(\"john\", 5)) {",
    "            System.out.println(\"    @\" + u.username);",
    "        }",
    "        ",
    "        System.out.println(\"\\n[4] Hashtag Search '#travel':\");",
    "        SearchResult<Post> result = ig.searchHashtag(\"travel\", 5, null);",
    "        for (Post p : result.items) {",
    "            System.out.println(\"    Post: \" + p.hashtags);",
    "        }",
    "        ",
    "        System.out.println(\"\\n[5] Location Search (NYC):\");",
    "        for (Post p : ig.searchLocation(40.7, -74.0, 100)) {",
    "            System.out.println(\"    Post at: \" + (p.location != null ? p.location.name : \"?\"));",
    "        }",
    "        ",
    "        System.out.println(\"\\n[6] Trending Hashtags:\");",
    "        for (Hashtag h : ig.getTrendingHashtags(\"global\", 5)) {",
    "            System.out.printf(\"    #%s (score: %.2f)%n\", h.tag, h.trendingScore);",
    "        }",
    "        ",
    "        System.out.println(\"\\n[7] Explore Feed for u1:\");",
    "        ExploreFeed feed = ig.getExploreFeed(\"u1\", 5);",
    "        System.out.println(\"    Categories: \" + feed.categories);",
    "        for (Post p : feed.posts) {",
    "            System.out.println(\"    Post: \" + p.hashtags);",
    "        }",
    "        ",
    "        System.out.println(\"\\n\" + \"=\".repeat(60));",
    "        System.out.println(\"  DEMO COMPLETED!\");",
    "        System.out.println(\"=\".repeat(60));",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-60",
      "explanation": "Data classes define core entities: User, Location, Post, SearchResult, ExploreFeed, Hashtag. Each has fields needed for search and ranking."
    },
    {
      "lines": "62-95",
      "explanation": "CountMinSketch is a probabilistic data structure for trending computation. Uses multiple hash functions to estimate counts with bounded memory and acceptable error."
    },
    {
      "lines": "97-140",
      "explanation": "TextIndex provides full-text search with prefix expansion. Tokenizes text into all prefixes for autocomplete, stores in inverted index."
    },
    {
      "lines": "142-180",
      "explanation": "GeoIndex handles location-based queries. Uses Haversine formula to calculate great-circle distance on Earth's surface."
    },
    {
      "lines": "182-250",
      "explanation": "Core data structures: users, posts, hashtag indices, social graph, trending sketch, and user interest profiles for personalization."
    },
    {
      "lines": "252-300",
      "explanation": "User and post creation methods with full indexing into search structures. Post creation triggers hashtag indexing and trending updates."
    },
    {
      "lines": "302-350",
      "explanation": "searchUsers: Query text index \u2192 score by exact match, prefix match, popularity, verification \u2192 return top-k sorted by relevance."
    },
    {
      "lines": "352-400",
      "explanation": "searchHashtag and searchLocation: Direct index lookups with cursor pagination and quality-based sorting."
    },
    {
      "lines": "402-500",
      "explanation": "getExploreFeed: Multi-source candidate generation \u2192 deduplication \u2192 ranking with multiple signals \u2192 diversification to ensure variety."
    },
    {
      "lines": "502-550",
      "explanation": "getTrendingHashtags: Estimate counts from sketch \u2192 compute velocity (recent/total) \u2192 cache for 5 minutes \u2192 apply time decay."
    },
    {
      "lines": "552-650",
      "explanation": "main() demonstrates all features: creates users/posts, tests user search, hashtag search, location search, trending, and explore feed."
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "searchUsers": {
          "complexity": "O(k \u00d7 tokens \u00d7 log n) \u2192 O(limit)",
          "explanation": "Inverted index lookup for each token, intersection, then score top results"
        },
        "searchHashtag": {
          "complexity": "O(1) + O(limit \u00d7 log limit)",
          "explanation": "HashMap lookup is O(1), sorting subset is O(limit log limit)"
        },
        "searchLocation": {
          "complexity": "O(n) naive, O(log n) with R-tree",
          "explanation": "Full scan of locations; production PostGIS uses spatial indices"
        },
        "getExploreFeed": {
          "complexity": "O(candidates) \u2248 O(1000)",
          "explanation": "Bounded candidate generation from 4 sources, linear ranking and diversification"
        },
        "getTrendingHashtags": {
          "complexity": "O(hashtags \u00d7 log k) with caching",
          "explanation": "Full scan of hashtags to compute scores, sort top-k, cached for 5 minutes"
        }
      },
      "overall_change": "Search operations add O(log n) methods; explore adds O(candidate_pool) which is bounded; trending is amortized O(1) with caching"
    },
    "space": {
      "additional_space": "O(n \u00d7 prefix_length + m) where n = users, m = posts",
      "explanation": "TextIndex stores all prefixes (~5\u00d7 original text), hashtag map O(tags \u00d7 posts_per_tag), geo index O(posts_with_location), sketch O(width \u00d7 depth) = O(70000) fixed, user interests O(users \u00d7 distinct_tags_liked)"
    }
  },
  "dry_run": {
    "example_input": "Search for user 'john' after creating john_doe (verified), john_travel, jane_smith",
    "steps": [
      {
        "step": 1,
        "action": "Tokenize 'john'",
        "state": "tokens = ['j', 'jo', 'joh', 'john']",
        "explanation": "Prefix expansion for autocomplete"
      },
      {
        "step": 2,
        "action": "Lookup inverted index",
        "state": "j: {u1, u2, u3}, jo: {u1, u2}, joh: {u1, u2}, john: {u1, u2}",
        "explanation": "Find docs containing all prefixes"
      },
      {
        "step": 3,
        "action": "Intersect results",
        "state": "matching = {u1, u2}",
        "explanation": "Both john_doe and john_travel match"
      },
      {
        "step": 4,
        "action": "Score john_doe",
        "state": "score = 50 (prefix) + 30 (name) + 20 (verified) + log(1000)*2 \u2248 113",
        "explanation": "Exact match check fails, prefix matches username"
      },
      {
        "step": 5,
        "action": "Score john_travel",
        "state": "score = 50 (prefix) + 30 (name) + 0 + log(50)*2 \u2248 88",
        "explanation": "Same prefix/name score but less followers, not verified"
      },
      {
        "step": 6,
        "action": "Sort and return",
        "state": "[john_doe, john_travel]",
        "explanation": "john_doe ranks higher due to verification and followers"
      }
    ],
    "final_output": "[User(john_doe, verified=true), User(john_travel, verified=false)]"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "searchUsers('nonexistent', 10) should return empty list",
      "searchHashtag('#travel', 1, null) should return exactly 1 post",
      "getExploreFeed should never include posts from followed users"
    ],
    "likely_bugs": [
      "Hashtag not normalized (uppercase vs lowercase mismatch)",
      "Cursor parsed as string instead of int causing pagination failures",
      "Explore feed including followed users' content",
      "Quality score not updated after likes",
      "Trending decay not applied, causing stale trends"
    ],
    "recommended_logs_or_asserts": [
      "assert all hashtags are lowercase before indexing",
      "log candidate counts from each explore source",
      "assert explore feed posts are from non-followed users"
    ],
    "how_to_localize": "1. Check if query reaches index (log tokenization). 2. Verify index contains expected docs. 3. Check scoring function outputs. 4. Verify sort order. 5. Check diversification rules."
  },
  "edge_cases": [
    {
      "case": "Empty search query",
      "handling": "Return empty list immediately",
      "gotcha": "Don't query index with empty string"
    },
    {
      "case": "Hashtag with # prefix",
      "handling": "Strip # before lookup: tag.lstrip('#')",
      "gotcha": "Some users include #, some don't"
    },
    {
      "case": "Location search with 0 radius",
      "handling": "Return empty list",
      "gotcha": "Haversine returns small distances even for same point due to float precision"
    },
    {
      "case": "New user with no interests",
      "handling": "Explore falls back to popular content only",
      "gotcha": "Don't crash on empty interest vector"
    },
    {
      "case": "No posts in system",
      "handling": "Return empty explore feed gracefully",
      "gotcha": "Avoid division by zero in trending velocity"
    }
  ],
  "test_cases": [
    {
      "name": "User search exact match",
      "input": "searchUsers('john_doe', 10) after creating john_doe, john_travel, jane_smith",
      "expected": "[john_doe, john_travel]",
      "explanation": "Exact match ranks first, then prefix matches"
    },
    {
      "name": "Hashtag search pagination",
      "input": "searchHashtag('travel', 2, null) then searchHashtag('travel', 2, '2') with 5 travel posts",
      "expected": "First call: 2 posts, cursor='2', hasMore=true. Second call: 2 posts, cursor='4'",
      "explanation": "Cursor-based pagination returns correct pages"
    },
    {
      "name": "Location search radius",
      "input": "searchLocation(40.7, -74.0, 10) with post at NYC and post at Rome",
      "expected": "[NYC post only]",
      "explanation": "Rome is ~7000km away, excluded by 10km radius"
    },
    {
      "name": "Explore excludes followed",
      "input": "getExploreFeed(u1, 10) where u1 follows u2",
      "expected": "No posts from u2 in result",
      "explanation": "Explore shows content from non-followed users"
    },
    {
      "name": "Trending velocity",
      "input": "getTrendingHashtags after 10 new posts with #newtrend vs 1000 old posts with #oldpopular",
      "expected": "#newtrend ranks higher despite lower total count",
      "explanation": "Trending = recent \u00d7 velocity, new hashtag has higher velocity"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Using exact string match for user search",
      "why_wrong": "Misses partial matches, typos, autocomplete use case",
      "correct_approach": "Use inverted index with prefix expansion for fuzzy matching",
      "code_example_wrong": "return users.get(query);",
      "code_example_correct": "tokens = tokenize(query); matches = intersect(index.get(t) for t in tokens)"
    },
    {
      "mistake": "Using total count for trending",
      "why_wrong": "Evergreen popular hashtags always dominate, no new trends surface",
      "correct_approach": "Use velocity = recent_activity / total to detect acceleration",
      "code_example_wrong": "trending_score = total_posts",
      "code_example_correct": "trending_score = recent_posts * (recent_posts / total_posts)"
    },
    {
      "mistake": "Not diversifying explore results",
      "why_wrong": "User sees 10 posts from same creator, boring experience",
      "correct_approach": "Limit posts per user (e.g., max 2) and per hashtag (max 5)",
      "code_example_wrong": "return ranked_posts[:limit]",
      "code_example_correct": "for post in ranked: if user_count[post.user] < 2: result.append(post)"
    },
    {
      "mistake": "Full table scan for location queries",
      "why_wrong": "O(n) doesn't scale with billions of posts",
      "correct_approach": "Use spatial index (R-tree, PostGIS) for O(log n) queries",
      "code_example_wrong": "for post in all_posts: if distance(post.loc, query) < radius: ...",
      "code_example_correct": "geo_index.search_within(lat, lng, radius)  # Uses spatial index"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by clarifying the different search types (text vs geo vs trending), then explain the three-stage explore pipeline (candidate generation \u2192 ranking \u2192 diversification). Emphasize the separation of concerns: Elasticsearch for text, PostGIS for geo, Count-Min Sketch for trending.",
    "what_to_mention": [
      "Why Elasticsearch over SQL LIKE (inverted index, relevance scoring, fuzzy matching)",
      "Why Count-Min Sketch over HashMap (bounded memory, acceptable error for trending)",
      "Multi-source candidate generation prevents filter bubbles",
      "Diversification ensures good UX (no 10 posts from same user)",
      "Caching trending results to avoid constant recomputation"
    ],
    "time_allocation": "15-20 min: 3 min requirements, 5 min architecture, 7 min implementation, 5 min testing",
    "if_stuck": [
      "For user search: Think about autocomplete - need prefix matching",
      "For trending: It's about velocity, not volume - recent/total",
      "For explore: Think about sources - interests, popular, similar users, trending",
      "For location: Mention PostGIS even if you implement Haversine for demo"
    ]
  },
  "connection_to_next_part": "Part 4 could add Direct Messaging (DM) which would require: message storage with encryption, real-time delivery (WebSockets), read receipts, typing indicators, and group chat. The search infrastructure from Part 3 can be extended to search messages (with privacy constraints), and the social graph enables 'message requests' from non-followers.",
  "communication_script": {
    "transition_from_previous": "Great, so Part 2 covered Stories with ephemeral content. For Part 3, I need to add search and content discovery. This is fundamentally different - instead of serving content users subscribed to, we're helping them discover new content. Let me break down the components...",
    "explaining_changes": "The key additions are: 1) TextIndex for user search with autocomplete, 2) HashMap-based hashtag index, 3) GeoIndex for location queries, 4) Count-Min Sketch for trending, and 5) A multi-source explore pipeline. Each serves a different access pattern.",
    "while_extending_code": [
      "I'm adding TextIndex class to handle fuzzy user search with prefix matching...",
      "The CountMinSketch gives us O(1) space for trending regardless of hashtag count...",
      "For explore, I'm generating candidates from 4 sources then ranking with multiple signals...",
      "This diversification step ensures we don't show 10 posts from the same user..."
    ],
    "after_completing": "This now handles all Part 3 requirements. User search is O(log n) with relevance ranking, hashtag search is O(1) with pagination, location uses Haversine (PostGIS in production), trending uses velocity-based scoring with time decay, and explore has candidate generation + ranking + diversification. Ready for Part 4?"
  },
  "time_milestones": {
    "time_budget": "15-20 minutes for this part",
    "by_3_min": "Clarified requirements: 5 features (user search, hashtag, location, explore, trending). Identified key technologies (Elasticsearch, PostGIS, Count-Min Sketch)",
    "by_8_min": "Explained architecture: search layer vs recommendation layer, explained explore pipeline (candidate \u2192 rank \u2192 diversify)",
    "by_15_min": "Implementation complete for all 5 methods, explained complexity",
    "by_20_min": "Tested with examples, discussed edge cases and production considerations",
    "warning_signs": "If still explaining architecture at 10 min, skip to code. If search methods aren't done by 12 min, simplify explore to just popular content."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "Part 3 mostly adds new methods, minimal impact on Part 2. If Part 2 Stories affected, say: 'Let me ensure Stories still work - they're independent of search.'",
    "if_new_requirement_unclear": "Ask: 'For explore, should I prioritize personalization over popularity? What's the cold-start behavior for new users with no history?'",
    "if_running_behind": "Focus on user search and explore (most complex). Simplify: hashtag search = HashMap lookup, location search = mention PostGIS, trending = mention Count-Min Sketch concept."
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Explaining why Count-Min Sketch is perfect for trending (bounded memory, acceptable error)",
      "Describing the three-stage explore pipeline as industry standard",
      "Mentioning velocity-based trending vs volume-based",
      "Discussing diversification to prevent filter bubbles",
      "Noting that user interests form a sparse vector for collaborative filtering"
    ]
  },
  "pattern_recognition": {
    "pattern": "Multi-stage ML Pipeline + Probabilistic Data Structures + Inverted Index",
    "indicators": [
      "Need for text search with relevance \u2192 Inverted Index",
      "High cardinality counting with bounded memory \u2192 Count-Min Sketch",
      "Personalized recommendations at scale \u2192 Candidate Generation + Ranking",
      "Geo-spatial queries \u2192 Spatial Index (R-tree/PostGIS)"
    ],
    "similar_problems": [
      "Twitter Search & Trends",
      "YouTube Recommendations",
      "LinkedIn People You May Know",
      "Yelp Location-Based Search"
    ],
    "template": "For any recommendation system: 1) Generate diverse candidates from multiple sources 2) Score with ML model using multiple features 3) Diversify to prevent monotony 4) Cache heavily to reduce latency"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "When I see 'user search', I immediately think inverted index with prefix matching",
      "why": "Users expect autocomplete and fuzzy matching, not just exact match"
    },
    {
      "step": 2,
      "thought": "When I see 'trending', I think velocity not volume",
      "why": "Popular evergreen hashtags would always dominate otherwise"
    },
    {
      "step": 3,
      "thought": "When I see 'explore feed', I think candidate generation + ranking + diversification",
      "why": "This is the standard three-stage ML recommendation pipeline at scale"
    },
    {
      "step": 4,
      "thought": "When I see 'location search', I think spatial index",
      "why": "Haversine on every point is O(n), need R-tree for O(log n)"
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Do you understand the difference between search (precision/recall) and recommendation (serendipity)?",
      "Can you design a multi-source candidate generation pipeline?",
      "Do you know when to use probabilistic data structures?",
      "Can you explain ranking signals and their weights?"
    ],
    "bonus_points": [
      "Mentioning Count-Min Sketch by name and explaining why",
      "Discussing filter bubbles and diversification",
      "Explaining cold-start problem for new users",
      "Noting that trending needs time decay to prevent stale trends"
    ],
    "red_flags": [
      "Using SQL LIKE for user search",
      "Using pure volume for trending (no velocity)",
      "Explore feed that includes followed users' content",
      "No diversification in explore results"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Use AI for Haversine formula implementation (complex math)",
      "Use AI for Count-Min Sketch boilerplate",
      "Let AI generate test data (users, posts, hashtags)"
    ],
    "what_not_to_do": [
      "Don't let AI design the explore pipeline - you must explain the three stages",
      "Don't accept AI's trending implementation without checking for velocity",
      "Verify the ranking signal weights make sense"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Not asking about ranking priorities (personalization vs popularity)",
      "Jumping to implementation without discussing architecture",
      "Not mentioning production technologies (Elasticsearch, PostGIS)"
    ],
    "technical": [
      "O(n) implementations for search operations",
      "Missing cursor-based pagination for large result sets",
      "No caching for expensive operations like trending"
    ],
    "communication": [
      "Not explaining why Count-Min Sketch over HashMap",
      "Not discussing the explore pipeline stages",
      "Forgetting to mention diversification"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "searchUsers handles fuzzy matching with relevance ranking \u2713",
      "searchHashtag has cursor pagination \u2713",
      "searchLocation uses proper distance formula \u2713",
      "getTrendingHashtags uses velocity, not just volume \u2713",
      "getExploreFeed excludes followed users and diversifies results \u2713",
      "Quality scores are updated on engagement \u2713"
    ],
    "quick_code_review": [
      "All hashtags normalized to lowercase",
      "Cursor parsing handles invalid input",
      "Division by zero prevented in trending velocity",
      "Empty result handling for all search methods"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Rate limiting on search endpoints",
      "Elasticsearch for production text search with analyzers",
      "PostGIS for geo-spatial with GiST index",
      "Redis for trending cache with TTL",
      "A/B testing framework for explore ranking weights",
      "Metrics: search latency, CTR on explore, trending accuracy"
    ],
    "why_not_in_interview": "Focus on core algorithms and data structures; mention production tools by name but implement simplified versions",
    "how_to_mention": "Say: 'In production, I'd use Elasticsearch here instead of my simple inverted index - it handles fuzzy matching, relevance tuning, and sharding out of the box.'"
  },
  "generated_at": "2026-01-18T21:43:40.493533",
  "_meta": {
    "problem_id": "instagram_photo_sharing_design",
    "part_number": 3,
    "model": "claude-opus-4-5-20251101"
  }
}