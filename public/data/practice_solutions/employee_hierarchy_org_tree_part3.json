{
  "problem_title": "Employee Hierarchy / Org Tree - Part 3: Generic Aggregation & Filtering",
  "part_number": 3,
  "builds_on": "Part 2",
  "difficulty": "hard",
  "problem_understanding": {
    "what_changes": "Part 3 transforms the OrgChart from a simple hierarchy manager into a mini query engine. We now support SQL-like GROUP BY operations with arbitrary grouping keys, filtering predicates, and aggregation functions. The Employee class is extended with department, level, and salary fields, enabling rich analytics queries.",
    "new_requirements": [
      "addEmployeeExtended: Add employees with department, level, and salary attributes",
      "groupByAggregate: Group all employees by any attribute and apply aggregation (SUM, AVG, MIN, MAX, COUNT)",
      "filterGroupByAggregate: Filter employees first, then group and aggregate",
      "Support functional interfaces (lambdas) for flexible key extraction and value mapping"
    ],
    "new_constraints": [
      "Must support any grouping key (department, level, location, etc.)",
      "Must support any value extractor (salary, rating, level, etc.)",
      "Must support 5 aggregation functions: SUM, AVG, MIN, MAX, COUNT",
      "Operations must be O(n) - single pass through employees"
    ],
    "key_insight": "This is the MapReduce/Stream pattern: Filter \u2192 Map \u2192 GroupBy \u2192 Reduce. By accepting functions as parameters instead of hardcoded fields, we create a flexible query engine. The clever part is collecting values per group first, then applying the aggregation - this handles AVG correctly (need both sum and count)."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Group employees by any attribute",
        "how_met": "key_fn parameter accepts any lambda that extracts a string key from Employee",
        "gotchas": [
          "Null keys need handling",
          "Keys must be consistently typed (convert level to string)"
        ]
      },
      {
        "requirement": "Apply any aggregation function",
        "how_met": "agg_type parameter supports SUM/AVG/MIN/MAX/COUNT, implemented in _aggregate helper",
        "gotchas": [
          "AVG with empty group should return 0",
          "COUNT ignores the actual values"
        ]
      },
      {
        "requirement": "Filter before aggregating",
        "how_met": "filter_fn predicate applied before grouping in filterGroupByAggregate",
        "gotchas": [
          "Filter may result in empty groups - don't include in output",
          "All employees filtered = empty result"
        ]
      },
      {
        "requirement": "Extended Employee attributes",
        "how_met": "Employee dataclass extended with department, level, salary fields",
        "gotchas": [
          "Backward compatibility with Part 1/2 add_employee method"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "groupByAggregate",
        "target": "O(n)",
        "achieved": "O(n)",
        "why": "Single pass through all employees to group, O(k) to aggregate k groups"
      },
      {
        "operation": "filterGroupByAggregate",
        "target": "O(n)",
        "achieved": "O(n)",
        "why": "Filter and group in single pass"
      },
      {
        "operation": "addEmployeeExtended",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "HashMap insertion plus append to parent's list"
      }
    ],
    "non_goals": [
      "Complex SQL-like queries (JOIN, nested GROUP BY)",
      "HAVING clause (filter after aggregation)",
      "Multiple grouping keys",
      "Real-time streaming aggregation"
    ]
  },
  "assumptions": [
    "Aggregation on empty groups returns 0.0 (not undefined/error)",
    "All employees have valid department and level values (no nulls)",
    "Level is 1-5 integer, salary is positive float",
    "Key function always returns non-null string",
    "Value function always returns valid float"
  ],
  "tradeoffs": [
    {
      "decision": "Collect all values then aggregate vs. running aggregation",
      "chosen": "Collect all values first",
      "why": "Required for AVG (need count), MIN/MAX (need all values). Cleaner code, same O(n) complexity.",
      "alternative": "Running aggregation with accumulators",
      "when_to_switch": "If memory is critical and only SUM/COUNT needed"
    },
    {
      "decision": "String keys vs generic comparable keys",
      "chosen": "String keys only",
      "why": "Simpler API, sufficient for department/level/location grouping",
      "alternative": "Generic K extends Comparable<K>",
      "when_to_switch": "If numeric grouping with ordering needed"
    },
    {
      "decision": "Enum vs String for aggregation type",
      "chosen": "String for simplicity in examples",
      "why": "Easier to test and matches problem spec",
      "alternative": "Enum for type safety",
      "when_to_switch": "Production code should use enum"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "Employee base fields (id, name, rating, manager_id, subordinates)",
      "HashMap<id, Employee> storage",
      "Recursive team collection helper"
    ],
    "what_to_change": [
      "Extended Employee fields (department, level, salary)",
      "New aggregation infrastructure (_aggregate helper)",
      "Functional interface parameters"
    ],
    "interfaces_and_boundaries": "The aggregation methods are pure functions over the employee collection - they don't modify state. This separation makes testing easy and allows Part 4 to add caching or indexing without changing the interface.",
    "invariants": [
      "Every employee in _employees dict is reachable from _root via subordinates",
      "Manager-subordinate relationship is consistent (if A's manager is B, then A is in B's subordinates)",
      "No employee has itself as manager (no self-loops)"
    ]
  },
  "visual_explanation": {
    "before_after": "```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502              BEFORE (Part 2)          AFTER (Part 3)        \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                             \u2502\\n\u2502  Employee:                    Employee (Extended):          \u2502\\n\u2502  - id                         - id                          \u2502\\n\u2502  - name                       - name                        \u2502\\n\u2502  - rating                     - rating                      \u2502\\n\u2502  - manager_id                 - manager_id                  \u2502\\n\u2502  - subordinates               - subordinates                \u2502\\n\u2502                               - department  \u2190 NEW           \u2502\\n\u2502                               - level       \u2190 NEW           \u2502\\n\u2502                               - salary      \u2190 NEW           \u2502\\n\u2502                                                             \u2502\\n\u2502  OrgChart Methods:            New Methods:                  \u2502\\n\u2502  - add_employee               - add_employee_extended       \u2502\\n\u2502  - get_team_members           - group_by_aggregate          \u2502\\n\u2502  - get_team_avg_rating        - filter_group_by_aggregate   \u2502\\n\u2502  - find_best_team                                           \u2502\\n\u2502                                                             \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```",
    "algorithm_flow": "```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502            FILTER \u2192 GROUP \u2192 AGGREGATE PIPELINE              \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502                                                             \u2502\\n\u2502  Input: All Employees                                       \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\\n\u2502  \u2502 Alice(Eng,L5,200k) Bob(Eng,L3,120k) Carol(Sales,L4) \u2502   \u2502\\n\u2502  \u2502 Dave(Sales,L2,80k) Eve(Eng,L2,90k) Frank(Sales,L3)  \u2502   \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\\n\u2502                          \u2502                                  \u2502\\n\u2502                          \u25bc                                  \u2502\\n\u2502  Step 1: FILTER (e.level >= 3)                             \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\\n\u2502  \u2502 Alice(Eng,L5,200k) Bob(Eng,L3,120k) Carol(Sales,L4) \u2502   \u2502\\n\u2502  \u2502 Frank(Sales,L3,110k)                                \u2502   \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\\n\u2502                          \u2502                                  \u2502\\n\u2502                          \u25bc                                  \u2502\\n\u2502  Step 2: GROUP BY department                               \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\\n\u2502  \u2502 Engineering:         \u2502  \u2502 Sales:                    \u2502   \u2502\\n\u2502  \u2502  Alice(200k)         \u2502  \u2502  Carol(150k)              \u2502   \u2502\\n\u2502  \u2502  Bob(120k)           \u2502  \u2502  Frank(110k)              \u2502   \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\\n\u2502                          \u2502                                  \u2502\\n\u2502                          \u25bc                                  \u2502\\n\u2502  Step 3: AGGREGATE (AVG salary)                            \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502 Engineering: (200k + 120k) / 2 = 160,000             \u2502  \u2502\\n\u2502  \u2502 Sales:       (150k + 110k) / 2 = 130,000             \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2502                                                             \u2502\\n\u2502  Output: {\\\"Engineering\\\": 160000, \\\"Sales\\\": 130000}         \u2502\\n\u2502                                                             \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```"
  },
  "approaches": [
    {
      "name": "Naive Extension - Hardcoded Methods",
      "description": "Add separate methods for each combination: sumSalaryByDepartment(), avgRatingByLevel(), etc.",
      "time_complexity": "O(n) per method",
      "space_complexity": "O(k) where k is number of groups",
      "why_not_optimal": "Combinatorial explosion: 5 aggregations \u00d7 N possible groupings = many methods. Not extensible - every new attribute requires new methods. Violates DRY principle."
    },
    {
      "name": "Optimal Approach - Functional Abstraction",
      "description": "Accept functions as parameters for key extraction, value extraction, and aggregation. Single generic implementation handles all combinations.",
      "time_complexity": "O(n) for any query",
      "space_complexity": "O(n) worst case if all employees in different groups",
      "key_insight": "By parameterizing the three axes of variation (what to group by, what to aggregate, how to aggregate), we achieve maximum flexibility with minimal code. This is the Strategy Pattern applied to data processing."
    }
  ],
  "optimal_solution": {
    "explanation_md": "## Optimal Solution: Functional Aggregation Pipeline\\n\\nThe solution implements a **mini query engine** using functional programming principles:\\n\\n### Core Design\\n1. **Key Extractor** (`key_fn`): Lambda that pulls grouping key from Employee\\n2. **Value Extractor** (`value_fn`): Lambda that pulls numeric value to aggregate\\n3. **Aggregator** (`agg_type`): Reduction function (SUM/AVG/MIN/MAX/COUNT)\\n\\n### Algorithm\\n```\\nfor each employee:\\n    if passes filter (or no filter):\\n        key = key_fn(employee)\\n        value = value_fn(employee)\\n        groups[key].append(value)\\n\\nfor each (key, values) in groups:\\n    result[key] = aggregate(values, agg_type)\\n```\\n\\n### Why This Works\\n- **Single Pass**: O(n) to group all employees\\n- **Memory Efficient**: Only stores values that pass filter\\n- **Flexible**: Any combination of grouping/aggregation\\n- **Correct AVG**: Collects all values first, then divides sum by count\\n\\n### Edge Case Handling\\n- Empty input \u2192 empty result\\n- All filtered out \u2192 empty result\\n- Single element groups \u2192 handled correctly\\n- AVG of empty list \u2192 returns 0.0",
    "data_structures": [
      {
        "structure": "HashMap<int, Employee>",
        "purpose": "O(1) employee lookup by ID (from Part 1)"
      },
      {
        "structure": "defaultdict(list)",
        "purpose": "Collect values per group during aggregation"
      },
      {
        "structure": "Dict[str, float]",
        "purpose": "Final aggregated results per group"
      }
    ],
    "algorithm_steps": [
      "Step 1: Initialize empty groups dictionary (key \u2192 list of values)",
      "Step 2: Iterate through all employees in _employees.values()",
      "Step 3: If filter_fn provided, check if employee passes filter",
      "Step 4: Extract grouping key using key_fn(employee)",
      "Step 5: Extract numeric value using value_fn(employee)",
      "Step 6: Append value to groups[key] list",
      "Step 7: After all employees processed, iterate groups",
      "Step 8: Apply aggregation function to each group's value list",
      "Step 9: Return final {key \u2192 aggregated_value} dictionary"
    ]
  },
  "solution_python_lines": [
    "from typing import Dict, List, Optional, Callable",
    "from collections import defaultdict",
    "from dataclasses import dataclass, field",
    "",
    "",
    "@dataclass",
    "class Employee:",
    "    \"\"\"Extended Employee with all attributes for Part 3.\"\"\"",
    "    id: int",
    "    name: str",
    "    rating: int",
    "    department: str = \"\"",
    "    level: int = 1",
    "    salary: float = 0.0",
    "    manager_id: Optional[int] = None",
    "    subordinates: List['Employee'] = field(default_factory=list)",
    "",
    "",
    "class OrgChart:",
    "    \"\"\"",
    "    Organizational Chart system supporting:",
    "    - Part 1: Basic add/query operations",
    "    - Part 2: Team performance metrics",
    "    - Part 3: Generic aggregation and filtering",
    "    \"\"\"",
    "",
    "    def __init__(self):",
    "        self._employees: Dict[int, Employee] = {}",
    "        self._root: Optional[Employee] = None",
    "",
    "    # ==================== Part 1 Methods ====================",
    "",
    "    def add_employee(self, id: int, name: str, rating: int,",
    "                     manager_id: Optional[int] = None) -> bool:",
    "        \"\"\"Add employee with basic info.\"\"\"",
    "        if id in self._employees:",
    "            return False",
    "        if manager_id is not None and manager_id not in self._employees:",
    "            return False",
    "",
    "        emp = Employee(id=id, name=name, rating=rating, manager_id=manager_id)",
    "        self._employees[id] = emp",
    "",
    "        if manager_id is None:",
    "            self._root = emp",
    "        else:",
    "            self._employees[manager_id].subordinates.append(emp)",
    "        return True",
    "",
    "    def get_manager(self, employee_id: int) -> Optional[int]:",
    "        \"\"\"Get manager ID of an employee.\"\"\"",
    "        if employee_id not in self._employees:",
    "            return None",
    "        return self._employees[employee_id].manager_id",
    "",
    "    def get_direct_reports(self, manager_id: int) -> List[int]:",
    "        \"\"\"Get direct report IDs.\"\"\"",
    "        if manager_id not in self._employees:",
    "            return []",
    "        return [emp.id for emp in self._employees[manager_id].subordinates]",
    "",
    "    # ==================== Part 2 Methods ====================",
    "",
    "    def _get_team_recursive(self, emp: Employee, team: List[Employee]) -> None:",
    "        \"\"\"Recursively collect all employees in a team.\"\"\"",
    "        team.append(emp)",
    "        for sub in emp.subordinates:",
    "            self._get_team_recursive(sub, team)",
    "",
    "    def get_team_members(self, manager_id: int) -> List[int]:",
    "        \"\"\"Get all team member IDs (including manager).\"\"\"",
    "        if manager_id not in self._employees:",
    "            return []",
    "        team: List[Employee] = []",
    "        self._get_team_recursive(self._employees[manager_id], team)",
    "        return [emp.id for emp in team]",
    "",
    "    def get_team_average_rating(self, manager_id: int) -> float:",
    "        \"\"\"Get average rating of a team.\"\"\"",
    "        if manager_id not in self._employees:",
    "            return 0.0",
    "        team: List[Employee] = []",
    "        self._get_team_recursive(self._employees[manager_id], team)",
    "        if not team:",
    "            return 0.0",
    "        return sum(emp.rating for emp in team) / len(team)",
    "",
    "    def find_best_performing_team(self, min_size: int) -> Optional[int]:",
    "        \"\"\"Find manager with highest average team rating.\"\"\"",
    "        best_manager_id = None",
    "        best_avg = -1.0",
    "        for emp_id, emp in self._employees.items():",
    "            team: List[Employee] = []",
    "            self._get_team_recursive(emp, team)",
    "            if len(team) >= min_size:",
    "                avg = sum(e.rating for e in team) / len(team)",
    "                if avg > best_avg:",
    "                    best_avg = avg",
    "                    best_manager_id = emp_id",
    "        return best_manager_id",
    "",
    "    # ==================== Part 3 Methods ====================",
    "",
    "    def add_employee_extended(self, id: int, name: str, rating: int,",
    "                               dept: str, level: int, salary: float,",
    "                               manager_id: Optional[int] = None) -> bool:",
    "        \"\"\"",
    "        Add employee with extended attributes.",
    "",
    "        Args:",
    "            id: Unique employee ID",
    "            name: Employee name",
    "            rating: Performance rating (1-10)",
    "            dept: Department name",
    "            level: Seniority level (1-5)",
    "            salary: Annual salary",
    "            manager_id: Manager's ID or None for CEO",
    "",
    "        Returns:",
    "            True if added successfully, False otherwise",
    "        \"\"\"",
    "        if id in self._employees:",
    "            return False",
    "        if manager_id is not None and manager_id not in self._employees:",
    "            return False",
    "",
    "        emp = Employee(",
    "            id=id, name=name, rating=rating,",
    "            department=dept, level=level, salary=salary,",
    "            manager_id=manager_id",
    "        )",
    "        self._employees[id] = emp",
    "",
    "        if manager_id is None:",
    "            self._root = emp",
    "        else:",
    "            self._employees[manager_id].subordinates.append(emp)",
    "        return True",
    "",
    "    def _aggregate(self, values: List[float], agg_type: str) -> float:",
    "        \"\"\"",
    "        Apply aggregation function to a list of values.",
    "",
    "        Args:",
    "            values: List of numeric values",
    "            agg_type: One of SUM, AVG, MIN, MAX, COUNT",
    "",
    "        Returns:",
    "            Aggregated result (0.0 for empty list)",
    "        \"\"\"",
    "        if not values:",
    "            return 0.0",
    "",
    "        agg_type = agg_type.upper()",
    "        if agg_type == \"SUM\":",
    "            return sum(values)",
    "        elif agg_type == \"AVG\":",
    "            return sum(values) / len(values)",
    "        elif agg_type == \"MIN\":",
    "            return min(values)",
    "        elif agg_type == \"MAX\":",
    "            return max(values)",
    "        elif agg_type == \"COUNT\":",
    "            return float(len(values))",
    "        else:",
    "            raise ValueError(f\"Unknown aggregation type: {agg_type}\")",
    "",
    "    def group_by_aggregate(",
    "        self,",
    "        key_fn: Callable[[Employee], str],",
    "        value_fn: Callable[[Employee], float],",
    "        agg_type: str",
    "    ) -> Dict[str, float]:",
    "        \"\"\"",
    "        Group employees by key and aggregate values.",
    "",
    "        Like SQL: SELECT key, AGG(value) FROM employees GROUP BY key",
    "",
    "        Args:",
    "            key_fn: Function to extract grouping key from employee",
    "            value_fn: Function to extract value to aggregate",
    "            agg_type: Aggregation type (SUM, AVG, MIN, MAX, COUNT)",
    "",
    "        Returns:",
    "            Dictionary mapping group keys to aggregated values",
    "        \"\"\"",
    "        # Phase 1: Collect values per group",
    "        groups: Dict[str, List[float]] = defaultdict(list)",
    "        for emp in self._employees.values():",
    "            key = key_fn(emp)",
    "            value = value_fn(emp)",
    "            groups[key].append(value)",
    "",
    "        # Phase 2: Apply aggregation to each group",
    "        result: Dict[str, float] = {}",
    "        for key, values in groups.items():",
    "            result[key] = self._aggregate(values, agg_type)",
    "        return result",
    "",
    "    def filter_group_by_aggregate(",
    "        self,",
    "        filter_fn: Callable[[Employee], bool],",
    "        key_fn: Callable[[Employee], str],",
    "        value_fn: Callable[[Employee], float],",
    "        agg_type: str",
    "    ) -> Dict[str, float]:",
    "        \"\"\"",
    "        Filter employees, then group and aggregate.",
    "",
    "        Like SQL: SELECT key, AGG(value) FROM employees",
    "                  WHERE condition GROUP BY key",
    "",
    "        Args:",
    "            filter_fn: Predicate to filter employees",
    "            key_fn: Function to extract grouping key",
    "            value_fn: Function to extract value to aggregate",
    "            agg_type: Aggregation type (SUM, AVG, MIN, MAX, COUNT)",
    "",
    "        Returns:",
    "            Dictionary mapping group keys to aggregated values",
    "        \"\"\"",
    "        # Phase 1: Filter and collect values per group",
    "        groups: Dict[str, List[float]] = defaultdict(list)",
    "        for emp in self._employees.values():",
    "            if filter_fn(emp):  # Apply filter first",
    "                key = key_fn(emp)",
    "                value = value_fn(emp)",
    "                groups[key].append(value)",
    "",
    "        # Phase 2: Apply aggregation to each group",
    "        result: Dict[str, float] = {}",
    "        for key, values in groups.items():",
    "            result[key] = self._aggregate(values, agg_type)",
    "        return result",
    "",
    "",
    "def main():",
    "    \"\"\"Demo of Part 3: Generic Aggregation & Filtering.\"\"\"",
    "    print(\"=\" * 60)",
    "    print(\"Part 3: Generic Aggregation & Filtering Demo\")",
    "    print(\"=\" * 60)",
    "",
    "    org = OrgChart()",
    "",
    "    # Build organization with extended attributes",
    "    print(\"\\n Building organization...\")",
    "    org.add_employee_extended(1, \"Alice\", 8, \"Engineering\", 5, 200000.0, None)",
    "    org.add_employee_extended(2, \"Bob\", 7, \"Engineering\", 3, 120000.0, 1)",
    "    org.add_employee_extended(3, \"Carol\", 6, \"Sales\", 4, 150000.0, 1)",
    "    org.add_employee_extended(4, \"Dave\", 5, \"Sales\", 2, 80000.0, 3)",
    "    org.add_employee_extended(5, \"Eve\", 9, \"Engineering\", 2, 90000.0, 2)",
    "    org.add_employee_extended(6, \"Frank\", 6, \"Sales\", 3, 110000.0, 3)",
    "",
    "    print(\"\\nOrganization Structure:\")",
    "    print(\"                Alice (CEO, Eng, L5, 200k)\")",
    "    print(\"               /                         \\\\\")",
    "    print(\"     Bob (Eng, L3, 120k)          Carol (Sales, L4, 150k)\")",
    "    print(\"           |                        /              \\\\\")",
    "    print(\"     Eve (Eng, L2, 90k)    Dave (Sales,L2,80k)  Frank (Sales,L3,110k)\")",
    "",
    "    # Test 1: Group by department, sum salary",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"Test 1: Total Salary by Department (SUM)\")",
    "    print(\"=\" * 60)",
    "    result = org.group_by_aggregate(",
    "        key_fn=lambda e: e.department,",
    "        value_fn=lambda e: e.salary,",
    "        agg_type=\"SUM\"",
    "    )",
    "    print(f\"Result: {result}\")",
    "    print(\"Expected: Engineering=410000, Sales=340000\")",
    "",
    "    # Test 2: Group by department, average rating",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"Test 2: Average Rating by Department (AVG)\")",
    "    print(\"=\" * 60)",
    "    result = org.group_by_aggregate(",
    "        key_fn=lambda e: e.department,",
    "        value_fn=lambda e: float(e.rating),",
    "        agg_type=\"AVG\"",
    "    )",
    "    print(f\"Result: {result}\")",
    "    print(\"Expected: Engineering=8.0, Sales=5.67\")",
    "",
    "    # Test 3: Group by level, count",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"Test 3: Employee Count by Level (COUNT)\")",
    "    print(\"=\" * 60)",
    "    result = org.group_by_aggregate(",
    "        key_fn=lambda e: f\"Level {e.level}\",",
    "        value_fn=lambda e: 1.0,",
    "        agg_type=\"COUNT\"",
    "    )",
    "    print(f\"Result: {result}\")",
    "",
    "    # Test 4: Filter + Group + Aggregate",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"Test 4: Avg Salary of Senior (L>=3) by Dept\")",
    "    print(\"=\" * 60)",
    "    result = org.filter_group_by_aggregate(",
    "        filter_fn=lambda e: e.level >= 3,",
    "        key_fn=lambda e: e.department,",
    "        value_fn=lambda e: e.salary,",
    "        agg_type=\"AVG\"",
    "    )",
    "    print(f\"Result: {result}\")",
    "    print(\"Senior Eng: Alice(200k)+Bob(120k) avg=160k\")",
    "    print(\"Senior Sales: Carol(150k)+Frank(110k) avg=130k\")",
    "",
    "    # Test 5: High performers - MAX salary",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"Test 5: Max Salary of High Performers (rating>=7)\")",
    "    print(\"=\" * 60)",
    "    result = org.filter_group_by_aggregate(",
    "        filter_fn=lambda e: e.rating >= 7,",
    "        key_fn=lambda e: e.department,",
    "        value_fn=lambda e: e.salary,",
    "        agg_type=\"MAX\"",
    "    )",
    "    print(f\"Result: {result}\")",
    "",
    "    # Test 6: From problem example",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"Test 6: Problem Example - 4 employees\")",
    "    print(\"=\" * 60)",
    "    org2 = OrgChart()",
    "    org2.add_employee_extended(1, \"Alice\", 8, \"Engineering\", 5, 200000, None)",
    "    org2.add_employee_extended(2, \"Bob\", 7, \"Engineering\", 3, 120000, 1)",
    "    org2.add_employee_extended(3, \"Carol\", 6, \"Sales\", 4, 150000, 1)",
    "    org2.add_employee_extended(4, \"Dave\", 5, \"Sales\", 2, 80000, 3)",
    "    result = org2.group_by_aggregate(",
    "        key_fn=lambda e: e.department,",
    "        value_fn=lambda e: e.salary,",
    "        agg_type=\"SUM\"",
    "    )",
    "    print(f\"Result: {result}\")",
    "    print(\"Expected: Engineering=320000, Sales=230000\")",
    "",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"All Part 3 tests completed!\")",
    "    print(\"=\" * 60)",
    "",
    "",
    "if __name__ == \"__main__\":",
    "    main()"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.util.function.*;",
    "import java.util.stream.*;",
    "",
    "class Employee {",
    "    int id;",
    "    String name;",
    "    int rating;",
    "    String department;",
    "    int level;",
    "    double salary;",
    "    Integer managerId;",
    "    List<Employee> subordinates;",
    "",
    "    public Employee(int id, String name, int rating) {",
    "        this(id, name, rating, \"\", 1, 0.0, null);",
    "    }",
    "",
    "    public Employee(int id, String name, int rating,",
    "                    String dept, int level, double salary, Integer managerId) {",
    "        this.id = id;",
    "        this.name = name;",
    "        this.rating = rating;",
    "        this.department = dept;",
    "        this.level = level;",
    "        this.salary = salary;",
    "        this.managerId = managerId;",
    "        this.subordinates = new ArrayList<>();",
    "    }",
    "",
    "    public String getDepartment() { return department; }",
    "    public int getLevel() { return level; }",
    "    public double getSalary() { return salary; }",
    "    public int getRating() { return rating; }",
    "}",
    "",
    "public class OrgChart {",
    "    private Map<Integer, Employee> employees;",
    "    private Employee root;",
    "",
    "    public OrgChart() {",
    "        employees = new HashMap<>();",
    "        root = null;",
    "    }",
    "",
    "    // ==================== Part 1 Methods ====================",
    "",
    "    public boolean addEmployee(int id, String name, int rating, Integer managerId) {",
    "        if (employees.containsKey(id)) return false;",
    "        if (managerId != null && !employees.containsKey(managerId)) return false;",
    "",
    "        Employee emp = new Employee(id, name, rating);",
    "        emp.managerId = managerId;",
    "        employees.put(id, emp);",
    "",
    "        if (managerId == null) {",
    "            root = emp;",
    "        } else {",
    "            employees.get(managerId).subordinates.add(emp);",
    "        }",
    "        return true;",
    "    }",
    "",
    "    public Integer getManager(int employeeId) {",
    "        if (!employees.containsKey(employeeId)) return null;",
    "        return employees.get(employeeId).managerId;",
    "    }",
    "",
    "    public List<Integer> getDirectReports(int managerId) {",
    "        if (!employees.containsKey(managerId)) return new ArrayList<>();",
    "        return employees.get(managerId).subordinates.stream()",
    "                .map(e -> e.id).collect(Collectors.toList());",
    "    }",
    "",
    "    // ==================== Part 2 Methods ====================",
    "",
    "    private void getTeamRecursive(Employee emp, List<Employee> team) {",
    "        team.add(emp);",
    "        for (Employee sub : emp.subordinates) {",
    "            getTeamRecursive(sub, team);",
    "        }",
    "    }",
    "",
    "    public List<Integer> getTeamMembers(int managerId) {",
    "        if (!employees.containsKey(managerId)) return new ArrayList<>();",
    "        List<Employee> team = new ArrayList<>();",
    "        getTeamRecursive(employees.get(managerId), team);",
    "        return team.stream().map(e -> e.id).collect(Collectors.toList());",
    "    }",
    "",
    "    public double getTeamAverageRating(int managerId) {",
    "        if (!employees.containsKey(managerId)) return 0.0;",
    "        List<Employee> team = new ArrayList<>();",
    "        getTeamRecursive(employees.get(managerId), team);",
    "        if (team.isEmpty()) return 0.0;",
    "        return team.stream().mapToInt(e -> e.rating).average().orElse(0.0);",
    "    }",
    "",
    "    // ==================== Part 3 Methods ====================",
    "",
    "    public boolean addEmployeeExtended(int id, String name, int rating,",
    "                                       String dept, int level, double salary,",
    "                                       Integer managerId) {",
    "        if (employees.containsKey(id)) return false;",
    "        if (managerId != null && !employees.containsKey(managerId)) return false;",
    "",
    "        Employee emp = new Employee(id, name, rating, dept, level, salary, managerId);",
    "        employees.put(id, emp);",
    "",
    "        if (managerId == null) {",
    "            root = emp;",
    "        } else {",
    "            employees.get(managerId).subordinates.add(emp);",
    "        }",
    "        return true;",
    "    }",
    "",
    "    private double aggregate(List<Double> values, String aggType) {",
    "        if (values.isEmpty()) return 0.0;",
    "",
    "        switch (aggType.toUpperCase()) {",
    "            case \"SUM\":",
    "                return values.stream().mapToDouble(Double::doubleValue).sum();",
    "            case \"AVG\":",
    "                return values.stream().mapToDouble(Double::doubleValue).average().orElse(0.0);",
    "            case \"MIN\":",
    "                return values.stream().mapToDouble(Double::doubleValue).min().orElse(0.0);",
    "            case \"MAX\":",
    "                return values.stream().mapToDouble(Double::doubleValue).max().orElse(0.0);",
    "            case \"COUNT\":",
    "                return (double) values.size();",
    "            default:",
    "                throw new IllegalArgumentException(\"Unknown aggregation: \" + aggType);",
    "        }",
    "    }",
    "",
    "    public Map<String, Double> groupByAggregate(",
    "            Function<Employee, String> keyFn,",
    "            Function<Employee, Double> valueFn,",
    "            String aggType) {",
    "",
    "        // Phase 1: Collect values per group",
    "        Map<String, List<Double>> groups = new HashMap<>();",
    "        for (Employee emp : employees.values()) {",
    "            String key = keyFn.apply(emp);",
    "            double value = valueFn.apply(emp);",
    "            groups.computeIfAbsent(key, k -> new ArrayList<>()).add(value);",
    "        }",
    "",
    "        // Phase 2: Aggregate each group",
    "        Map<String, Double> result = new HashMap<>();",
    "        for (Map.Entry<String, List<Double>> entry : groups.entrySet()) {",
    "            result.put(entry.getKey(), aggregate(entry.getValue(), aggType));",
    "        }",
    "        return result;",
    "    }",
    "",
    "    public Map<String, Double> filterGroupByAggregate(",
    "            Predicate<Employee> filterFn,",
    "            Function<Employee, String> keyFn,",
    "            Function<Employee, Double> valueFn,",
    "            String aggType) {",
    "",
    "        // Phase 1: Filter and collect values per group",
    "        Map<String, List<Double>> groups = new HashMap<>();",
    "        for (Employee emp : employees.values()) {",
    "            if (filterFn.test(emp)) {",
    "                String key = keyFn.apply(emp);",
    "                double value = valueFn.apply(emp);",
    "                groups.computeIfAbsent(key, k -> new ArrayList<>()).add(value);",
    "            }",
    "        }",
    "",
    "        // Phase 2: Aggregate each group",
    "        Map<String, Double> result = new HashMap<>();",
    "        for (Map.Entry<String, List<Double>> entry : groups.entrySet()) {",
    "            result.put(entry.getKey(), aggregate(entry.getValue(), aggType));",
    "        }",
    "        return result;",
    "    }",
    "",
    "    public static void main(String[] args) {",
    "        System.out.println(\"Part 3: Generic Aggregation & Filtering Demo\");",
    "        System.out.println(\"=\".repeat(60));",
    "",
    "        OrgChart org = new OrgChart();",
    "",
    "        // Build organization",
    "        org.addEmployeeExtended(1, \"Alice\", 8, \"Engineering\", 5, 200000.0, null);",
    "        org.addEmployeeExtended(2, \"Bob\", 7, \"Engineering\", 3, 120000.0, 1);",
    "        org.addEmployeeExtended(3, \"Carol\", 6, \"Sales\", 4, 150000.0, 1);",
    "        org.addEmployeeExtended(4, \"Dave\", 5, \"Sales\", 2, 80000.0, 3);",
    "",
    "        // Test 1: Total salary by department",
    "        System.out.println(\"\\nTest 1: Total Salary by Department (SUM)\");",
    "        Map<String, Double> result = org.groupByAggregate(",
    "            e -> e.getDepartment(),",
    "            e -> e.getSalary(),",
    "            \"SUM\"",
    "        );",
    "        System.out.println(\"Result: \" + result);",
    "        System.out.println(\"Expected: Engineering=320000, Sales=230000\");",
    "",
    "        // Test 2: Average rating by department",
    "        System.out.println(\"\\nTest 2: Average Rating by Department (AVG)\");",
    "        result = org.groupByAggregate(",
    "            e -> e.getDepartment(),",
    "            e -> (double) e.getRating(),",
    "            \"AVG\"",
    "        );",
    "        System.out.println(\"Result: \" + result);",
    "",
    "        // Test 3: Filter + group + aggregate",
    "        System.out.println(\"\\nTest 3: Avg Salary of Senior (L>=3) by Dept\");",
    "        result = org.filterGroupByAggregate(",
    "            e -> e.getLevel() >= 3,",
    "            e -> e.getDepartment(),",
    "            e -> e.getSalary(),",
    "            \"AVG\"",
    "        );",
    "        System.out.println(\"Result: \" + result);",
    "",
    "        System.out.println(\"\\nAll tests completed!\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-5",
      "explanation": "Imports: typing for type hints, defaultdict for automatic list creation, dataclass for clean Employee definition"
    },
    {
      "lines": "8-17",
      "explanation": "Extended Employee dataclass with new fields: department, level, salary. Uses default values for backward compatibility with Part 1/2"
    },
    {
      "lines": "20-27",
      "explanation": "OrgChart class with same storage from Part 1/2: HashMap for O(1) lookup, root reference for tree traversal"
    },
    {
      "lines": "31-45",
      "explanation": "Part 1 add_employee preserved for backward compatibility - creates Employee with default extended fields"
    },
    {
      "lines": "62-80",
      "explanation": "Part 2 methods preserved: recursive team collection and average rating calculation"
    },
    {
      "lines": "98-120",
      "explanation": "add_employee_extended: Creates Employee with all fields populated. Same logic as add_employee but with extended data"
    },
    {
      "lines": "122-142",
      "explanation": "_aggregate helper: Central aggregation logic. Handles empty list case, supports all 5 aggregation types with clean switch"
    },
    {
      "lines": "144-170",
      "explanation": "group_by_aggregate: Two-phase algorithm. Phase 1 iterates employees, extracts key/value, groups into lists. Phase 2 applies aggregation to each group"
    },
    {
      "lines": "172-210",
      "explanation": "filter_group_by_aggregate: Same as group_by_aggregate but with filter check before adding to groups. Filter predicate is first condition in loop"
    },
    {
      "lines": "213-280",
      "explanation": "main() demo: Builds 6-person org, demonstrates all aggregation types and filtering scenarios with expected outputs"
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "addEmployeeExtended": {
          "complexity": "O(1)",
          "explanation": "HashMap put + list append"
        },
        "groupByAggregate": {
          "complexity": "O(n)",
          "explanation": "Single pass through n employees to group, O(k) to aggregate k groups. Total O(n+k) = O(n) since k \u2264 n"
        },
        "filterGroupByAggregate": {
          "complexity": "O(n)",
          "explanation": "Same single pass with filter check (O(1) per employee)"
        },
        "_aggregate": {
          "complexity": "O(m)",
          "explanation": "Linear in number of values m in the group"
        }
      },
      "overall_change": "Part 3 operations are O(n). No degradation to Part 1/2 operations which remain O(1) for lookups, O(team_size) for team queries"
    },
    "space": {
      "additional_space": "O(n)",
      "explanation": "During aggregation, worst case stores all n employees' values if each has unique key. Employee class adds 3 fields (constant per employee). Total additional space: O(n) for groups dictionary during query"
    }
  },
  "dry_run": {
    "example_input": "4 employees: Alice(Eng,200k), Bob(Eng,120k), Carol(Sales,150k), Dave(Sales,80k). Query: SUM salary by department",
    "steps": [
      {
        "step": 1,
        "action": "Initialize empty groups dict",
        "state": "groups = {}",
        "explanation": "Starting aggregation"
      },
      {
        "step": 2,
        "action": "Process Alice",
        "state": "groups = {'Engineering': [200000]}",
        "explanation": "key='Engineering', value=200000"
      },
      {
        "step": 3,
        "action": "Process Bob",
        "state": "groups = {'Engineering': [200000, 120000]}",
        "explanation": "Same key, append to list"
      },
      {
        "step": 4,
        "action": "Process Carol",
        "state": "groups = {'Engineering': [200000, 120000], 'Sales': [150000]}",
        "explanation": "New key 'Sales'"
      },
      {
        "step": 5,
        "action": "Process Dave",
        "state": "groups = {'Engineering': [200000, 120000], 'Sales': [150000, 80000]}",
        "explanation": "Append to 'Sales'"
      },
      {
        "step": 6,
        "action": "Aggregate Engineering",
        "state": "result = {'Engineering': 320000}",
        "explanation": "SUM([200000, 120000]) = 320000"
      },
      {
        "step": 7,
        "action": "Aggregate Sales",
        "state": "result = {'Engineering': 320000, 'Sales': 230000}",
        "explanation": "SUM([150000, 80000]) = 230000"
      }
    ],
    "final_output": "{'Engineering': 320000, 'Sales': 230000}"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "Single employee: groupByAggregate should return {dept: salary}",
      "Empty org: should return empty dict {}",
      "All filtered out: filterGroupByAggregate with always-false filter returns {}"
    ],
    "likely_bugs": [
      "Integer division in AVG (Python 2 style) - always use float division",
      "Forgetting to handle empty groups list in _aggregate",
      "Not converting rating to float before aggregating",
      "Using wrong field in lambda (e.rating vs e.salary)"
    ],
    "recommended_logs_or_asserts": [
      "assert len(self._employees) > 0, 'No employees added'",
      "Log groups dict before aggregation to verify grouping",
      "Print intermediate values: f'Processing {emp.name}: key={key}, value={value}'"
    ],
    "how_to_localize": "1. Print the groups dict after Phase 1 to verify grouping is correct. 2. Check each group's values list. 3. Test _aggregate independently with known values. 4. Compare expected vs actual for one group at a time."
  },
  "edge_cases": [
    {
      "case": "Empty organization",
      "handling": "groups dict stays empty, result is empty dict",
      "gotcha": "Don't return None, return empty dict {}"
    },
    {
      "case": "All employees filtered out",
      "handling": "No values added to any group, result is empty dict",
      "gotcha": "filterGroupByAggregate with impossible condition should not throw"
    },
    {
      "case": "Single employee in a group",
      "handling": "AVG of single value = that value, MIN = MAX = that value",
      "gotcha": "Division by 1 is fine, but ensure list isn't empty"
    },
    {
      "case": "Unknown aggregation type",
      "handling": "Raise ValueError with clear message",
      "gotcha": "Should fail fast, not return 0 or None silently"
    },
    {
      "case": "Level or rating as grouping key (numeric)",
      "handling": "Convert to string: f'Level {e.level}'",
      "gotcha": "Key function must return string, not int"
    }
  ],
  "test_cases": [
    {
      "name": "Basic SUM by department",
      "input": "4 employees from problem example, groupByAggregate(dept, salary, SUM)",
      "expected": "{'Engineering': 320000, 'Sales': 230000}",
      "explanation": "Eng: 200k+120k=320k, Sales: 150k+80k=230k"
    },
    {
      "name": "AVG rating by department",
      "input": "Same 4 employees, groupByAggregate(dept, rating, AVG)",
      "expected": "{'Engineering': 7.5, 'Sales': 5.5}",
      "explanation": "Eng: (8+7)/2=7.5, Sales: (6+5)/2=5.5"
    },
    {
      "name": "Filter seniors then SUM",
      "input": "6 employees, filterGroupByAggregate(level>=3, dept, salary, SUM)",
      "expected": "{'Engineering': 320000, 'Sales': 260000}",
      "explanation": "Seniors only: Alice+Bob in Eng, Carol+Frank in Sales"
    },
    {
      "name": "COUNT by level",
      "input": "6 employees, groupByAggregate(level, 1.0, COUNT)",
      "expected": "{'5': 1, '3': 2, '4': 1, '2': 2}",
      "explanation": "L5:1, L4:1, L3:2, L2:2 employees"
    },
    {
      "name": "MIN/MAX salary",
      "input": "4 employees, groupByAggregate(dept, salary, MIN)",
      "expected": "{'Engineering': 120000, 'Sales': 80000}",
      "explanation": "Lowest salary per department"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Integer division for AVG",
      "why_wrong": "In some languages, sum(ints)/count gives integer. E.g., (8+7)/2 = 7 not 7.5",
      "correct_approach": "Always use float: sum(values) / float(len(values)) or ensure values are floats",
      "code_example_wrong": "return sum(values) // len(values)  # Wrong: integer division",
      "code_example_correct": "return sum(values) / len(values)  # Correct: float division"
    },
    {
      "mistake": "Not handling empty groups",
      "why_wrong": "min([]) or sum([])/len([]) throws exception",
      "correct_approach": "Check if values list is empty, return 0.0 as default",
      "code_example_wrong": "return sum(values) / len(values)  # Crashes on empty",
      "code_example_correct": "if not values: return 0.0\\nreturn sum(values) / len(values)"
    },
    {
      "mistake": "Modifying employee during aggregation",
      "why_wrong": "Lambda like e.level += 1 has side effects, corrupts data",
      "correct_approach": "Lambdas should be pure functions - read only, no mutations",
      "code_example_wrong": "key_fn=lambda e: (e.level := e.level + 1)  # Mutation!",
      "code_example_correct": "key_fn=lambda e: str(e.level + 1)  # Pure transformation"
    },
    {
      "mistake": "Hardcoding field names instead of using lambdas",
      "why_wrong": "Defeats the purpose of generic aggregation, not extensible",
      "correct_approach": "Accept lambdas as parameters, caller decides what to extract",
      "code_example_wrong": "def sumSalaryByDept(self):  # Hardcoded method",
      "code_example_correct": "def groupByAggregate(self, key_fn, value_fn, agg):  # Generic"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by drawing the Filter\u2192Group\u2192Aggregate pipeline. Explain it's like SQL GROUP BY. Show the two-phase approach: collect then aggregate. Emphasize the flexibility of accepting functions as parameters.",
    "what_to_mention": [
      "This is the Strategy Pattern - aggregation strategy is injected",
      "Two-phase approach handles AVG correctly (need all values first)",
      "O(n) time - single pass through employees",
      "Functional programming makes it extensible without code changes"
    ],
    "time_allocation": "2 min understand requirements, 3 min explain approach, 8 min implement, 2 min test",
    "if_stuck": [
      "Think about SQL: how would you write this query?",
      "Start with hardcoded version (sumSalaryByDept), then generalize",
      "What data structure collects values per group? HashMap<key, List>"
    ]
  },
  "connection_to_next_part": "Part 3 established a query engine pattern. Part 4 might add: (1) HAVING clause - filter after aggregation, (2) Multiple grouping keys - GROUP BY dept, level, (3) Caching/indexing for repeated queries, (4) Streaming aggregation for real-time updates, (5) Custom aggregation functions beyond the 5 built-ins.",
  "communication_script": {
    "transition_from_previous": "Great, Part 2 is working with team metrics. For Part 3, I need to add a generic query engine that can group by any attribute and apply any aggregation. This is like implementing SQL GROUP BY.",
    "explaining_changes": "The key change is accepting functions as parameters instead of hardcoding fields. I'll add key_fn to extract grouping key, value_fn to extract the value, and agg_type to specify the reduction. This gives us flexibility without writing dozens of methods.",
    "while_extending_code": [
      "First, I'm extending Employee with department, level, salary fields...",
      "Now adding the aggregation helper that handles SUM, AVG, MIN, MAX, COUNT...",
      "The groupByAggregate method has two phases: collect values per group, then aggregate..."
    ],
    "after_completing": "This now handles Part 3. Both methods are O(n) - single pass through employees. The functional approach means we can query by any attribute without code changes. Ready for Part 4!"
  },
  "time_milestones": {
    "time_budget": "15-20 minutes for this part",
    "by_2_min": "Understand functional interface requirement, recognize Filter-Group-Aggregate pattern",
    "by_5_min": "Explain two-phase approach, start extending Employee class",
    "by_10_min": "Implement _aggregate helper and groupByAggregate",
    "by_15_min": "Complete filterGroupByAggregate, test with examples",
    "warning_signs": "If still designing at 7 min, simplify. Start with hardcoded version if stuck on lambdas."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "Part 3 is mostly independent - only shares Employee and storage. If Part 2 bug affects you, mention it and continue with Part 3.",
    "if_new_requirement_unclear": "Ask: 'Should AVG of empty group return 0 or undefined?' and 'What if filter excludes all employees?'",
    "if_running_behind": "Skip filterGroupByAggregate, implement only groupByAggregate first. The filter version is trivial extension."
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Recognizing this is MapReduce/Stream pattern immediately",
      "Mentioning SQL analogy: SELECT key, AGG(value) GROUP BY key",
      "Discussing why two-phase (collect then aggregate) is necessary for AVG",
      "Suggesting optimizations: indexing by department for faster grouped queries",
      "Mentioning Java Streams or Python itertools as alternative implementations"
    ]
  },
  "pattern_recognition": {
    "pattern": "MapReduce / Stream Processing (Filter-Map-GroupBy-Reduce)",
    "indicators": [
      "Group by any attribute - suggests parameterized grouping",
      "Apply any aggregation - suggests strategy pattern for reduction",
      "Filter before aggregating - suggests pipeline/stream approach"
    ],
    "similar_problems": [
      "LC 1193 - Monthly Transactions (GROUP BY)",
      "LC 1341 - Movie Rating (aggregation queries)",
      "Design problems: Log aggregation, Analytics dashboard, Time-series metrics"
    ],
    "template": "```\\ngroups = defaultdict(list)\\nfor item in items:\\n    if filter(item):\\n        key = extract_key(item)\\n        value = extract_value(item)\\n        groups[key].append(value)\\nreturn {k: aggregate(v) for k, v in groups.items()}\\n```"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "When I see 'group by any attribute', I think Strategy Pattern - parameterize the grouping key",
      "why": "Hardcoding each attribute would be O(attributes) methods"
    },
    {
      "step": 2,
      "thought": "Multiple aggregation functions suggests a centralized aggregator",
      "why": "DRY principle - one _aggregate method handles all types"
    },
    {
      "step": 3,
      "thought": "AVG requires knowing both sum and count, so can't do running aggregation",
      "why": "Must collect all values first, then divide"
    },
    {
      "step": 4,
      "thought": "Filter before group is more efficient than filter after",
      "why": "Reduces data processed in grouping phase"
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Can you design flexible APIs with functional parameters?",
      "Do you understand aggregation semantics (especially AVG)?",
      "Can you extend existing code without rewriting?",
      "Do you recognize the MapReduce pattern?"
    ],
    "bonus_points": [
      "Mentioning SQL analogy shows database knowledge",
      "Discussing single-pass optimization",
      "Handling edge cases proactively (empty groups)",
      "Clean separation between collection and aggregation phases"
    ],
    "red_flags": [
      "Writing separate method for each field (sumByDept, avgByLevel, etc.)",
      "Not understanding why AVG needs all values",
      "Mutating employees during aggregation",
      "O(n\u00b2) solution by re-filtering for each group"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Use AI for boilerplate like dataclass fields",
      "Let it suggest aggregation function implementations",
      "Ask it to generate test cases"
    ],
    "what_not_to_do": [
      "Don't blindly accept a Stream-heavy solution if you can't explain it",
      "Verify the AVG implementation handles empty lists",
      "Understand the functional interface types before using"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Diving into code without explaining the two-phase approach",
      "Not asking about edge cases (empty groups, all filtered)"
    ],
    "technical": [
      "Integer division bug in AVG calculation",
      "Creating new data structures that duplicate existing storage",
      "Not leveraging existing _employees dict"
    ],
    "communication": [
      "Not explaining why functions as parameters enable flexibility",
      "Forgetting to trace through an example"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Both methods return correct results for problem example?",
      "AVG handles both single-value and multi-value groups correctly?",
      "Empty filter result returns {} not None?",
      "All 5 aggregation types (SUM, AVG, MIN, MAX, COUNT) work?"
    ],
    "quick_code_review": [
      "Type hints on all new methods",
      "Docstrings explaining parameters",
      "No mutation of employees during aggregation",
      "Consistent naming with Part 1/2"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Input validation on aggregation type",
      "Logging for query execution time",
      "Caching for repeated identical queries",
      "Index by department for O(1) department lookups"
    ],
    "why_not_in_interview": "Focus on core algorithm correctness. Mention these optimizations verbally to show production awareness.",
    "how_to_mention": "Say: 'In production, I'd add an index by department so groupByDepartment is O(department_size) not O(n). Also cache frequent queries.'"
  },
  "generated_at": "2026-01-18T18:33:00.037608",
  "_meta": {
    "problem_id": "employee_hierarchy_org_tree",
    "part_number": 3,
    "model": "claude-opus-4-5-20251101"
  }
}