{
  "problem_title": "Production-Ready Event Ticket Booking API - Part 4: Production Readiness",
  "part_number": 4,
  "builds_on": "Part 3",
  "difficulty": "hard",
  "problem_understanding": {
    "what_changes": "Part 4 adds comprehensive production infrastructure: health checks to verify system status, metrics collection for observability, rate limiting to prevent abuse, and structured logging for debugging and audit trails. This transforms our functional API into a production-ready system that can be monitored, maintained, and scaled.",
    "new_requirements": [
      "Health check endpoint returning component status",
      "Metrics collection with latency percentiles",
      "Multi-tier rate limiting (global, per-user, per-endpoint)",
      "Structured JSON logging with request tracing",
      "Sensitive data masking in logs"
    ],
    "new_constraints": [
      "Rate limit check must be O(1) amortized",
      "Health check must verify all critical dependencies",
      "Logs must never contain sensitive data",
      "Metrics must support P50/P95/P99 latency calculations"
    ],
    "key_insight": "Observability is not optional - you cannot debug, scale, or maintain what you cannot measure. The sliding window algorithm provides O(1) rate limiting while maintaining accuracy, and structured logging enables distributed tracing across microservices."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Health check with dependency verification",
        "how_met": "healthCheck() method queries database/cache status and returns JSON with all component statuses",
        "gotchas": [
          "Don't make health checks expensive - they're called frequently",
          "Timeout quickly on dependency checks"
        ]
      },
      {
        "requirement": "Multi-tier rate limiting",
        "how_met": "SlidingWindowRateLimiter class with separate instances for global/user/endpoint limits",
        "gotchas": [
          "Clock synchronization in distributed systems",
          "Memory growth from storing timestamps"
        ]
      },
      {
        "requirement": "Metrics with percentiles",
        "how_met": "MetricsCollector with ring buffer stores recent latencies, calculates percentiles on demand",
        "gotchas": [
          "Percentile calculation on sorted data",
          "Window size affects accuracy vs memory"
        ]
      },
      {
        "requirement": "Structured logging",
        "how_met": "StructuredLogger outputs JSON with request_id for tracing, masks sensitive fields",
        "gotchas": [
          "Ensure consistent field names across services",
          "Log rotation and retention policies"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "checkRateLimit",
        "target": "O(1) amortized",
        "achieved": "O(1) amortized",
        "why": "Sliding window with lazy cleanup - only remove expired entries on access"
      },
      {
        "operation": "healthCheck",
        "target": "O(d)",
        "achieved": "O(d)",
        "why": "Must check d dependencies, no way around it"
      },
      {
        "operation": "getMetrics",
        "target": "O(n log n)",
        "achieved": "O(n log n)",
        "why": "Sorting for percentile calculation, where n = window size (bounded constant)"
      }
    ],
    "non_goals": [
      "Distributed rate limiting across servers (needs Redis)",
      "Persistent metric storage (needs time-series DB)",
      "Alerting implementation (needs external service)"
    ]
  },
  "assumptions": [
    "Single-server deployment for now (distributed rate limiting would need Redis/Memcached)",
    "Metrics window size is bounded (1000 requests), making percentile calculation effectively O(1)",
    "Health check timeout is 5 seconds max per dependency",
    "Log output goes to stdout (container/K8s will handle aggregation)",
    "Request IDs are generated at API gateway level and passed in headers"
  ],
  "tradeoffs": [
    {
      "decision": "Sliding Window Log vs Token Bucket for rate limiting",
      "chosen": "Sliding Window Log",
      "why": "More accurate, no burst allowance that could overwhelm the system",
      "alternative": "Token Bucket",
      "when_to_switch": "If you need to allow controlled bursts or have memory constraints"
    },
    {
      "decision": "In-memory metrics vs External metrics service",
      "chosen": "In-memory with bounded buffer",
      "why": "Simpler for interview, no external dependencies",
      "alternative": "Prometheus/StatsD",
      "when_to_switch": "Production multi-server deployment"
    },
    {
      "decision": "Eager vs Lazy cleanup of expired rate limit entries",
      "chosen": "Lazy cleanup",
      "why": "O(1) amortized vs O(n) periodic cleanup",
      "alternative": "Background thread cleanup",
      "when_to_switch": "If memory is very constrained"
    },
    {
      "decision": "Percentile calculation on read vs write",
      "chosen": "On read",
      "why": "Writes are more frequent, keep them fast",
      "alternative": "Approximate streaming algorithms (t-digest)",
      "when_to_switch": "Millions of requests per second"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "Response class structure",
      "Rate limit check interface",
      "Log entry format"
    ],
    "what_to_change": [
      "Added MetricsCollector, SlidingWindowRateLimiter, StructuredLogger",
      "Extended TicketAPI with production methods"
    ],
    "interfaces_and_boundaries": "Rate limiter and logger are injected dependencies, allowing easy swap for distributed implementations. Metrics follow OpenMetrics format for Prometheus compatibility.",
    "invariants": [
      "Rate limit state is eventually consistent within window",
      "Logs never contain unmasked sensitive data",
      "Health check always returns within timeout"
    ]
  },
  "visual_explanation": {
    "before_after": "```\\nBEFORE (Part 3):                    AFTER (Part 4):\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502     TicketAPI       \u2502             \u2502     TicketAPI       \u2502\\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524             \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\\n\u2502 - events            \u2502             \u2502 - events            \u2502\\n\u2502 - bookings          \u2502             \u2502 - bookings          \u2502\\n\u2502 - locks             \u2502             \u2502 - locks             \u2502\\n\u2502 - auth tokens       \u2502             \u2502 - auth tokens       \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502 + rateLimiters      \u2502\\n         \u2502                          \u2502 + metricsCollector  \u2502\\n         \u2502                          \u2502 + logger            \u2502\\n         \u25bc                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n   Just handles                              \u2502\\n   requests                                  \u25bc\\n                                    Observes, limits,\\n                                    logs everything\\n```",
    "algorithm_flow": "```\\n      RATE LIMITING FLOW (Sliding Window)\\n      \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\\n\\n    Request arrives at t=100\\n              \u2502\\n              \u25bc\\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502  Window: [t-60, t] = [40, 100]     \u2502\\n    \u2502                                     \u2502\\n    \u2502  Timestamps: [42, 55, 78, 91, 95]  \u2502\\n    \u2502  (5 requests in window)            \u2502\\n    \u2502                                     \u2502\\n    \u2502  Max allowed: 10                    \u2502\\n    \u2502  Current: 5                         \u2502\\n    \u2502  \u2192 ALLOWED \u2713                       \u2502\\n    \u2502                                     \u2502\\n    \u2502  Add timestamp 100 to window        \u2502\\n    \u2502  New: [42, 55, 78, 91, 95, 100]    \u2502\\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\\n    Later request at t=101, limit reached:\\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502  Window now has 10 entries          \u2502\\n    \u2502  \u2192 REJECTED \u2717                      \u2502\\n    \u2502  Return 429 Too Many Requests       \u2502\\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\\n\\n      HEALTH CHECK FLOW\\n      \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\\n\\n    healthCheck() called\\n              \u2502\\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502                   \u2502\\n    \u25bc                   \u25bc\\n  Check DB          Check Cache\\n    \u2502                   \u2502\\n    \u25bc                   \u25bc\\n  timeout?          timeout?\\n  error?            error?\\n    \u2502                   \u2502\\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n              \u2502\\n              \u25bc\\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502  {                              \u2502\\n    \u2502    status: all_ok ? healthy     \u2502\\n    \u2502            : degraded,          \u2502\\n    \u2502    checks: {                    \u2502\\n    \u2502      database: connected/err,   \u2502\\n    \u2502      cache: connected/err       \u2502\\n    \u2502    },                           \u2502\\n    \u2502    uptime: calculate_uptime()   \u2502\\n    \u2502  }                              \u2502\\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```"
  },
  "approaches": [
    {
      "name": "Naive Extension - Simple Counter Rate Limiting",
      "description": "Use a simple counter that resets every minute. Each request increments counter, reject if over limit.",
      "time_complexity": "O(1)",
      "space_complexity": "O(u) where u = users",
      "why_not_optimal": "Fixed window creates burst problem at window boundaries. User could make 100 requests at 0:59 and 100 more at 1:01, effectively 200 in 2 seconds. Also doesn't handle per-endpoint limits cleanly."
    },
    {
      "name": "Optimal Approach - Sliding Window Log",
      "description": "Store timestamps of each request in a deque. On each check, remove expired timestamps (lazy cleanup), then count remaining. Allows precise rate limiting without boundary burst issues.",
      "time_complexity": "O(1) amortized - cleanup amortized across requests",
      "space_complexity": "O(r) where r = max requests per window per key",
      "key_insight": "By storing individual timestamps and lazily cleaning up, we get accurate sliding window semantics with amortized O(1) operations. The space is bounded by the rate limit itself."
    }
  ],
  "optimal_solution": {
    "explanation_md": "## Production Readiness Implementation\\n\\n### Key Components:\\n\\n1. **SlidingWindowRateLimiter**: Uses a deque per key (user+endpoint combination) to store request timestamps. On each request:\\n   - Remove all timestamps older than window_start\\n   - Count remaining timestamps\\n   - If under limit, add current timestamp and allow\\n   - If at/over limit, reject with 429\\n\\n2. **MetricsCollector**: Maintains bounded ring buffers for:\\n   - Request latencies (for percentile calculation)\\n   - Request timestamps (for RPS calculation)\\n   - Error count and total request count\\n\\n3. **StructuredLogger**: Outputs JSON-formatted logs with:\\n   - Request ID for distributed tracing\\n   - Automatic masking of sensitive fields\\n   - Consistent timestamp format (ISO 8601)\\n\\n4. **Health Check**: Verifies:\\n   - Database connectivity (checks event/booking counts)\\n   - Cache status (if applicable)\\n   - System uptime\\n   - Version information\\n\\n### **Why This Design?**\\n\\n- **Thread-safe**: All shared state protected by locks\\n- **Memory-bounded**: Ring buffers prevent unbounded growth\\n- **Production patterns**: Follows 12-factor app principles\\n- **Observable**: Every request is logged and metered",
    "data_structures": [
      {
        "structure": "deque (per rate limit key)",
        "purpose": "O(1) append/popleft for sliding window timestamps"
      },
      {
        "structure": "deque (bounded ring buffer)",
        "purpose": "Store last N latencies for percentile calculation"
      },
      {
        "structure": "Dict[str, deque]",
        "purpose": "Map user+endpoint keys to their request timestamp queues"
      },
      {
        "structure": "List[LogEntry]",
        "purpose": "In-memory log buffer (production would stream to file/service)"
      }
    ],
    "algorithm_steps": [
      "Step 1: On request arrival, generate/extract request_id for tracing",
      "Step 2: Check rate limit - lazy cleanup of expired entries, then count",
      "Step 3: If rate limited, log and return 429 immediately",
      "Step 4: Process the actual request (from Parts 1-3)",
      "Step 5: Record metrics (latency, success/error)",
      "Step 6: Log the request with all context",
      "Step 7: Return response with appropriate headers (X-RateLimit-Remaining)"
    ]
  },
  "solution_python_lines": [
    "from typing import Dict, List, Optional, Any, Set",
    "from dataclasses import dataclass, field",
    "from datetime import datetime, timedelta",
    "from collections import deque",
    "from enum import Enum",
    "import threading",
    "import time",
    "import json",
    "import re",
    "import hashlib",
    "import secrets",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# PART 4: PRODUCTION READINESS - ENUMS AND DATA CLASSES",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "class LogLevel(Enum):",
    "    DEBUG = \"DEBUG\"",
    "    INFO = \"INFO\"",
    "    WARN = \"WARN\"",
    "    ERROR = \"ERROR\"",
    "",
    "@dataclass",
    "class LogEntry:",
    "    \"\"\"Structured log entry for production logging.\"\"\"",
    "    timestamp: str",
    "    level: LogLevel",
    "    request_id: str",
    "    user_id: Optional[str]",
    "    method: str",
    "    endpoint: str",
    "    status: int",
    "    duration_ms: float",
    "    message: str",
    "    error_details: Optional[str] = None",
    "",
    "@dataclass",
    "class MetricsSnapshot:",
    "    \"\"\"Point-in-time metrics snapshot.\"\"\"",
    "    total_requests: int",
    "    requests_per_second: float",
    "    error_count: int",
    "    error_rate: float",
    "    avg_latency_ms: float",
    "    p50_latency_ms: float",
    "    p95_latency_ms: float",
    "    p99_latency_ms: float",
    "    active_events: int",
    "    total_bookings: int",
    "",
    "@dataclass",
    "class Response:",
    "    \"\"\"HTTP Response wrapper.\"\"\"",
    "    status: int",
    "    body: Any",
    "    headers: Dict[str, str] = field(default_factory=dict)",
    "",
    "@dataclass",
    "class Event:",
    "    \"\"\"Event entity.\"\"\"",
    "    id: str",
    "    name: str",
    "    date: str",
    "    total_tickets: int",
    "    available_tickets: int",
    "    price: float",
    "",
    "@dataclass",
    "class Booking:",
    "    \"\"\"Booking entity.\"\"\"",
    "    id: str",
    "    event_id: str",
    "    user_id: str",
    "    quantity: int",
    "    status: str",
    "    created_at: str",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# SLIDING WINDOW RATE LIMITER",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "class SlidingWindowRateLimiter:",
    "    \"\"\"",
    "    Sliding window log rate limiter with O(1) amortized complexity.",
    "    ",
    "    Uses lazy cleanup: expired entries are only removed when checking,",
    "    which amortizes the cleanup cost across multiple requests.",
    "    \"\"\"",
    "    ",
    "    def __init__(self, window_seconds: int, max_requests: int):",
    "        self.window_seconds = window_seconds",
    "        self.max_requests = max_requests",
    "        self.requests: Dict[str, deque] = {}",
    "        self._lock = threading.Lock()",
    "    ",
    "    def is_allowed(self, key: str) -> bool:",
    "        \"\"\"",
    "        Check if request is allowed and record it if so.",
    "        ",
    "        Args:",
    "            key: Unique identifier (e.g., user_id or user_id:endpoint)",
    "            ",
    "        Returns:",
    "            True if request is allowed, False if rate limited",
    "        \"\"\"",
    "        with self._lock:",
    "            current_time = time.time()",
    "            window_start = current_time - self.window_seconds",
    "            ",
    "            if key not in self.requests:",
    "                self.requests[key] = deque()",
    "            ",
    "            # Lazy cleanup: remove expired entries",
    "            while self.requests[key] and self.requests[key][0] < window_start:",
    "                self.requests[key].popleft()",
    "            ",
    "            # Check if under limit",
    "            if len(self.requests[key]) < self.max_requests:",
    "                self.requests[key].append(current_time)",
    "                return True",
    "            ",
    "            return False",
    "    ",
    "    def get_remaining(self, key: str) -> int:",
    "        \"\"\"Get remaining requests allowed in current window.\"\"\"",
    "        with self._lock:",
    "            current_time = time.time()",
    "            window_start = current_time - self.window_seconds",
    "            ",
    "            if key not in self.requests:",
    "                return self.max_requests",
    "            ",
    "            # Count valid entries",
    "            valid_count = sum(1 for t in self.requests[key] if t >= window_start)",
    "            return max(0, self.max_requests - valid_count)",
    "    ",
    "    def get_reset_time(self, key: str) -> float:",
    "        \"\"\"Get seconds until oldest request expires from window.\"\"\"",
    "        with self._lock:",
    "            if key not in self.requests or not self.requests[key]:",
    "                return 0",
    "            oldest = self.requests[key][0]",
    "            reset_at = oldest + self.window_seconds",
    "            return max(0, reset_at - time.time())",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# METRICS COLLECTOR",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "class MetricsCollector:",
    "    \"\"\"",
    "    Collects and aggregates system metrics.",
    "    ",
    "    Uses bounded ring buffers to prevent unbounded memory growth.",
    "    Supports percentile calculations for latency monitoring.",
    "    \"\"\"",
    "    ",
    "    def __init__(self, window_size: int = 1000):",
    "        self.window_size = window_size",
    "        self.latencies: deque = deque(maxlen=window_size)",
    "        self.request_times: deque = deque(maxlen=window_size)",
    "        self.error_count = 0",
    "        self.total_requests = 0",
    "        self.start_time = time.time()",
    "        self._lock = threading.Lock()",
    "    ",
    "    def record_request(self, duration_ms: float, is_error: bool = False):",
    "        \"\"\"Record a completed request with its latency.\"\"\"",
    "        with self._lock:",
    "            current_time = time.time()",
    "            self.latencies.append(duration_ms)",
    "            self.request_times.append(current_time)",
    "            self.total_requests += 1",
    "            if is_error:",
    "                self.error_count += 1",
    "    ",
    "    def get_snapshot(self, active_events: int = 0, total_bookings: int = 0) -> MetricsSnapshot:",
    "        \"\"\"Get current metrics snapshot with percentiles.\"\"\"",
    "        with self._lock:",
    "            current_time = time.time()",
    "            ",
    "            # Calculate RPS over last 60 seconds",
    "            recent_cutoff = current_time - 60",
    "            recent_requests = sum(1 for t in self.request_times if t > recent_cutoff)",
    "            rps = recent_requests / 60.0",
    "            ",
    "            # Calculate latency percentiles",
    "            sorted_latencies = sorted(self.latencies) if self.latencies else [0]",
    "            ",
    "            def percentile(data: List[float], p: float) -> float:",
    "                if not data:",
    "                    return 0",
    "                k = (len(data) - 1) * p",
    "                f = int(k)",
    "                c = min(f + 1, len(data) - 1)",
    "                return data[f] + (k - f) * (data[c] - data[f])",
    "            ",
    "            avg_latency = sum(sorted_latencies) / len(sorted_latencies) if sorted_latencies else 0",
    "            error_rate = (self.error_count / self.total_requests * 100) if self.total_requests > 0 else 0",
    "            ",
    "            return MetricsSnapshot(",
    "                total_requests=self.total_requests,",
    "                requests_per_second=round(rps, 2),",
    "                error_count=self.error_count,",
    "                error_rate=round(error_rate, 2),",
    "                avg_latency_ms=round(avg_latency, 2),",
    "                p50_latency_ms=round(percentile(sorted_latencies, 0.50), 2),",
    "                p95_latency_ms=round(percentile(sorted_latencies, 0.95), 2),",
    "                p99_latency_ms=round(percentile(sorted_latencies, 0.99), 2),",
    "                active_events=active_events,",
    "                total_bookings=total_bookings",
    "            )",
    "    ",
    "    def get_uptime(self) -> str:",
    "        \"\"\"Get formatted uptime string.\"\"\"",
    "        elapsed = time.time() - self.start_time",
    "        hours = int(elapsed // 3600)",
    "        minutes = int((elapsed % 3600) // 60)",
    "        seconds = int(elapsed % 60)",
    "        return f\"{hours}h {minutes}m {seconds}s\"",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# STRUCTURED LOGGER",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "class StructuredLogger:",
    "    \"\"\"",
    "    Production-ready structured JSON logging.",
    "    ",
    "    Features:",
    "    - Consistent JSON format for log aggregation",
    "    - Automatic masking of sensitive data",
    "    - Request ID tracking for distributed tracing",
    "    \"\"\"",
    "    ",
    "    SENSITIVE_FIELDS: Set[str] = {",
    "        'password', 'token', 'access_token', 'refresh_token',",
    "        'credit_card', 'card_number', 'cvv', 'ssn', 'api_key',",
    "        'secret', 'authorization'",
    "    }",
    "    ",
    "    def __init__(self, service_name: str = \"ticket-api\"):",
    "        self.service_name = service_name",
    "        self.logs: List[Dict] = []",
    "        self._lock = threading.Lock()",
    "    ",
    "    def log(self, level: LogLevel, message: str, **context):",
    "        \"\"\"Log a message with structured context.\"\"\"",
    "        entry = {",
    "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",",
    "            \"level\": level.value,",
    "            \"service\": self.service_name,",
    "            \"message\": message,",
    "            **self._mask_sensitive(context)",
    "        }",
    "        with self._lock:",
    "            self.logs.append(entry)",
    "        # In production: print to stdout for container log collection",
    "        print(json.dumps(entry))",
    "    ",
    "    def log_request(self, entry: LogEntry):",
    "        \"\"\"Log a complete request/response cycle.\"\"\"",
    "        log_dict = {",
    "            \"timestamp\": entry.timestamp,",
    "            \"level\": entry.level.value,",
    "            \"service\": self.service_name,",
    "            \"requestId\": entry.request_id,",
    "            \"userId\": entry.user_id or \"anonymous\",",
    "            \"method\": entry.method,",
    "            \"endpoint\": entry.endpoint,",
    "            \"status\": entry.status,",
    "            \"durationMs\": entry.duration_ms,",
    "            \"message\": entry.message",
    "        }",
    "        if entry.error_details:",
    "            log_dict[\"errorDetails\"] = entry.error_details",
    "        ",
    "        with self._lock:",
    "            self.logs.append(log_dict)",
    "        print(json.dumps(log_dict))",
    "    ",
    "    def _mask_sensitive(self, data: Dict) -> Dict:",
    "        \"\"\"Recursively mask sensitive fields in data.\"\"\"",
    "        masked = {}",
    "        for key, value in data.items():",
    "            key_lower = key.lower()",
    "            if any(sensitive in key_lower for sensitive in self.SENSITIVE_FIELDS):",
    "                masked[key] = \"***REDACTED***\"",
    "            elif isinstance(value, dict):",
    "                masked[key] = self._mask_sensitive(value)",
    "            else:",
    "                masked[key] = value",
    "        return masked",
    "    ",
    "    def info(self, message: str, **context):",
    "        self.log(LogLevel.INFO, message, **context)",
    "    ",
    "    def warn(self, message: str, **context):",
    "        self.log(LogLevel.WARN, message, **context)",
    "    ",
    "    def error(self, message: str, **context):",
    "        self.log(LogLevel.ERROR, message, **context)",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# INPUT VALIDATOR (from Part 1)",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "class InputValidator:",
    "    \"\"\"Bulletproof input validation.\"\"\"",
    "    ",
    "    MAX_NAME_LENGTH = 200",
    "    MAX_TICKETS = 10000",
    "    MAX_BOOKING_QUANTITY = 10",
    "    ",
    "    @staticmethod",
    "    def validate_event_name(name: str) -> tuple[bool, str]:",
    "        if not name or not name.strip():",
    "            return False, \"Event name is required\"",
    "        if len(name) > InputValidator.MAX_NAME_LENGTH:",
    "            return False, f\"Event name exceeds {InputValidator.MAX_NAME_LENGTH} characters\"",
    "        # Prevent XSS/injection",
    "        if re.search(r'[<>\"\\']|script|javascript', name, re.IGNORECASE):",
    "            return False, \"Event name contains invalid characters\"",
    "        return True, \"\"",
    "    ",
    "    @staticmethod",
    "    def validate_ticket_count(count: Any) -> tuple[bool, str]:",
    "        if not isinstance(count, int):",
    "            return False, \"Ticket count must be an integer\"",
    "        if count < 0:",
    "            return False, \"Ticket count cannot be negative\"",
    "        if count > InputValidator.MAX_TICKETS:",
    "            return False, f\"Ticket count exceeds maximum of {InputValidator.MAX_TICKETS}\"",
    "        return True, \"\"",
    "    ",
    "    @staticmethod",
    "    def validate_booking_quantity(quantity: Any) -> tuple[bool, str]:",
    "        if not isinstance(quantity, int):",
    "            return False, \"Quantity must be an integer\"",
    "        if quantity < 1:",
    "            return False, \"Quantity must be at least 1\"",
    "        if quantity > InputValidator.MAX_BOOKING_QUANTITY:",
    "            return False, f\"Cannot book more than {InputValidator.MAX_BOOKING_QUANTITY} tickets\"",
    "        return True, \"\"",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# MAIN TICKET API CLASS",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "class TicketAPI:",
    "    \"\"\"",
    "    Production-Ready Event Ticket Booking API.",
    "    ",
    "    Features:",
    "    - Part 1: Input validation",
    "    - Part 2: Authentication (simplified)",
    "    - Part 3: Concurrency control with locks",
    "    - Part 4: Production readiness (metrics, logging, rate limiting)",
    "    \"\"\"",
    "    ",
    "    VERSION = \"1.0.0\"",
    "    ",
    "    # Rate limit configurations",
    "    GLOBAL_RATE_LIMIT = 10000  # requests/second",
    "    USER_RATE_LIMIT = 100      # requests/minute",
    "    BOOKING_RATE_LIMIT = 10    # bookings/minute per user",
    "    EVENTS_RATE_LIMIT = 60     # event queries/minute per user",
    "    ",
    "    def __init__(self):",
    "        # Core data stores",
    "        self.events: Dict[str, Event] = {}",
    "        self.bookings: Dict[str, Booking] = {}",
    "        self.user_bookings: Dict[str, List[str]] = {}  # user_id -> [booking_ids]",
    "        ",
    "        # Concurrency control (Part 3)",
    "        self._event_locks: Dict[str, threading.Lock] = {}",
    "        self._global_lock = threading.Lock()",
    "        ",
    "        # Authentication (Part 2 - simplified)",
    "        self.auth_tokens: Dict[str, str] = {}  # token -> user_id",
    "        ",
    "        # Production readiness (Part 4)",
    "        self.metrics = MetricsCollector()",
    "        self.logger = StructuredLogger()",
    "        ",
    "        # Multi-tier rate limiters",
    "        self.global_limiter = SlidingWindowRateLimiter(1, self.GLOBAL_RATE_LIMIT)",
    "        self.user_limiter = SlidingWindowRateLimiter(60, self.USER_RATE_LIMIT)",
    "        self.booking_limiter = SlidingWindowRateLimiter(60, self.BOOKING_RATE_LIMIT)",
    "        self.events_limiter = SlidingWindowRateLimiter(60, self.EVENTS_RATE_LIMIT)",
    "        ",
    "        # Counter for IDs",
    "        self._event_counter = 0",
    "        self._booking_counter = 0",
    "    ",
    "    def _get_event_lock(self, event_id: str) -> threading.Lock:",
    "        \"\"\"Get or create a lock for a specific event.\"\"\"",
    "        with self._global_lock:",
    "            if event_id not in self._event_locks:",
    "                self._event_locks[event_id] = threading.Lock()",
    "            return self._event_locks[event_id]",
    "    ",
    "    def _generate_request_id(self) -> str:",
    "        \"\"\"Generate unique request ID for tracing.\"\"\"",
    "        return f\"req_{secrets.token_hex(8)}\"",
    "    ",
    "    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    # PART 4: PRODUCTION READINESS METHODS",
    "    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    ",
    "    def health_check(self) -> Response:",
    "        \"\"\"",
    "        Check system health and return status of all components.",
    "        ",
    "        Returns:",
    "            Response with health status, component checks, version, and uptime",
    "        \"\"\"",
    "        start_time = time.time()",
    "        request_id = self._generate_request_id()",
    "        ",
    "        checks = {}",
    "        overall_healthy = True",
    "        ",
    "        # Check \"database\" (our in-memory stores)",
    "        try:",
    "            event_count = len(self.events)",
    "            booking_count = len(self.bookings)",
    "            checks[\"database\"] = \"connected\"",
    "            checks[\"eventCount\"] = event_count",
    "            checks[\"bookingCount\"] = booking_count",
    "        except Exception as e:",
    "            checks[\"database\"] = f\"error: {str(e)}\"",
    "            overall_healthy = False",
    "        ",
    "        # Check rate limiter health",
    "        try:",
    "            _ = self.global_limiter.get_remaining(\"health_check\")",
    "            checks[\"rateLimiter\"] = \"operational\"",
    "        except Exception as e:",
    "            checks[\"rateLimiter\"] = f\"error: {str(e)}\"",
    "            overall_healthy = False",
    "        ",
    "        # Check metrics collector",
    "        try:",
    "            _ = self.metrics.get_uptime()",
    "            checks[\"metrics\"] = \"collecting\"",
    "        except Exception as e:",
    "            checks[\"metrics\"] = f\"error: {str(e)}\"",
    "            overall_healthy = False",
    "        ",
    "        duration_ms = (time.time() - start_time) * 1000",
    "        ",
    "        status = \"healthy\" if overall_healthy else \"degraded\"",
    "        ",
    "        body = {",
    "            \"status\": status,",
    "            \"checks\": checks,",
    "            \"version\": self.VERSION,",
    "            \"uptime\": self.metrics.get_uptime()",
    "        }",
    "        ",
    "        self.logger.info(",
    "            \"Health check completed\",",
    "            requestId=request_id,",
    "            status=status,",
    "            durationMs=round(duration_ms, 2)",
    "        )",
    "        ",
    "        return Response(status=200, body=body)",
    "    ",
    "    def get_metrics(self) -> Response:",
    "        \"\"\"",
    "        Get current system metrics.",
    "        ",
    "        Returns:",
    "            Response with metrics snapshot including latency percentiles",
    "        \"\"\"",
    "        snapshot = self.metrics.get_snapshot(",
    "            active_events=len(self.events),",
    "            total_bookings=len(self.bookings)",
    "        )",
    "        ",
    "        body = {",
    "            \"totalRequests\": snapshot.total_requests,",
    "            \"requestsPerSecond\": snapshot.requests_per_second,",
    "            \"errorCount\": snapshot.error_count,",
    "            \"errorRate\": f\"{snapshot.error_rate}%\",",
    "            \"latency\": {",
    "                \"avg\": f\"{snapshot.avg_latency_ms}ms\",",
    "                \"p50\": f\"{snapshot.p50_latency_ms}ms\",",
    "                \"p95\": f\"{snapshot.p95_latency_ms}ms\",",
    "                \"p99\": f\"{snapshot.p99_latency_ms}ms\"",
    "            },",
    "            \"activeEvents\": snapshot.active_events,",
    "            \"totalBookings\": snapshot.total_bookings,",
    "            \"uptime\": self.metrics.get_uptime()",
    "        }",
    "        ",
    "        return Response(status=200, body=body)",
    "    ",
    "    def check_rate_limit(self, user_id: str, endpoint: str) -> bool:",
    "        \"\"\"",
    "        Check if request is within rate limits.",
    "        ",
    "        Implements multi-tier rate limiting:",
    "        1. Global rate limit (protects infrastructure)",
    "        2. Per-user rate limit (prevents single user abuse)",
    "        3. Per-endpoint rate limit (tighter limits on critical endpoints)",
    "        ",
    "        Args:",
    "            user_id: User making the request",
    "            endpoint: API endpoint being accessed",
    "            ",
    "        Returns:",
    "            True if allowed, False if rate limited",
    "        \"\"\"",
    "        # Tier 1: Global rate limit",
    "        if not self.global_limiter.is_allowed(\"global\"):",
    "            self.logger.warn(",
    "                \"Global rate limit exceeded\",",
    "                userId=user_id,",
    "                endpoint=endpoint",
    "            )",
    "            return False",
    "        ",
    "        # Tier 2: Per-user rate limit",
    "        if not self.user_limiter.is_allowed(user_id):",
    "            self.logger.warn(",
    "                \"User rate limit exceeded\",",
    "                userId=user_id,",
    "                endpoint=endpoint",
    "            )",
    "            return False",
    "        ",
    "        # Tier 3: Per-endpoint rate limit",
    "        endpoint_key = f\"{user_id}:{endpoint}\"",
    "        ",
    "        if \"/bookings\" in endpoint and \"POST\" in endpoint.upper():",
    "            if not self.booking_limiter.is_allowed(endpoint_key):",
    "                self.logger.warn(",
    "                    \"Booking rate limit exceeded\",",
    "                    userId=user_id,",
    "                    endpoint=endpoint",
    "                )",
    "                return False",
    "        elif \"/events\" in endpoint:",
    "            if not self.events_limiter.is_allowed(endpoint_key):",
    "                self.logger.warn(",
    "                    \"Events rate limit exceeded\",",
    "                    userId=user_id,",
    "                    endpoint=endpoint",
    "                )",
    "                return False",
    "        ",
    "        return True",
    "    ",
    "    def log_request(self, method: str, endpoint: str, status: int,",
    "                    duration_ms: float, user_id: Optional[str] = None,",
    "                    request_id: Optional[str] = None,",
    "                    error_details: Optional[str] = None):",
    "        \"\"\"",
    "        Log a request with full context for observability.",
    "        ",
    "        Args:",
    "            method: HTTP method (GET, POST, etc.)",
    "            endpoint: API endpoint path",
    "            status: HTTP response status code",
    "            duration_ms: Request duration in milliseconds",
    "            user_id: Optional user ID",
    "            request_id: Optional request ID for tracing",
    "            error_details: Optional error message on failure",
    "        \"\"\"",
    "        level = LogLevel.INFO if status < 400 else LogLevel.ERROR",
    "        message = \"Request completed\" if status < 400 else \"Request failed\"",
    "        ",
    "        entry = LogEntry(",
    "            timestamp=datetime.utcnow().isoformat() + \"Z\",",
    "            level=level,",
    "            request_id=request_id or self._generate_request_id(),",
    "            user_id=user_id,",
    "            method=method,",
    "            endpoint=endpoint,",
    "            status=status,",
    "            duration_ms=duration_ms,",
    "            message=message,",
    "            error_details=error_details",
    "        )",
    "        ",
    "        self.logger.log_request(entry)",
    "        ",
    "        # Record metrics",
    "        is_error = status >= 400",
    "        self.metrics.record_request(duration_ms, is_error)",
    "    ",
    "    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    # CORE API METHODS (from Parts 1-3, with production instrumentation)",
    "    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    ",
    "    def create_event(self, name: str, date: str, total_tickets: int,",
    "                     price: float, user_id: str = \"system\") -> Response:",
    "        \"\"\"Create a new event with validation and logging.\"\"\"",
    "        start_time = time.time()",
    "        request_id = self._generate_request_id()",
    "        ",
    "        # Rate limit check",
    "        if not self.check_rate_limit(user_id, \"POST /events\"):",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"POST\", \"/events\", 429, duration_ms, user_id,",
    "                           request_id, \"Rate limit exceeded\")",
    "            return Response(",
    "                status=429,",
    "                body={\"error\": \"Rate limit exceeded\"},",
    "                headers={\"Retry-After\": \"60\"}",
    "            )",
    "        ",
    "        # Validation",
    "        valid, error = InputValidator.validate_event_name(name)",
    "        if not valid:",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"POST\", \"/events\", 400, duration_ms, user_id,",
    "                           request_id, error)",
    "            return Response(status=400, body={\"error\": error})",
    "        ",
    "        valid, error = InputValidator.validate_ticket_count(total_tickets)",
    "        if not valid:",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"POST\", \"/events\", 400, duration_ms, user_id,",
    "                           request_id, error)",
    "            return Response(status=400, body={\"error\": error})",
    "        ",
    "        # Create event",
    "        with self._global_lock:",
    "            self._event_counter += 1",
    "            event_id = f\"evt_{self._event_counter:03d}\"",
    "        ",
    "        event = Event(",
    "            id=event_id,",
    "            name=name.strip(),",
    "            date=date,",
    "            total_tickets=total_tickets,",
    "            available_tickets=total_tickets,",
    "            price=price",
    "        )",
    "        ",
    "        self.events[event_id] = event",
    "        ",
    "        duration_ms = (time.time() - start_time) * 1000",
    "        self.log_request(\"POST\", \"/events\", 201, duration_ms, user_id, request_id)",
    "        ",
    "        return Response(",
    "            status=201,",
    "            body={",
    "                \"id\": event.id,",
    "                \"name\": event.name,",
    "                \"date\": event.date,",
    "                \"totalTickets\": event.total_tickets,",
    "                \"availableTickets\": event.available_tickets,",
    "                \"price\": event.price",
    "            }",
    "        )",
    "    ",
    "    def get_event(self, event_id: str, user_id: str = \"anonymous\") -> Response:",
    "        \"\"\"Get event details by ID.\"\"\"",
    "        start_time = time.time()",
    "        request_id = self._generate_request_id()",
    "        ",
    "        if not self.check_rate_limit(user_id, \"GET /events\"):",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"GET\", f\"/events/{event_id}\", 429, duration_ms,",
    "                           user_id, request_id, \"Rate limit exceeded\")",
    "            return Response(status=429, body={\"error\": \"Rate limit exceeded\"})",
    "        ",
    "        if event_id not in self.events:",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"GET\", f\"/events/{event_id}\", 404, duration_ms,",
    "                           user_id, request_id, \"Event not found\")",
    "            return Response(status=404, body={\"error\": \"Event not found\"})",
    "        ",
    "        event = self.events[event_id]",
    "        duration_ms = (time.time() - start_time) * 1000",
    "        self.log_request(\"GET\", f\"/events/{event_id}\", 200, duration_ms,",
    "                        user_id, request_id)",
    "        ",
    "        return Response(",
    "            status=200,",
    "            body={",
    "                \"id\": event.id,",
    "                \"name\": event.name,",
    "                \"date\": event.date,",
    "                \"totalTickets\": event.total_tickets,",
    "                \"availableTickets\": event.available_tickets,",
    "                \"price\": event.price",
    "            }",
    "        )",
    "    ",
    "    def create_booking(self, event_id: str, user_id: str,",
    "                       quantity: int) -> Response:",
    "        \"\"\"",
    "        Create a booking with concurrency control.",
    "        Uses per-event locking to prevent double-booking.",
    "        \"\"\"",
    "        start_time = time.time()",
    "        request_id = self._generate_request_id()",
    "        endpoint = f\"/events/{event_id}/bookings\"",
    "        ",
    "        # Rate limit check (strict for bookings)",
    "        if not self.check_rate_limit(user_id, \"POST /bookings\"):",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"POST\", endpoint, 429, duration_ms, user_id,",
    "                           request_id, \"Rate limit exceeded\")",
    "            return Response(",
    "                status=429,",
    "                body={\"error\": \"Rate limit exceeded. Try again later.\"},",
    "                headers={\"Retry-After\": \"60\"}",
    "            )",
    "        ",
    "        # Validation",
    "        valid, error = InputValidator.validate_booking_quantity(quantity)",
    "        if not valid:",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"POST\", endpoint, 400, duration_ms, user_id,",
    "                           request_id, error)",
    "            return Response(status=400, body={\"error\": error})",
    "        ",
    "        # Check event exists",
    "        if event_id not in self.events:",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"POST\", endpoint, 404, duration_ms, user_id,",
    "                           request_id, \"Event not found\")",
    "            return Response(status=404, body={\"error\": \"Event not found\"})",
    "        ",
    "        # Acquire event-specific lock for thread safety",
    "        event_lock = self._get_event_lock(event_id)",
    "        ",
    "        with event_lock:",
    "            event = self.events[event_id]",
    "            ",
    "            # Check availability",
    "            if event.available_tickets < quantity:",
    "                duration_ms = (time.time() - start_time) * 1000",
    "                self.log_request(\"POST\", endpoint, 409, duration_ms, user_id,",
    "                               request_id, \"Insufficient tickets\")",
    "                return Response(",
    "                    status=409,",
    "                    body={",
    "                        \"error\": \"Insufficient tickets\",",
    "                        \"available\": event.available_tickets,",
    "                        \"requested\": quantity",
    "                    }",
    "                )",
    "            ",
    "            # Create booking",
    "            with self._global_lock:",
    "                self._booking_counter += 1",
    "                booking_id = f\"bkg_{self._booking_counter:03d}\"",
    "            ",
    "            booking = Booking(",
    "                id=booking_id,",
    "                event_id=event_id,",
    "                user_id=user_id,",
    "                quantity=quantity,",
    "                status=\"confirmed\",",
    "                created_at=datetime.utcnow().isoformat() + \"Z\"",
    "            )",
    "            ",
    "            # Update state atomically",
    "            event.available_tickets -= quantity",
    "            self.bookings[booking_id] = booking",
    "            ",
    "            if user_id not in self.user_bookings:",
    "                self.user_bookings[user_id] = []",
    "            self.user_bookings[user_id].append(booking_id)",
    "        ",
    "        duration_ms = (time.time() - start_time) * 1000",
    "        self.log_request(\"POST\", endpoint, 201, duration_ms, user_id, request_id)",
    "        ",
    "        self.logger.info(",
    "            \"Booking created successfully\",",
    "            requestId=request_id,",
    "            userId=user_id,",
    "            eventId=event_id,",
    "            bookingId=booking_id,",
    "            quantity=quantity",
    "        )",
    "        ",
    "        return Response(",
    "            status=201,",
    "            body={",
    "                \"id\": booking.id,",
    "                \"eventId\": booking.event_id,",
    "                \"userId\": booking.user_id,",
    "                \"quantity\": booking.quantity,",
    "                \"status\": booking.status,",
    "                \"createdAt\": booking.created_at",
    "            }",
    "        )",
    "    ",
    "    def get_booking(self, booking_id: str, user_id: str) -> Response:",
    "        \"\"\"Get booking details.\"\"\"",
    "        start_time = time.time()",
    "        request_id = self._generate_request_id()",
    "        ",
    "        if booking_id not in self.bookings:",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"GET\", f\"/bookings/{booking_id}\", 404, duration_ms,",
    "                           user_id, request_id, \"Booking not found\")",
    "            return Response(status=404, body={\"error\": \"Booking not found\"})",
    "        ",
    "        booking = self.bookings[booking_id]",
    "        ",
    "        # Authorization check",
    "        if booking.user_id != user_id:",
    "            duration_ms = (time.time() - start_time) * 1000",
    "            self.log_request(\"GET\", f\"/bookings/{booking_id}\", 403, duration_ms,",
    "                           user_id, request_id, \"Access denied\")",
    "            return Response(status=403, body={\"error\": \"Access denied\"})",
    "        ",
    "        duration_ms = (time.time() - start_time) * 1000",
    "        self.log_request(\"GET\", f\"/bookings/{booking_id}\", 200, duration_ms,",
    "                        user_id, request_id)",
    "        ",
    "        return Response(",
    "            status=200,",
    "            body={",
    "                \"id\": booking.id,",
    "                \"eventId\": booking.event_id,",
    "                \"userId\": booking.user_id,",
    "                \"quantity\": booking.quantity,",
    "                \"status\": booking.status,",
    "                \"createdAt\": booking.created_at",
    "            }",
    "        )",
    "",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "# DEMONSTRATION",
    "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "",
    "def main():",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"PART 4: PRODUCTION READINESS DEMONSTRATION\")",
    "    print(\"=\" * 70)",
    "    ",
    "    api = TicketAPI()",
    "    ",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "    print(\"\\n[1] HEALTH CHECK\")",
    "    print(\"-\" * 40)",
    "    response = api.health_check()",
    "    print(f\"Status: {response.status}\")",
    "    print(f\"Body: {json.dumps(response.body, indent=2)}\")",
    "    ",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "    print(\"\\n[2] CREATE SOME DATA FOR METRICS\")",
    "    print(\"-\" * 40)",
    "    ",
    "    # Create an event",
    "    response = api.create_event(",
    "        name=\"Tech Conference 2024\",",
    "        date=\"2024-12-20\",",
    "        total_tickets=100,",
    "        price=299.99,",
    "        user_id=\"admin_001\"",
    "    )",
    "    print(f\"Created event: {response.body.get('id')}\")",
    "    event_id = response.body.get('id')",
    "    ",
    "    # Create some bookings",
    "    for i in range(3):",
    "        response = api.create_booking(",
    "            event_id=event_id,",
    "            user_id=f\"user_{i+1:03d}\",",
    "            quantity=2",
    "        )",
    "        print(f\"Created booking: {response.body.get('id')}\")",
    "    ",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "    print(\"\\n[3] GET METRICS\")",
    "    print(\"-\" * 40)",
    "    response = api.get_metrics()",
    "    print(f\"Metrics: {json.dumps(response.body, indent=2)}\")",
    "    ",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "    print(\"\\n[4] RATE LIMITING TEST\")",
    "    print(\"-\" * 40)",
    "    ",
    "    # Test rate limiting",
    "    spam_user = \"usr_spam\"",
    "    ",
    "    # First few requests should succeed",
    "    for i in range(3):",
    "        result = api.check_rate_limit(spam_user, \"/bookings\")",
    "        print(f\"Request {i+1}: {'Allowed' if result else 'Blocked'}\")",
    "    ",
    "    # Simulate hitting booking rate limit",
    "    print(\"\\nSimulating booking rate limit (10/minute)...\")",
    "    booking_limiter = SlidingWindowRateLimiter(60, 10)",
    "    for i in range(12):",
    "        result = booking_limiter.is_allowed(\"test_user\")",
    "        status = \"\u2713 Allowed\" if result else \"\u2717 Blocked\"",
    "        print(f\"  Booking attempt {i+1}: {status}\")",
    "    ",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "    print(\"\\n[5] HEALTH CHECK AFTER ACTIVITY\")",
    "    print(\"-\" * 40)",
    "    response = api.health_check()",
    "    print(f\"Status: {response.status}\")",
    "    print(f\"Body: {json.dumps(response.body, indent=2)}\")",
    "    ",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "    print(\"\\n[6] STRUCTURED LOGGING SAMPLE\")",
    "    print(\"-\" * 40)",
    "    print(\"Recent log entries are printed above in JSON format.\")",
    "    print(\"Note: Sensitive data like 'password' would be REDACTED.\")",
    "    ",
    "    # Demonstrate sensitive data masking",
    "    test_data = {",
    "        \"userId\": \"user_123\",",
    "        \"password\": \"secret123\",",
    "        \"credit_card\": \"4111111111111111\",",
    "        \"action\": \"login\"",
    "    }",
    "    masked = StructuredLogger()._mask_sensitive(test_data)",
    "    print(f\"\\nOriginal: {test_data}\")",
    "    print(f\"Masked:   {masked}\")",
    "    ",
    "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "    print(\"\\n[7] ERROR HANDLING WITH LOGGING\")",
    "    print(\"-\" * 40)",
    "    ",
    "    # Test 404",
    "    response = api.get_event(\"evt_nonexistent\", \"user_001\")",
    "    print(f\"Get non-existent event: {response.status} - {response.body}\")",
    "    ",
    "    # Test validation error",
    "    response = api.create_booking(event_id, \"user_001\", 999)",
    "    print(f\"Invalid booking quantity: {response.status} - {response.body}\")",
    "    ",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"DEMONSTRATION COMPLETE\")",
    "    print(\"=\" * 70)",
    "",
    "if __name__ == \"__main__\":",
    "    main()"
  ],
  "solution_java_lines": [
    "import java.util.*;",
    "import java.util.concurrent.*;",
    "import java.util.concurrent.locks.*;",
    "import java.time.*;",
    "import java.time.format.*;",
    "",
    "/**",
    " * Production-Ready Event Ticket Booking API - Part 4",
    " * Features: Health checks, Metrics, Rate limiting, Structured logging",
    " */",
    "public class TicketAPI {",
    "    ",
    "    // Constants",
    "    private static final String VERSION = \"1.0.0\";",
    "    private static final int GLOBAL_RATE_LIMIT = 10000;",
    "    private static final int USER_RATE_LIMIT = 100;",
    "    private static final int BOOKING_RATE_LIMIT = 10;",
    "    ",
    "    // Data stores",
    "    private final Map<String, Event> events = new ConcurrentHashMap<>();",
    "    private final Map<String, Booking> bookings = new ConcurrentHashMap<>();",
    "    private final Map<String, List<String>> userBookings = new ConcurrentHashMap<>();",
    "    ",
    "    // Concurrency control",
    "    private final Map<String, ReentrantLock> eventLocks = new ConcurrentHashMap<>();",
    "    private final ReentrantLock globalLock = new ReentrantLock();",
    "    ",
    "    // Production readiness components",
    "    private final MetricsCollector metrics = new MetricsCollector();",
    "    private final StructuredLogger logger = new StructuredLogger();",
    "    private final SlidingWindowRateLimiter globalLimiter;",
    "    private final SlidingWindowRateLimiter userLimiter;",
    "    private final SlidingWindowRateLimiter bookingLimiter;",
    "    ",
    "    // Counters",
    "    private int eventCounter = 0;",
    "    private int bookingCounter = 0;",
    "    private final long startTime;",
    "    ",
    "    public TicketAPI() {",
    "        this.startTime = System.currentTimeMillis();",
    "        this.globalLimiter = new SlidingWindowRateLimiter(1, GLOBAL_RATE_LIMIT);",
    "        this.userLimiter = new SlidingWindowRateLimiter(60, USER_RATE_LIMIT);",
    "        this.bookingLimiter = new SlidingWindowRateLimiter(60, BOOKING_RATE_LIMIT);",
    "    }",
    "    ",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    // PART 4: PRODUCTION READINESS METHODS",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    ",
    "    public Response healthCheck() {",
    "        long requestStart = System.currentTimeMillis();",
    "        Map<String, Object> checks = new LinkedHashMap<>();",
    "        boolean healthy = true;",
    "        ",
    "        try {",
    "            checks.put(\"database\", \"connected\");",
    "            checks.put(\"eventCount\", events.size());",
    "            checks.put(\"bookingCount\", bookings.size());",
    "        } catch (Exception e) {",
    "            checks.put(\"database\", \"error: \" + e.getMessage());",
    "            healthy = false;",
    "        }",
    "        ",
    "        checks.put(\"rateLimiter\", \"operational\");",
    "        checks.put(\"metrics\", \"collecting\");",
    "        ",
    "        Map<String, Object> body = new LinkedHashMap<>();",
    "        body.put(\"status\", healthy ? \"healthy\" : \"degraded\");",
    "        body.put(\"checks\", checks);",
    "        body.put(\"version\", VERSION);",
    "        body.put(\"uptime\", getUptime());",
    "        ",
    "        long duration = System.currentTimeMillis() - requestStart;",
    "        logger.info(\"Health check completed\", Map.of(",
    "            \"status\", healthy ? \"healthy\" : \"degraded\",",
    "            \"durationMs\", duration",
    "        ));",
    "        ",
    "        return new Response(200, body);",
    "    }",
    "    ",
    "    public Response getMetrics() {",
    "        MetricsSnapshot snapshot = metrics.getSnapshot();",
    "        ",
    "        Map<String, Object> latency = new LinkedHashMap<>();",
    "        latency.put(\"avg\", snapshot.avgLatencyMs + \"ms\");",
    "        latency.put(\"p50\", snapshot.p50LatencyMs + \"ms\");",
    "        latency.put(\"p95\", snapshot.p95LatencyMs + \"ms\");",
    "        latency.put(\"p99\", snapshot.p99LatencyMs + \"ms\");",
    "        ",
    "        Map<String, Object> body = new LinkedHashMap<>();",
    "        body.put(\"totalRequests\", snapshot.totalRequests);",
    "        body.put(\"requestsPerSecond\", snapshot.requestsPerSecond);",
    "        body.put(\"errorCount\", snapshot.errorCount);",
    "        body.put(\"errorRate\", snapshot.errorRate + \"%\");",
    "        body.put(\"latency\", latency);",
    "        body.put(\"activeEvents\", events.size());",
    "        body.put(\"totalBookings\", bookings.size());",
    "        body.put(\"uptime\", getUptime());",
    "        ",
    "        return new Response(200, body);",
    "    }",
    "    ",
    "    public boolean checkRateLimit(String userId, String endpoint) {",
    "        // Tier 1: Global",
    "        if (!globalLimiter.isAllowed(\"global\")) {",
    "            logger.warn(\"Global rate limit exceeded\",",
    "                Map.of(\"userId\", userId, \"endpoint\", endpoint));",
    "            return false;",
    "        }",
    "        ",
    "        // Tier 2: Per-user",
    "        if (!userLimiter.isAllowed(userId)) {",
    "            logger.warn(\"User rate limit exceeded\",",
    "                Map.of(\"userId\", userId, \"endpoint\", endpoint));",
    "            return false;",
    "        }",
    "        ",
    "        // Tier 3: Per-endpoint (bookings are stricter)",
    "        if (endpoint.contains(\"/bookings\")) {",
    "            String key = userId + \":\" + endpoint;",
    "            if (!bookingLimiter.isAllowed(key)) {",
    "                logger.warn(\"Booking rate limit exceeded\",",
    "                    Map.of(\"userId\", userId, \"endpoint\", endpoint));",
    "                return false;",
    "            }",
    "        }",
    "        ",
    "        return true;",
    "    }",
    "    ",
    "    private String getUptime() {",
    "        long elapsed = System.currentTimeMillis() - startTime;",
    "        long hours = elapsed / 3600000;",
    "        long minutes = (elapsed % 3600000) / 60000;",
    "        long seconds = (elapsed % 60000) / 1000;",
    "        return String.format(\"%dh %dm %ds\", hours, minutes, seconds);",
    "    }",
    "    ",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    // CORE API METHODS (abbreviated)",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    ",
    "    public Response createEvent(String name, String date, int tickets, double price) {",
    "        long start = System.currentTimeMillis();",
    "        ",
    "        if (!checkRateLimit(\"system\", \"POST /events\")) {",
    "            return new Response(429, Map.of(\"error\", \"Rate limit exceeded\"));",
    "        }",
    "        ",
    "        globalLock.lock();",
    "        try {",
    "            String eventId = String.format(\"evt_%03d\", ++eventCounter);",
    "            Event event = new Event(eventId, name, date, tickets, tickets, price);",
    "            events.put(eventId, event);",
    "            ",
    "            long duration = System.currentTimeMillis() - start;",
    "            metrics.recordRequest(duration, false);",
    "            ",
    "            return new Response(201, event.toMap());",
    "        } finally {",
    "            globalLock.unlock();",
    "        }",
    "    }",
    "    ",
    "    public Response createBooking(String eventId, String userId, int quantity) {",
    "        long start = System.currentTimeMillis();",
    "        ",
    "        if (!checkRateLimit(userId, \"POST /bookings\")) {",
    "            return new Response(429, Map.of(\"error\", \"Rate limit exceeded\"));",
    "        }",
    "        ",
    "        if (!events.containsKey(eventId)) {",
    "            return new Response(404, Map.of(\"error\", \"Event not found\"));",
    "        }",
    "        ",
    "        ReentrantLock lock = eventLocks.computeIfAbsent(eventId, k -> new ReentrantLock());",
    "        lock.lock();",
    "        try {",
    "            Event event = events.get(eventId);",
    "            if (event.availableTickets < quantity) {",
    "                return new Response(409, Map.of(",
    "                    \"error\", \"Insufficient tickets\",",
    "                    \"available\", event.availableTickets",
    "                ));",
    "            }",
    "            ",
    "            globalLock.lock();",
    "            String bookingId;",
    "            try {",
    "                bookingId = String.format(\"bkg_%03d\", ++bookingCounter);",
    "            } finally {",
    "                globalLock.unlock();",
    "            }",
    "            ",
    "            event.availableTickets -= quantity;",
    "            Booking booking = new Booking(bookingId, eventId, userId, quantity);",
    "            bookings.put(bookingId, booking);",
    "            ",
    "            long duration = System.currentTimeMillis() - start;",
    "            metrics.recordRequest(duration, false);",
    "            ",
    "            return new Response(201, booking.toMap());",
    "        } finally {",
    "            lock.unlock();",
    "        }",
    "    }",
    "    ",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    // SUPPORTING CLASSES",
    "    // \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550",
    "    ",
    "    static class SlidingWindowRateLimiter {",
    "        private final int windowSeconds;",
    "        private final int maxRequests;",
    "        private final Map<String, Deque<Long>> requests = new ConcurrentHashMap<>();",
    "        ",
    "        public SlidingWindowRateLimiter(int windowSeconds, int maxRequests) {",
    "            this.windowSeconds = windowSeconds;",
    "            this.maxRequests = maxRequests;",
    "        }",
    "        ",
    "        public synchronized boolean isAllowed(String key) {",
    "            long now = System.currentTimeMillis();",
    "            long windowStart = now - (windowSeconds * 1000L);",
    "            ",
    "            requests.putIfAbsent(key, new LinkedList<>());",
    "            Deque<Long> timestamps = requests.get(key);",
    "            ",
    "            // Remove expired entries",
    "            while (!timestamps.isEmpty() && timestamps.peekFirst() < windowStart) {",
    "                timestamps.pollFirst();",
    "            }",
    "            ",
    "            if (timestamps.size() < maxRequests) {",
    "                timestamps.addLast(now);",
    "                return true;",
    "            }",
    "            return false;",
    "        }",
    "    }",
    "    ",
    "    static class MetricsCollector {",
    "        private final Deque<Double> latencies = new LinkedList<>();",
    "        private final int windowSize = 1000;",
    "        private int totalRequests = 0;",
    "        private int errorCount = 0;",
    "        ",
    "        public synchronized void recordRequest(long durationMs, boolean isError) {",
    "            if (latencies.size() >= windowSize) latencies.pollFirst();",
    "            latencies.addLast((double) durationMs);",
    "            totalRequests++;",
    "            if (isError) errorCount++;",
    "        }",
    "        ",
    "        public synchronized MetricsSnapshot getSnapshot() {",
    "            List<Double> sorted = new ArrayList<>(latencies);",
    "            Collections.sort(sorted);",
    "            double avg = sorted.isEmpty() ? 0 : ",
    "                sorted.stream().mapToDouble(d -> d).average().orElse(0);",
    "            double p50 = percentile(sorted, 0.50);",
    "            double p95 = percentile(sorted, 0.95);",
    "            double p99 = percentile(sorted, 0.99);",
    "            double errRate = totalRequests > 0 ? (errorCount * 100.0 / totalRequests) : 0;",
    "            return new MetricsSnapshot(totalRequests, 0, errorCount, errRate, avg, p50, p95, p99);",
    "        }",
    "        ",
    "        private double percentile(List<Double> data, double p) {",
    "            if (data.isEmpty()) return 0;",
    "            int idx = (int) Math.ceil(p * data.size()) - 1;",
    "            return data.get(Math.max(0, Math.min(idx, data.size() - 1)));",
    "        }",
    "    }",
    "    ",
    "    static class StructuredLogger {",
    "        public void info(String msg, Map<String, Object> ctx) { log(\"INFO\", msg, ctx); }",
    "        public void warn(String msg, Map<String, Object> ctx) { log(\"WARN\", msg, ctx); }",
    "        public void error(String msg, Map<String, Object> ctx) { log(\"ERROR\", msg, ctx); }",
    "        ",
    "        private void log(String level, String msg, Map<String, Object> ctx) {",
    "            System.out.printf(\"{\\\"level\\\":\\\"%s\\\",\\\"message\\\":\\\"%s\\\",\\\"context\\\":%s}%n\",",
    "                level, msg, ctx);",
    "        }",
    "    }",
    "    ",
    "    // Data classes (records in Java 14+)",
    "    static class Response { int status; Object body; Response(int s, Object b) { status=s; body=b; } }",
    "    static class Event { String id, name, date; int totalTickets, availableTickets; double price;",
    "        Event(String id, String n, String d, int t, int a, double p) { this.id=id; name=n; date=d; totalTickets=t; availableTickets=a; price=p; }",
    "        Map<String,Object> toMap() { return Map.of(\"id\",id,\"name\",name,\"availableTickets\",availableTickets); }",
    "    }",
    "    static class Booking { String id, eventId, userId; int quantity;",
    "        Booking(String i, String e, String u, int q) { id=i; eventId=e; userId=u; quantity=q; }",
    "        Map<String,Object> toMap() { return Map.of(\"id\",id,\"eventId\",eventId,\"quantity\",quantity); }",
    "    }",
    "    static class MetricsSnapshot { int totalRequests, errorCount; double requestsPerSecond, errorRate, avgLatencyMs, p50LatencyMs, p95LatencyMs, p99LatencyMs;",
    "        MetricsSnapshot(int t, double r, int e, double er, double a, double p50, double p95, double p99) {",
    "            totalRequests=t; requestsPerSecond=r; errorCount=e; errorRate=er; avgLatencyMs=a; p50LatencyMs=p50; p95LatencyMs=p95; p99LatencyMs=p99; }",
    "    }",
    "    ",
    "    public static void main(String[] args) {",
    "        TicketAPI api = new TicketAPI();",
    "        System.out.println(\"\\n=== HEALTH CHECK ===\");",
    "        System.out.println(api.healthCheck().body);",
    "        ",
    "        System.out.println(\"\\n=== CREATE EVENT ===\");",
    "        Response r = api.createEvent(\"Concert\", \"2024-12-20\", 100, 99.99);",
    "        System.out.println(r.body);",
    "        ",
    "        System.out.println(\"\\n=== RATE LIMIT TEST ===\");",
    "        for (int i = 0; i < 5; i++) {",
    "            System.out.println(\"Request \" + (i+1) + \": \" + ",
    "                (api.checkRateLimit(\"user1\", \"/bookings\") ? \"Allowed\" : \"Blocked\"));",
    "        }",
    "        ",
    "        System.out.println(\"\\n=== METRICS ===\");",
    "        System.out.println(api.getMetrics().body);",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-25",
      "explanation": "Imports and data class definitions for LogEntry, MetricsSnapshot, Response, Event, and Booking"
    },
    {
      "lines": "27-95",
      "explanation": "SlidingWindowRateLimiter: Core rate limiting with deque per key, lazy cleanup of expired timestamps, O(1) amortized check"
    },
    {
      "lines": "97-170",
      "explanation": "MetricsCollector: Bounded ring buffer for latencies, percentile calculation, RPS tracking"
    },
    {
      "lines": "172-240",
      "explanation": "StructuredLogger: JSON-formatted logging with sensitive data masking (passwords, tokens, credit cards auto-redacted)"
    },
    {
      "lines": "242-280",
      "explanation": "TicketAPI constructor: Initializes all stores, creates multi-tier rate limiters with different windows/limits"
    },
    {
      "lines": "282-340",
      "explanation": "healthCheck(): Checks database, rate limiter, metrics collector status. Returns comprehensive health JSON"
    },
    {
      "lines": "342-380",
      "explanation": "getMetrics(): Fetches MetricsSnapshot with percentiles, formats as JSON response"
    },
    {
      "lines": "382-430",
      "explanation": "checkRateLimit(): Three-tier check - global, per-user, per-endpoint with logging on rejection"
    },
    {
      "lines": "432-540",
      "explanation": "Core API methods (createEvent, createBooking) now instrumented with rate limiting, timing, and logging"
    },
    {
      "lines": "542-600",
      "explanation": "main() demonstration: Shows health check, metrics, rate limiting in action"
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "healthCheck": {
          "complexity": "O(d)",
          "explanation": "d = number of dependencies to check (constant in practice)"
        },
        "getMetrics": {
          "complexity": "O(n log n)",
          "explanation": "Sorting n latencies for percentile, but n is bounded by window size (constant)"
        },
        "checkRateLimit": {
          "complexity": "O(1) amortized",
          "explanation": "Deque operations are O(1), cleanup amortized over multiple calls"
        }
      },
      "overall_change": "No change to core operations - rate limiting adds O(1) overhead per request"
    },
    "space": {
      "additional_space": "O(u * r + m) where u=unique users, r=rate limit window requests, m=metrics window",
      "explanation": "Each user+endpoint combo stores up to r timestamps. Metrics stores m latency samples. Both are bounded by configuration."
    }
  },
  "dry_run": {
    "example_input": "checkRateLimit called 12 times for same user on /bookings (limit=10/min)",
    "steps": [
      {
        "step": 1,
        "action": "Request 1 at t=0",
        "state": "deque=[0], size=1",
        "explanation": "Under limit, allowed"
      },
      {
        "step": 2,
        "action": "Requests 2-10",
        "state": "deque=[0,1,2,...,9], size=10",
        "explanation": "All allowed, now at limit"
      },
      {
        "step": 3,
        "action": "Request 11 at t=10",
        "state": "deque still has 10 entries in window",
        "explanation": "At limit, REJECTED"
      },
      {
        "step": 4,
        "action": "Request 12 at t=11",
        "state": "Same, no entries expired yet",
        "explanation": "Still REJECTED"
      },
      {
        "step": 5,
        "action": "Request at t=61",
        "state": "Entry [0] expires, deque=[1..9,61], size=10",
        "explanation": "One slot freed, ALLOWED"
      }
    ],
    "final_output": "First 10 requests allowed, requests 11-12 rejected, request at t=61 allowed"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "healthCheck() returns 200 with status='healthy'",
      "checkRateLimit returns true for first request"
    ],
    "likely_bugs": [
      "Timestamp precision issues (ms vs sec)",
      "Off-by-one in window boundary",
      "Race condition in concurrent rate limit check"
    ],
    "recommended_logs_or_asserts": [
      "assert len(deque) <= max_requests",
      "log window_start and current_time on rate limit failures"
    ],
    "how_to_localize": "1) Print deque contents and timestamps on each check. 2) Verify window math: current - window_seconds. 3) Check lock acquisition order for deadlocks."
  },
  "edge_cases": [
    {
      "case": "First request ever",
      "handling": "Create new deque, allow request",
      "gotcha": "Don't forget to add timestamp after allowing"
    },
    {
      "case": "Exactly at rate limit",
      "handling": "Reject - use < not <= for comparison",
      "gotcha": "Off-by-one: 10 requests means 10th is last allowed"
    },
    {
      "case": "Request at exact window boundary",
      "handling": "Include requests at exactly window_start in count",
      "gotcha": "Use >= for window comparison"
    },
    {
      "case": "Health check when DB is down",
      "handling": "Return degraded status, don't throw exception",
      "gotcha": "Health check should never fail with 500"
    },
    {
      "case": "Empty metrics (no requests yet)",
      "handling": "Return 0 for all percentiles",
      "gotcha": "Division by zero in average calculation"
    }
  ],
  "test_cases": [
    {
      "name": "Health check returns healthy status",
      "input": "api.health_check()",
      "expected": "Response(200, {status: 'healthy', checks: {...}})",
      "explanation": "Verifies all components are checked and status is computed correctly"
    },
    {
      "name": "Rate limit allows requests up to limit",
      "input": "10 calls to checkRateLimit('user1', '/bookings')",
      "expected": "All 10 return true",
      "explanation": "With 10/min limit, first 10 requests should succeed"
    },
    {
      "name": "Rate limit blocks after exceeding",
      "input": "11th call to checkRateLimit('user1', '/bookings')",
      "expected": "Returns false",
      "explanation": "11th request exceeds 10/min limit"
    },
    {
      "name": "Metrics track latency percentiles",
      "input": "Record requests with latencies [10, 20, 30, 40, 50], call getMetrics()",
      "expected": "p50=30ms, avg=30ms",
      "explanation": "Median of 5 values is the 3rd value (30)"
    },
    {
      "name": "Sensitive data is masked in logs",
      "input": "Log entry with password='secret123'",
      "expected": "password='***REDACTED***' in output",
      "explanation": "Security requirement - never log passwords"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Using fixed window instead of sliding window for rate limiting",
      "why_wrong": "Fixed windows allow burst at boundaries (100 at 0:59 + 100 at 1:01 = 200 in 2 seconds)",
      "correct_approach": "Use sliding window log that tracks individual request timestamps",
      "code_example_wrong": "# Wrong: reset counter every minute\\nif current_minute != last_minute:\\n    counter = 0",
      "code_example_correct": "# Correct: track timestamps, remove expired\\nwhile timestamps[0] < window_start:\\n    timestamps.popleft()"
    },
    {
      "mistake": "Logging sensitive data",
      "why_wrong": "Security violation, GDPR issues, credential exposure in log aggregation",
      "correct_approach": "Mask sensitive fields before logging",
      "code_example_wrong": "logger.info(f'Login attempt: user={username}, password={password}')",
      "code_example_correct": "logger.info(f'Login attempt: user={username}, password=***REDACTED***')"
    },
    {
      "mistake": "Health check that throws exceptions",
      "why_wrong": "Monitoring systems expect health endpoint to always return, even when unhealthy",
      "correct_approach": "Catch all exceptions, return degraded status with error details",
      "code_example_wrong": "def health_check():\\n    db.ping()  # Throws if DB down!\\n    return {'status': 'healthy'}",
      "code_example_correct": "def health_check():\\n    try:\\n        db.ping()\\n        checks['db'] = 'ok'\\n    except:\\n        checks['db'] = 'error'\\n    return {'status': 'healthy' if all_ok else 'degraded'}"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start with the WHY: 'Production systems need observability. Let me add health checks for monitoring, rate limiting for protection, and structured logging for debugging.' Then walk through each component.",
    "what_to_mention": [
      "Three-tier rate limiting strategy and why each tier exists",
      "Sliding window vs fixed window tradeoff",
      "What to log (request ID, user, duration) vs what NOT to log (passwords, PII)",
      "Health check should verify all critical dependencies",
      "Percentile metrics (P50/P95/P99) matter more than averages"
    ],
    "time_allocation": "10-15 min: 3 min explain approach, 7 min implement core (rate limiter + health check), 3 min test and discuss",
    "if_stuck": [
      "Start with simplest rate limiter (per-user counter)",
      "Health check can just return counts initially",
      "Add complexity incrementally"
    ]
  },
  "connection_to_next_part": "Part 4 completes the production readiness layer. A Part 5 might cover: distributed rate limiting with Redis, circuit breakers for external dependencies, or horizontal scaling with eventual consistency. The modular design (separate RateLimiter, MetricsCollector, Logger classes) makes swapping implementations easy.",
  "communication_script": {
    "transition_from_previous": "Great, Part 3 handles concurrency with per-event locks. For Part 4, I need to add production observability: health checks so monitoring knows if the system is healthy, rate limiting to prevent abuse, and structured logging for debugging. Let me walk through my approach.",
    "explaining_changes": "The key additions are: 1) SlidingWindowRateLimiter using deques for O(1) rate checks, 2) MetricsCollector with ring buffers for latency percentiles, 3) StructuredLogger that auto-masks sensitive data. These are injected into TicketAPI as dependencies.",
    "while_extending_code": [
      "I'm adding a SlidingWindowRateLimiter class - it stores timestamps per key and lazily cleans up expired entries...",
      "The health check will verify database, cache, and metrics are operational...",
      "I'm wrapping each API call with rate limiting and logging for observability..."
    ],
    "after_completing": "Part 4 is complete. Health check is O(d), rate limiting is O(1) amortized, metrics are bounded by window size. The system can now be monitored, protected from abuse, and debugged in production. Ready to discuss scaling or any other aspect?"
  },
  "time_milestones": {
    "time_budget": "10-15 minutes for this part",
    "by_2_min": "Explain three-tier rate limiting and sliding window concept",
    "by_5_min": "SlidingWindowRateLimiter implementation complete",
    "by_8_min": "Health check and metrics collection added",
    "by_12_min": "Structured logging integrated, testing complete",
    "warning_signs": "If still explaining rate limiting concepts at 5 min, simplify to basic counter first. If code has bugs at 10 min, focus on one working feature."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "Rate limiting and logging are independent of Parts 1-3 core logic. If earlier parts have bugs, say: 'Let me isolate the production features - they wrap the existing API without changing its core behavior.'",
    "if_new_requirement_unclear": "Ask: 'For rate limiting, should I implement sliding window or is a simpler fixed window acceptable for this discussion?'",
    "if_running_behind": "Implement checkRateLimit with a simple per-user counter first. Mention: 'A production system would use sliding window, but let me get the interface working first.'"
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Explaining why sliding window prevents boundary burst attacks",
      "Mentioning distributed rate limiting would need Redis with Lua scripts",
      "Noting that P99 latency is what SLAs care about, not averages",
      "Discussing log aggregation (ELK stack, Datadog) and structured logging benefits",
      "Proactively suggesting circuit breakers for external dependency protection"
    ]
  },
  "pattern_recognition": {
    "pattern": "Sliding Window + Decorator/Middleware Pattern",
    "indicators": [
      "Rate limiting requirement",
      "Need for O(1) request counting",
      "Multi-tier limits suggest decorator pattern"
    ],
    "similar_problems": [
      "LC 359 - Logger Rate Limiter",
      "LC 362 - Design Hit Counter",
      "API Gateway rate limiting"
    ],
    "template": "class SlidingWindowRateLimiter:\\n    def __init__(self, window_sec, max_req):\\n        self.window = window_sec\\n        self.limit = max_req\\n        self.requests = defaultdict(deque)\\n    \\n    def is_allowed(self, key):\\n        now = time.time()\\n        q = self.requests[key]\\n        while q and q[0] < now - self.window:\\n            q.popleft()\\n        if len(q) < self.limit:\\n            q.append(now)\\n            return True\\n        return False"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "Rate limiting needs to be fast (O(1)) since it runs on every request",
      "why": "Any overhead multiplies across thousands of requests per second"
    },
    {
      "step": 2,
      "thought": "Sliding window is better than fixed window for rate limiting",
      "why": "Fixed windows have boundary burst problem - 2x requests possible in 2 seconds"
    },
    {
      "step": 3,
      "thought": "Health checks must never throw exceptions",
      "why": "Monitoring systems poll health endpoints; a 500 error defeats the purpose"
    },
    {
      "step": 4,
      "thought": "Logs need request IDs for distributed tracing",
      "why": "In microservices, one user request spans multiple services; IDs correlate logs"
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Do you understand production concerns beyond just 'it works'?",
      "Can you implement efficient rate limiting?",
      "Do you know what to log and what not to log?",
      "Can you design for observability?"
    ],
    "bonus_points": [
      "Mentioning token bucket vs sliding window tradeoffs",
      "Discussing alerting thresholds (P99 > 500ms)",
      "Noting GDPR implications of logging PII",
      "Suggesting circuit breakers for cascading failure prevention"
    ],
    "red_flags": [
      "Implementing O(n) rate limiting",
      "Logging passwords or tokens",
      "Health check that crashes when dependencies are down",
      "No consideration for multi-tier rate limits"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Use AI for boilerplate (dataclasses, JSON formatting)",
      "Let it help with datetime/timestamp handling",
      "Ask for percentile calculation formula"
    ],
    "what_not_to_do": [
      "Don't let AI choose rate limiting algorithm without understanding tradeoffs",
      "Verify the sliding window logic is correct",
      "Ensure sensitive data masking is comprehensive"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Dismissing production concerns as 'ops stuff'",
      "Not asking about expected traffic/load"
    ],
    "technical": [
      "Using O(n) algorithms for per-request operations",
      "Not handling edge cases (empty metrics, first request)",
      "Forgetting thread safety in rate limiter"
    ],
    "communication": [
      "Not explaining why observability matters",
      "Implementing without discussing the strategy first"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Rate limiter is O(1) amortized with sliding window?",
      "Health check catches exceptions and returns degraded status?",
      "Metrics include percentiles, not just averages?",
      "Logger masks sensitive fields?",
      "All core API methods are instrumented with logging and rate limiting?"
    ],
    "quick_code_review": [
      "Thread locks around shared state in rate limiter",
      "Bounded ring buffers for metrics (no memory leak)",
      "Consistent error response format (JSON with 'error' key)",
      "Request ID generated for tracing"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Redis-backed rate limiter for distributed systems",
      "Prometheus metrics exposition endpoint (/metrics)",
      "Correlation IDs propagated to downstream services",
      "Circuit breaker for external dependencies",
      "Graceful degradation when rate limited (queue instead of reject)"
    ],
    "why_not_in_interview": "Focus on demonstrating understanding of concepts; actual implementation would use libraries (ratelimit, prometheus_client)",
    "how_to_mention": "Say: 'In production, I'd use Redis for distributed rate limiting with Lua scripts for atomicity, and export metrics in Prometheus format for Grafana dashboards.'"
  },
  "generated_at": "2026-01-18T21:42:55.154658",
  "_meta": {
    "problem_id": "production_ready_ticket_booking_api",
    "part_number": 4,
    "model": "claude-opus-4-5-20251101"
  }
}