{
  "problem_title": "News Feed Aggregator System - Part 2: Real-Time Notifications & Breaking News",
  "part_number": 2,
  "builds_on": "Part 1",
  "difficulty": "medium",
  "problem_understanding": {
    "what_changes": "Part 2 extends the basic news feed system with real-time notification capabilities. While Part 1 focused on fetching and displaying articles in a user's feed, Part 2 adds a **push-based** delivery mechanism that proactively alerts users about breaking news within 30 seconds. This requires: (1) An inverted index from categories to users for fast audience lookup, (2) A notification preferences system with rate limiting, (3) An async message queue for processing notifications, (4) Delivery tracking for engagement analytics.",
    "new_requirements": [
      "Breaking news alerts must reach relevant users within 30 seconds",
      "Personalized notification filtering based on user interests and followed publishers",
      "Support for notification preferences including frequency limits and quiet hours",
      "Track notification delivery and engagement (read status)",
      "Rate limiting to prevent notification spam (configurable per user)"
    ],
    "new_constraints": [
      "30-second SLA for breaking news delivery",
      "Must support 100K+ concurrent users receiving notifications",
      "Rate limiting: configurable max notifications per day per user",
      "Quiet hours: no notifications during user-specified hours",
      "Priority threshold: only notify for articles meeting minimum priority"
    ],
    "key_insight": "**Pre-build an inverted index: category -> [user_ids]**. When breaking news arrives, audience lookup is O(1) per category instead of O(n) scanning all users. Combined with a message queue for async processing and Redis-style rate limiting, we can meet the 30-second SLA even at scale."
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Breaking news within 30 seconds",
        "how_met": "Message queue + inverted index enables O(1) audience lookup. publishBreakingNews() enqueues immediately, workers process async.",
        "gotchas": [
          "Don't block on push gateway responses",
          "Use circuit breaker for external services"
        ]
      },
      {
        "requirement": "Personalized notification filtering",
        "how_met": "_should_notify_user() checks: enabled flag, priority threshold, category interest, quiet hours, rate limit",
        "gotchas": [
          "Category intersection must use user's notification prefs, not just their interests"
        ]
      },
      {
        "requirement": "Notification preferences with limits",
        "how_met": "NotificationPrefs dataclass stores max_daily, categories, quiet_hours. RateLimiter tracks sends per user.",
        "gotchas": [
          "Quiet hours can span midnight (22:00-08:00) - handle overnight range correctly"
        ]
      },
      {
        "requirement": "Track delivery and engagement",
        "how_met": "delivery_stats dict tracks delivered_at, read_at timestamps. markNotificationRead() updates engagement.",
        "gotchas": [
          "Don't forget to record delivery when notification is created, not just when sent to push gateway"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "publishBreakingNews",
        "target": "O(1) enqueue, O(audience) process",
        "achieved": "O(1) + O(A)",
        "why": "Queue enqueue is O(1), processing iterates over target audience"
      },
      {
        "operation": "setNotificationPreferences",
        "target": "O(categories)",
        "achieved": "O(C)",
        "why": "Updates inverted index for each category"
      },
      {
        "operation": "getPendingNotifications",
        "target": "O(n log n)",
        "achieved": "O(n log n)",
        "why": "Filters and sorts user's notifications"
      },
      {
        "operation": "markNotificationRead",
        "target": "O(n)",
        "achieved": "O(n)",
        "why": "Linear scan through user's notifications"
      }
    ],
    "non_goals": [
      "Actual push notification integration (FCM/APNS) - we simulate delivery",
      "Distributed message queue (Kafka) - we use in-memory Queue",
      "WebSocket connections for real-time web delivery",
      "Notification batching/digest mode"
    ]
  },
  "assumptions": [
    "Part 1 has basic user registration, publisher following, and article publishing implemented",
    "Priority >= 8 is considered 'breaking news' threshold (configurable)",
    "In-memory data structures are acceptable for interview; production would use Redis + Kafka",
    "Single-threaded processing for demonstration; production would use worker pools",
    "Notification delivery is simulated (no actual FCM/APNS integration)"
  ],
  "tradeoffs": [
    {
      "decision": "Inverted Index vs Full User Scan",
      "chosen": "Inverted Index (category -> users)",
      "why": "O(1) lookup per category vs O(n) scanning all users. Critical for 30-second SLA.",
      "alternative": "Full scan with parallel processing",
      "when_to_switch": "If categories are highly dynamic or users change interests frequently"
    },
    {
      "decision": "Synchronous vs Async Notification Processing",
      "chosen": "Async (Message Queue)",
      "why": "publishBreakingNews returns immediately, doesn't block on audience processing",
      "alternative": "Synchronous inline processing",
      "when_to_switch": "For very small user bases where latency doesn't matter"
    },
    {
      "decision": "In-Memory vs External Rate Limiter",
      "chosen": "In-Memory RateLimiter class",
      "why": "Simpler for interview, demonstrates the algorithm clearly",
      "alternative": "Redis Sorted Sets with TTL",
      "when_to_switch": "Production systems with multiple servers need shared state"
    },
    {
      "decision": "List vs Heap for Notifications",
      "chosen": "List with sort on read",
      "why": "Simpler, notifications are usually read in batches not streamed",
      "alternative": "Heap for O(log n) insert, O(1) top priority",
      "when_to_switch": "If users have thousands of pending notifications and need streaming"
    }
  ],
  "extensibility_notes": {
    "what_to_keep_stable": [
      "Public method signatures (publishBreakingNews, setNotificationPreferences, etc.)",
      "Notification and NotificationPrefs dataclass structure",
      "Inverted index lookup pattern"
    ],
    "what_to_change": [
      "Added category_users inverted index",
      "Added user_notifications storage",
      "Added RateLimiter and MessageQueue classes",
      "Extended User dataclass with notification_prefs"
    ],
    "interfaces_and_boundaries": "NotificationProcessor could be extracted as an interface for different delivery backends (FCM, APNS, WebSocket). RateLimiter is already a separate class that could implement a Redis backend. MessageQueue abstracts the queue implementation.",
    "invariants": [
      "Every notification has a unique notification_id",
      "rate_limiter.get_count(user) <= user.notification_prefs.max_daily (after filtering)",
      "category_users[cat] always reflects current user subscriptions",
      "Notifications are created only after passing all filters"
    ]
  },
  "visual_explanation": {
    "before_after": "```\nBEFORE (Part 1 Only):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Publisher \u2192 Article Store \u2192 User Request \u2192 Feed        \u2502\n\u2502                                                         \u2502\n\u2502  Users PULL their feed (read-heavy, 100K QPS)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nAFTER (Part 2 Added):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Publisher \u2192 Article Store \u2192 User Request \u2192 Feed        \u2502\n\u2502       \u2502                                                 \u2502\n\u2502       \u25bc (if breaking news)                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502 NOTIFICATION PIPELINE (NEW)                    \u2502     \u2502\n\u2502  \u2502                                                \u2502     \u2502\n\u2502  \u2502  Message Queue \u2192 Audience Finder \u2192 Filter     \u2502     \u2502\n\u2502  \u2502       \u2193              \u2193               \u2193        \u2502     \u2502\n\u2502  \u2502  O(1) enqueue   O(1) lookup    Rate limit    \u2502     \u2502\n\u2502  \u2502                      \u2193               \u2193        \u2502     \u2502\n\u2502  \u2502               category_users   Preferences   \u2502     \u2502\n\u2502  \u2502                      \u2193                        \u2502     \u2502\n\u2502  \u2502               Push Notifications \u2192 Users      \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": "```\npublishBreakingNews() Flow:\n\n  1. STORE ARTICLE\n     \u2514\u2500\u2500 publish_article() [O(1)]\n\n  2. CHECK PRIORITY\n     \u2514\u2500\u2500 if priority >= 8 \u2192 enqueue notification job\n\n  3. PROCESS QUEUE (async)\n     \u2502\n     \u251c\u2500\u2500 3a. FIND AUDIENCE [O(1) per source]\n     \u2502   \u251c\u2500\u2500 publisher_followers[publisher_id]\n     \u2502   \u2514\u2500\u2500 category_users[category] for each category\n     \u2502   \u2514\u2500\u2500 Union all \u2192 target_users set\n     \u2502\n     \u251c\u2500\u2500 3b. FILTER EACH USER [O(1) per user]\n     \u2502   \u251c\u2500\u2500 Check: enabled?\n     \u2502   \u251c\u2500\u2500 Check: priority >= min_priority?\n     \u2502   \u251c\u2500\u2500 Check: interested in categories?\n     \u2502   \u251c\u2500\u2500 Check: not in quiet hours?\n     \u2502   \u2514\u2500\u2500 Check: rate limit not exceeded?\n     \u2502\n     \u2514\u2500\u2500 3c. CREATE NOTIFICATIONS [O(1) per user]\n         \u251c\u2500\u2500 Generate notification_id\n         \u251c\u2500\u2500 Add to user_notifications[user_id]\n         \u2514\u2500\u2500 Record in rate_limiter\n```"
  },
  "approaches": [
    {
      "name": "Naive Extension - Full User Scan",
      "description": "On every breaking news, iterate through ALL users to check if they should be notified. For each user, check if they follow the publisher OR are interested in any article category.",
      "time_complexity": "O(U) where U = total users (potentially millions)",
      "space_complexity": "O(1) additional",
      "why_not_optimal": "With 10M users and 58 writes/second, this means scanning 580M users per second. Impossible to meet 30-second SLA. Even with parallelization, this doesn't scale."
    },
    {
      "name": "Optimal Approach - Inverted Index + Message Queue",
      "description": "Pre-build inverted index: category -> Set<user_ids>. Also maintain publisher_followers index. On breaking news: (1) O(1) queue enqueue, (2) O(1) lookup interested users via index, (3) Filter and notify only relevant users.",
      "time_complexity": "O(1) enqueue + O(A) process where A = audience size (typically <<< total users)",
      "space_complexity": "O(U\u00d7C) for inverted index where U = users, C = avg categories per user",
      "key_insight": "Most breaking news only reaches a small fraction of users (10-50K out of 10M). Pre-computing the audience lookup turns a full scan into a hash lookup."
    }
  ],
  "optimal_solution": {
    "explanation_md": "## Optimal Solution: Inverted Index + Async Processing\n\n### Core Insight\nThe **key optimization** is maintaining an inverted index that maps each category/interest to the set of users who want notifications for that category.\n\nInstead of:\n```\nfor each user in all_users:  # O(U) - millions\n    if user interested in article.categories:\n        notify(user)\n```\n\nWe do:\n```\ntarget_users = set()\nfor category in article.categories:  # O(C) - typically 2-3\n    target_users |= category_users[category]  # O(1) lookup\nfor user in target_users:  # O(A) - actual audience\n    if passes_filters(user):\n        notify(user)\n```\n\n### Data Structures\n\n1. **Inverted Index**: `category_users: Dict[str, Set[str]]`\n   - Maps category \u2192 set of user IDs interested in that category\n   - Updated on: user registration, preference changes, following changes\n\n2. **Rate Limiter**: Sliding window counter per user\n   - Tracks notification count in last 24 hours\n   - Uses timestamp list with cleanup\n\n3. **Message Queue**: Decouples publishing from processing\n   - Publisher returns immediately after enqueue\n   - Workers process notification jobs async\n\n### Filter Pipeline\n\nEach potential recipient goes through a filter chain:\n1. **Enabled Check**: Is notifications enabled?\n2. **Priority Check**: Does article priority >= user's min_priority?\n3. **Category Check**: Does user care about ANY article category?\n4. **Quiet Hours Check**: Is current time within user's quiet hours?\n5. **Rate Limit Check**: Has user exceeded daily limit?\n\nOnly users passing ALL filters receive the notification.",
    "data_structures": [
      {
        "structure": "Dict[str, Set[str]] - category_users",
        "purpose": "Inverted index for O(1) audience lookup by category"
      },
      {
        "structure": "Dict[str, List[Notification]] - user_notifications",
        "purpose": "Store pending and historical notifications per user"
      },
      {
        "structure": "RateLimiter (sliding window)",
        "purpose": "Track and enforce daily notification limits per user"
      },
      {
        "structure": "MessageQueue (FIFO)",
        "purpose": "Async processing of notification jobs"
      }
    ],
    "algorithm_steps": [
      "Step 1: publishBreakingNews receives article with priority",
      "Step 2: Store article in articles dict (same as Part 1)",
      "Step 3: If priority >= threshold (8), create notification job and enqueue",
      "Step 4: Worker dequeues job and finds target audience via inverted index",
      "Step 5: For each target user, run filter pipeline (_should_notify_user)",
      "Step 6: Create Notification object for users passing all filters",
      "Step 7: Store notification in user_notifications and record in rate_limiter",
      "Step 8: (Production) Send to push gateway (FCM/APNS)"
    ]
  },
  "solution_python_lines": [
    "from dataclasses import dataclass, field",
    "from typing import Dict, List, Set, Optional",
    "from datetime import datetime",
    "from collections import defaultdict",
    "from enum import Enum",
    "import time",
    "import uuid",
    "from threading import Lock",
    "from queue import Queue",
    "",
    "",
    "class NotificationPriority(Enum):",
    "    \"\"\"Priority levels for notifications.\"\"\"",
    "    LOW = 1",
    "    MEDIUM = 5",
    "    HIGH = 8",
    "    BREAKING = 10",
    "",
    "",
    "@dataclass",
    "class Article:",
    "    \"\"\"Represents a news article.\"\"\"",
    "    article_id: str",
    "    title: str",
    "    content: str",
    "    publisher_id: str",
    "    categories: List[str]",
    "    timestamp: datetime = field(default_factory=datetime.now)",
    "    url: str = \"\"",
    "",
    "",
    "@dataclass",
    "class NotificationPrefs:",
    "    \"\"\"User notification preferences.\"\"\"",
    "    max_daily: int = 5",
    "    categories: List[str] = field(default_factory=lambda: [\"Breaking\"])",
    "    quiet_hours_start: int = 22  # 10 PM",
    "    quiet_hours_end: int = 8    # 8 AM",
    "    enabled: bool = True",
    "    min_priority: int = 5",
    "",
    "",
    "@dataclass",
    "class Notification:",
    "    \"\"\"Represents a user notification.\"\"\"",
    "    notification_id: str",
    "    article_id: str",
    "    title: str",
    "    publisher_id: str",
    "    priority: int",
    "    timestamp: datetime",
    "    read: bool = False",
    "    delivered: bool = False",
    "",
    "",
    "@dataclass",
    "class User:",
    "    \"\"\"Represents a user with their preferences.\"\"\"",
    "    user_id: str",
    "    interests: List[str] = field(default_factory=list)",
    "    following: Set[str] = field(default_factory=set)",
    "    notification_prefs: NotificationPrefs = field(default_factory=NotificationPrefs)",
    "",
    "",
    "class RateLimiter:",
    "    \"\"\"",
    "    Sliding window rate limiter for notifications.",
    "    ",
    "    Uses a list of timestamps per user to track notification count",
    "    within a sliding window (default 24 hours).",
    "    \"\"\"",
    "    ",
    "    def __init__(self, window_seconds: int = 86400):",
    "        self.window_seconds = window_seconds",
    "        self.user_timestamps: Dict[str, List[float]] = defaultdict(list)",
    "        self._lock = Lock()",
    "    ",
    "    def can_send(self, user_id: str, max_count: int) -> bool:",
    "        \"\"\"Check if user can receive another notification.\"\"\"",
    "        with self._lock:",
    "            current_time = time.time()",
    "            cutoff = current_time - self.window_seconds",
    "            ",
    "            # Clean old entries",
    "            self.user_timestamps[user_id] = [",
    "                ts for ts in self.user_timestamps[user_id]",
    "                if ts > cutoff",
    "            ]",
    "            ",
    "            return len(self.user_timestamps[user_id]) < max_count",
    "    ",
    "    def record_send(self, user_id: str) -> None:",
    "        \"\"\"Record a notification send for rate limiting.\"\"\"",
    "        with self._lock:",
    "            self.user_timestamps[user_id].append(time.time())",
    "    ",
    "    def get_count(self, user_id: str) -> int:",
    "        \"\"\"Get current notification count for user.\"\"\"",
    "        with self._lock:",
    "            current_time = time.time()",
    "            cutoff = current_time - self.window_seconds",
    "            self.user_timestamps[user_id] = [",
    "                ts for ts in self.user_timestamps[user_id]",
    "                if ts > cutoff",
    "            ]",
    "            return len(self.user_timestamps[user_id])",
    "",
    "",
    "class MessageQueue:",
    "    \"\"\"Simple in-memory message queue for demonstration.\"\"\"",
    "    ",
    "    def __init__(self):",
    "        self._queue: Queue = Queue()",
    "    ",
    "    def enqueue(self, message: dict) -> None:",
    "        self._queue.put(message)",
    "    ",
    "    def dequeue(self) -> Optional[dict]:",
    "        if self._queue.empty():",
    "            return None",
    "        return self._queue.get_nowait()",
    "    ",
    "    def is_empty(self) -> bool:",
    "        return self._queue.empty()",
    "",
    "",
    "class NewsAggregator:",
    "    \"\"\"",
    "    News Feed Aggregator System with Real-Time Notifications.",
    "    ",
    "    Part 2 extends the base system with:",
    "    - Breaking news alerts within 30 seconds",
    "    - Personalized notification filtering",
    "    - Notification preferences (frequency limits, quiet hours)",
    "    - Delivery and engagement tracking",
    "    \"\"\"",
    "    ",
    "    BREAKING_NEWS_THRESHOLD = 8",
    "    ",
    "    def __init__(self):",
    "        # Part 1 data structures",
    "        self.users: Dict[str, User] = {}",
    "        self.articles: Dict[str, Article] = {}",
    "        self.publisher_articles: Dict[str, List[str]] = defaultdict(list)",
    "        self.publisher_followers: Dict[str, Set[str]] = defaultdict(set)",
    "        ",
    "        # Part 2: Inverted index for fast audience lookup",
    "        # Maps category -> set of user IDs interested in that category",
    "        self.category_users: Dict[str, Set[str]] = defaultdict(set)",
    "        ",
    "        # User notifications storage",
    "        self.user_notifications: Dict[str, List[Notification]] = defaultdict(list)",
    "        ",
    "        # Rate limiter for daily notification limits",
    "        self.rate_limiter = RateLimiter()",
    "        ",
    "        # Message queue for async notification processing",
    "        self.notification_queue = MessageQueue()",
    "        ",
    "        # Delivery statistics for analytics",
    "        self.delivery_stats: Dict[str, dict] = {}",
    "        ",
    "        # Thread safety lock",
    "        self._lock = Lock()",
    "    ",
    "    # ==================== Part 1 Methods (Extended) ====================",
    "    ",
    "    def register_user(self, user_id: str, interests: List[str] = None) -> None:",
    "        \"\"\"Register a new user with optional interests.\"\"\"",
    "        if user_id in self.users:",
    "            return",
    "        ",
    "        interests = interests or []",
    "        self.users[user_id] = User(user_id=user_id, interests=interests)",
    "        ",
    "        # Update inverted index for interests",
    "        for category in interests:",
    "            self.category_users[category].add(user_id)",
    "    ",
    "    def follow_publisher(self, user_id: str, publisher_id: str) -> None:",
    "        \"\"\"User follows a publisher.\"\"\"",
    "        if user_id not in self.users:",
    "            self.register_user(user_id)",
    "        ",
    "        self.users[user_id].following.add(publisher_id)",
    "        self.publisher_followers[publisher_id].add(user_id)",
    "    ",
    "    def unfollow_publisher(self, user_id: str, publisher_id: str) -> None:",
    "        \"\"\"User unfollows a publisher.\"\"\"",
    "        if user_id in self.users:",
    "            self.users[user_id].following.discard(publisher_id)",
    "            self.publisher_followers[publisher_id].discard(user_id)",
    "    ",
    "    def add_user_interest(self, user_id: str, category: str) -> None:",
    "        \"\"\"Add an interest category for a user.\"\"\"",
    "        if user_id not in self.users:",
    "            self.register_user(user_id)",
    "        ",
    "        if category not in self.users[user_id].interests:",
    "            self.users[user_id].interests.append(category)",
    "            self.category_users[category].add(user_id)",
    "    ",
    "    def publish_article(self, publisher_id: str, article: Article) -> str:",
    "        \"\"\"Publish a regular article (non-breaking news).\"\"\"",
    "        article_id = article.article_id or f\"article_{uuid.uuid4().hex[:8]}\"",
    "        article.article_id = article_id",
    "        article.publisher_id = publisher_id",
    "        ",
    "        self.articles[article_id] = article",
    "        self.publisher_articles[publisher_id].append(article_id)",
    "        ",
    "        return article_id",
    "    ",
    "    def get_feed(self, user_id: str, page_size: int = 10) -> List[Article]:",
    "        \"\"\"Get personalized feed for user (from Part 1).\"\"\"",
    "        if user_id not in self.users:",
    "            return []",
    "        ",
    "        user = self.users[user_id]",
    "        feed_articles = []",
    "        ",
    "        for publisher_id in user.following:",
    "            for article_id in self.publisher_articles.get(publisher_id, []):",
    "                if article_id in self.articles:",
    "                    feed_articles.append(self.articles[article_id])",
    "        ",
    "        feed_articles.sort(key=lambda a: a.timestamp, reverse=True)",
    "        return feed_articles[:page_size]",
    "    ",
    "    # ==================== Part 2 Methods ====================",
    "    ",
    "    def set_notification_preferences(",
    "        self, user_id: str, prefs: NotificationPrefs",
    "    ) -> None:",
    "        \"\"\"",
    "        Set notification preferences for a user.",
    "        ",
    "        Args:",
    "            user_id: The user ID",
    "            prefs: NotificationPrefs object with settings",
    "        ",
    "        Time Complexity: O(C) where C = number of categories",
    "        \"\"\"",
    "        if user_id not in self.users:",
    "            self.register_user(user_id)",
    "        ",
    "        old_prefs = self.users[user_id].notification_prefs",
    "        self.users[user_id].notification_prefs = prefs",
    "        ",
    "        # Update category index if categories changed",
    "        old_categories = set(old_prefs.categories) if old_prefs else set()",
    "        new_categories = set(prefs.categories)",
    "        ",
    "        for cat in old_categories - new_categories:",
    "            self.category_users[cat].discard(user_id)",
    "        ",
    "        for cat in new_categories - old_categories:",
    "            self.category_users[cat].add(user_id)",
    "    ",
    "    def publish_breaking_news(",
    "        self, publisher_id: str, article: Article, priority: int",
    "    ) -> None:",
    "        \"\"\"",
    "        Publish breaking news and trigger notification pipeline.",
    "        ",
    "        This is the main entry point for breaking news. It:",
    "        1. Validates and stores the article",
    "        2. Enqueues notification job if priority >= threshold",
    "        3. Processes notifications asynchronously",
    "        ",
    "        Args:",
    "            publisher_id: The publisher ID",
    "            article: The breaking news article",
    "            priority: Priority level 1-10 (10 = most urgent)",
    "        ",
    "        Time Complexity: O(1) to enqueue, O(audience_size) to process",
    "        \"\"\"",
    "        # Store the article",
    "        article_id = self.publish_article(publisher_id, article)",
    "        ",
    "        # Only process as breaking news if priority meets threshold",
    "        if priority >= self.BREAKING_NEWS_THRESHOLD:",
    "            notification_job = {",
    "                \"type\": \"breaking_news\",",
    "                \"article_id\": article_id,",
    "                \"publisher_id\": publisher_id,",
    "                \"title\": article.title,",
    "                \"categories\": article.categories,",
    "                \"priority\": priority,",
    "                \"timestamp\": datetime.now().isoformat()",
    "            }",
    "            self.notification_queue.enqueue(notification_job)",
    "            ",
    "            # Process immediately (in production, async workers)",
    "            self._process_notification_queue()",
    "    ",
    "    def _process_notification_queue(self) -> None:",
    "        \"\"\"Process pending notification jobs from the queue.\"\"\"",
    "        while not self.notification_queue.is_empty():",
    "            job = self.notification_queue.dequeue()",
    "            if job and job[\"type\"] == \"breaking_news\":",
    "                self._process_breaking_news_notification(job)",
    "    ",
    "    def _process_breaking_news_notification(self, job: dict) -> None:",
    "        \"\"\"",
    "        Process a single breaking news notification job.",
    "        ",
    "        Steps:",
    "        1. Find target audience (publisher followers + category interested)",
    "        2. Filter by user preferences",
    "        3. Create and deliver notifications",
    "        ",
    "        Time Complexity: O(audience_size)",
    "        \"\"\"",
    "        article_id = job[\"article_id\"]",
    "        publisher_id = job[\"publisher_id\"]",
    "        categories = job[\"categories\"]",
    "        priority = job[\"priority\"]",
    "        title = job[\"title\"]",
    "        ",
    "        # Find target audience using inverted index - O(1) per source",
    "        target_users: Set[str] = set()",
    "        ",
    "        # Add publisher followers",
    "        target_users.update(self.publisher_followers.get(publisher_id, set()))",
    "        ",
    "        # Add users interested in these categories",
    "        for category in categories:",
    "            target_users.update(self.category_users.get(category, set()))",
    "        ",
    "        # Filter and create notifications",
    "        for user_id in target_users:",
    "            if self._should_notify_user(user_id, categories, priority):",
    "                self._create_notification(",
    "                    user_id, article_id, title, publisher_id, priority",
    "                )",
    "    ",
    "    def _should_notify_user(",
    "        self, user_id: str, categories: List[str], priority: int",
    "    ) -> bool:",
    "        \"\"\"",
    "        Check if a user should receive a notification.",
    "        ",
    "        Filters:",
    "        1. User has notifications enabled",
    "        2. Priority meets user's minimum",
    "        3. User is interested in at least one category",
    "        4. Not in quiet hours",
    "        5. Not exceeded daily rate limit",
    "        \"\"\"",
    "        if user_id not in self.users:",
    "            return False",
    "        ",
    "        user = self.users[user_id]",
    "        prefs = user.notification_prefs",
    "        ",
    "        # Check if notifications enabled",
    "        if not prefs.enabled:",
    "            return False",
    "        ",
    "        # Check priority threshold",
    "        if priority < prefs.min_priority:",
    "            return False",
    "        ",
    "        # Check category interest",
    "        user_categories = set(prefs.categories)",
    "        if not user_categories.intersection(set(categories)):",
    "            return False",
    "        ",
    "        # Check quiet hours (handle overnight range)",
    "        current_hour = datetime.now().hour",
    "        start = prefs.quiet_hours_start",
    "        end = prefs.quiet_hours_end",
    "        ",
    "        if start <= end:",
    "            # Same day range (e.g., 8 to 22)",
    "            in_quiet = start <= current_hour < end",
    "        else:",
    "            # Overnight range (e.g., 22 to 8)",
    "            in_quiet = current_hour >= start or current_hour < end",
    "        ",
    "        if in_quiet:",
    "            return False",
    "        ",
    "        # Check rate limit",
    "        if not self.rate_limiter.can_send(user_id, prefs.max_daily):",
    "            return False",
    "        ",
    "        return True",
    "    ",
    "    def _create_notification(",
    "        self, user_id: str, article_id: str,",
    "        title: str, publisher_id: str, priority: int",
    "    ) -> None:",
    "        \"\"\"Create and store a notification for a user.\"\"\"",
    "        notification = Notification(",
    "            notification_id=f\"notif_{uuid.uuid4().hex[:8]}\",",
    "            article_id=article_id,",
    "            title=title,",
    "            publisher_id=publisher_id,",
    "            priority=priority,",
    "            timestamp=datetime.now(),",
    "            delivered=True",
    "        )",
    "        ",
    "        with self._lock:",
    "            self.user_notifications[user_id].append(notification)",
    "        ",
    "        # Record for rate limiting",
    "        self.rate_limiter.record_send(user_id)",
    "        ",
    "        # Update delivery stats",
    "        self.delivery_stats[notification.notification_id] = {",
    "            \"user_id\": user_id,",
    "            \"delivered_at\": datetime.now().isoformat(),",
    "            \"read_at\": None",
    "        }",
    "    ",
    "    def get_pending_notifications(self, user_id: str) -> List[Notification]:",
    "        \"\"\"",
    "        Get all pending (unread) notifications for a user.",
    "        ",
    "        Returns:",
    "            List of unread notifications, sorted by priority (highest first)",
    "        ",
    "        Time Complexity: O(n log n) where n = pending notifications",
    "        \"\"\"",
    "        if user_id not in self.user_notifications:",
    "            return []",
    "        ",
    "        pending = [",
    "            n for n in self.user_notifications[user_id]",
    "            if not n.read",
    "        ]",
    "        ",
    "        # Sort by priority (descending), then timestamp (descending)",
    "        pending.sort(key=lambda n: (-n.priority, -n.timestamp.timestamp()))",
    "        ",
    "        return pending",
    "    ",
    "    def mark_notification_read(",
    "        self, user_id: str, notification_id: str",
    "    ) -> bool:",
    "        \"\"\"",
    "        Mark a notification as read.",
    "        ",
    "        Returns:",
    "            True if notification was found and marked read",
    "        \"\"\"",
    "        if user_id not in self.user_notifications:",
    "            return False",
    "        ",
    "        for notification in self.user_notifications[user_id]:",
    "            if notification.notification_id == notification_id:",
    "                notification.read = True",
    "                if notification_id in self.delivery_stats:",
    "                    self.delivery_stats[notification_id][\"read_at\"] = (",
    "                        datetime.now().isoformat()",
    "                    )",
    "                return True",
    "        ",
    "        return False",
    "    ",
    "    def get_notification_count(self, user_id: str) -> int:",
    "        \"\"\"Get count of unread notifications.\"\"\"",
    "        return len([",
    "            n for n in self.user_notifications.get(user_id, [])",
    "            if not n.read",
    "        ])",
    "    ",
    "    def get_notification_summary(self, user_id: str) -> dict:",
    "        \"\"\"Get a summary of user's notification status.\"\"\"",
    "        notifications = self.user_notifications.get(user_id, [])",
    "        unread = [n for n in notifications if not n.read]",
    "        ",
    "        max_daily = 0",
    "        if user_id in self.users:",
    "            max_daily = self.users[user_id].notification_prefs.max_daily",
    "        ",
    "        return {",
    "            \"total\": len(notifications),",
    "            \"unread\": len(unread),",
    "            \"sent_today\": self.rate_limiter.get_count(user_id),",
    "            \"daily_limit\": max_daily",
    "        }",
    "",
    "",
    "def main():",
    "    \"\"\"Demonstration of the News Aggregator with Real-Time Notifications.\"\"\"",
    "    ",
    "    print(\"=\" * 70)",
    "    print(\"NEWS AGGREGATOR SYSTEM - PART 2: REAL-TIME NOTIFICATIONS\")",
    "    print(\"=\" * 70)",
    "    ",
    "    # Initialize system",
    "    aggregator = NewsAggregator()",
    "    ",
    "    # Setup: Register users with interests",
    "    print(\"\\n[SETUP] Registering users and setting preferences...\")",
    "    ",
    "    aggregator.register_user(\"user_1\", interests=[\"Technology\", \"Breaking\"])",
    "    aggregator.register_user(\"user_2\", interests=[\"Politics\", \"Breaking\"])",
    "    aggregator.register_user(\"user_3\", interests=[\"Sports\"])",
    "    ",
    "    # Set notification preferences",
    "    prefs_1 = NotificationPrefs(",
    "        max_daily=5,",
    "        categories=[\"Breaking\", \"Technology\"],",
    "        quiet_hours_start=22,",
    "        quiet_hours_end=8,",
    "        enabled=True,",
    "        min_priority=5",
    "    )",
    "    aggregator.set_notification_preferences(\"user_1\", prefs_1)",
    "    ",
    "    prefs_2 = NotificationPrefs(",
    "        max_daily=10,",
    "        categories=[\"Breaking\", \"Politics\"],",
    "        enabled=True,",
    "        min_priority=8",
    "    )",
    "    aggregator.set_notification_preferences(\"user_2\", prefs_2)",
    "    ",
    "    # Disable notifications for user_3",
    "    prefs_3 = NotificationPrefs(enabled=False)",
    "    aggregator.set_notification_preferences(\"user_3\", prefs_3)",
    "    ",
    "    # Users follow publishers",
    "    aggregator.follow_publisher(\"user_1\", \"pub_nyt\")",
    "    aggregator.follow_publisher(\"user_1\", \"pub_techcrunch\")",
    "    aggregator.follow_publisher(\"user_2\", \"pub_nyt\")",
    "    aggregator.follow_publisher(\"user_3\", \"pub_espn\")",
    "    ",
    "    print(\"  - user_1: Follows NYT, TechCrunch | Categories: Breaking, Tech\")",
    "    print(\"  - user_2: Follows NYT | Categories: Breaking, Politics\")",
    "    print(\"  - user_3: Follows ESPN | Notifications DISABLED\")",
    "    ",
    "    # Test 1: Publish breaking news",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"[TEST 1] Publishing Breaking News (Priority 10)\")",
    "    print(\"=\" * 70)",
    "    ",
    "    breaking_article = Article(",
    "        article_id=\"article_123\",",
    "        title=\"Major Event: Breaking News Alert!\",",
    "        content=\"This is a major breaking news story...\",",
    "        publisher_id=\"pub_nyt\",",
    "        categories=[\"Breaking\", \"Politics\"]",
    "    )",
    "    ",
    "    aggregator.publish_breaking_news(\"pub_nyt\", breaking_article, priority=10)",
    "    ",
    "    print(\"\\n  Breaking news published: 'Major Event: Breaking News Alert!'\")",
    "    print(\"  Publisher: NYT | Categories: Breaking, Politics | Priority: 10\")",
    "    ",
    "    # Check notifications",
    "    print(\"\\n  Checking notifications:\")",
    "    for user_id in [\"user_1\", \"user_2\", \"user_3\"]:",
    "        pending = aggregator.get_pending_notifications(user_id)",
    "        if pending:",
    "            print(f\"    {user_id}: {len(pending)} notification(s)\")",
    "            for n in pending:",
    "                print(f\"      - {n.title} (priority: {n.priority})\")",
    "        else:",
    "            print(f\"    {user_id}: No notifications (filtered out)\")",
    "    ",
    "    # Test 2: Lower priority article (should not notify)",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"[TEST 2] Publishing Lower Priority Article (Priority 5)\")",
    "    print(\"=\" * 70)",
    "    ",
    "    regular_article = Article(",
    "        article_id=\"article_456\",",
    "        title=\"Tech Company Releases New Product\",",
    "        content=\"A tech company announced...\",",
    "        publisher_id=\"pub_techcrunch\",",
    "        categories=[\"Technology\"]",
    "    )",
    "    ",
    "    aggregator.publish_breaking_news(",
    "        \"pub_techcrunch\", regular_article, priority=5",
    "    )",
    "    ",
    "    print(\"\\n  Article published: 'Tech Company Releases New Product'\")",
    "    print(\"  Publisher: TechCrunch | Categories: Technology | Priority: 5\")",
    "    print(\"  Note: This won't trigger notifications (priority < 8)\")",
    "    ",
    "    # Verify no new notifications for user_1",
    "    pending = aggregator.get_pending_notifications(\"user_1\")",
    "    print(f\"\\n  user_1 still has {len(pending)} notification(s) (unchanged)\")",
    "    ",
    "    # Test 3: Mark notification as read",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"[TEST 3] Marking Notification as Read\")",
    "    print(\"=\" * 70)",
    "    ",
    "    pending = aggregator.get_pending_notifications(\"user_1\")",
    "    if pending:",
    "        notif_id = pending[0].notification_id",
    "        print(f\"\\n  Before: {len(pending)} pending notification(s)\")",
    "        ",
    "        aggregator.mark_notification_read(\"user_1\", notif_id)",
    "        ",
    "        pending_after = aggregator.get_pending_notifications(\"user_1\")",
    "        print(f\"  After marking read: {len(pending_after)} pending\")",
    "    ",
    "    # Test 4: Notification summary",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"[TEST 4] Notification Summary\")",
    "    print(\"=\" * 70)",
    "    ",
    "    for user_id in [\"user_1\", \"user_2\"]:",
    "        summary = aggregator.get_notification_summary(user_id)",
    "        print(f\"\\n  {user_id}:\")",
    "        print(f\"    Total: {summary['total']}, Unread: {summary['unread']}\")",
    "        print(f\"    Sent today: {summary['sent_today']}/{summary['daily_limit']}\")",
    "    ",
    "    # Test 5: Rate limiting",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"[TEST 5] Rate Limiting Test\")",
    "    print(\"=\" * 70)",
    "    ",
    "    # Set strict rate limit for test user",
    "    strict_prefs = NotificationPrefs(",
    "        max_daily=2, categories=[\"Breaking\"], enabled=True, min_priority=1",
    "    )",
    "    aggregator.register_user(\"user_test\")",
    "    aggregator.set_notification_preferences(\"user_test\", strict_prefs)",
    "    aggregator.follow_publisher(\"user_test\", \"pub_nyt\")",
    "    ",
    "    print(\"\\n  User 'user_test' has daily limit of 2 notifications\")",
    "    print(\"  Publishing 4 breaking news articles...\")",
    "    ",
    "    for i in range(4):",
    "        test_article = Article(",
    "            article_id=f\"rate_test_{i}\",",
    "            title=f\"Breaking News #{i+1}\",",
    "            content=\"Content...\",",
    "            publisher_id=\"pub_nyt\",",
    "            categories=[\"Breaking\"]",
    "        )",
    "        aggregator.publish_breaking_news(\"pub_nyt\", test_article, priority=10)",
    "    ",
    "    pending = aggregator.get_pending_notifications(\"user_test\")",
    "    print(f\"\\n  Result: {len(pending)} notifications received\")",
    "    print(\"  (Limited to 2 due to rate limiting)\")",
    "    ",
    "    print(\"\\n\" + \"=\" * 70)",
    "    print(\"DEMONSTRATION COMPLETE\")",
    "    print(\"=\" * 70)",
    "",
    "",
    "if __name__ == \"__main__\":",
    "    main()"
  ],
  "solution_java_lines": [
    "import java.time.*;",
    "import java.util.*;",
    "import java.util.concurrent.*;",
    "import java.util.concurrent.locks.*;",
    "import java.util.stream.*;",
    "",
    "/**",
    " * News Feed Aggregator System with Real-Time Notifications.",
    " * Part 2: Breaking news alerts, personalized filtering, rate limiting.",
    " */",
    "public class NewsAggregator {",
    "    ",
    "    private static final int BREAKING_NEWS_THRESHOLD = 8;",
    "    ",
    "    // Part 1 data structures",
    "    private final Map<String, User> users = new ConcurrentHashMap<>();",
    "    private final Map<String, Article> articles = new ConcurrentHashMap<>();",
    "    private final Map<String, List<String>> publisherArticles = new ConcurrentHashMap<>();",
    "    private final Map<String, Set<String>> publisherFollowers = new ConcurrentHashMap<>();",
    "    ",
    "    // Part 2: Inverted index for fast audience lookup",
    "    private final Map<String, Set<String>> categoryUsers = new ConcurrentHashMap<>();",
    "    ",
    "    // User notifications storage",
    "    private final Map<String, List<Notification>> userNotifications = new ConcurrentHashMap<>();",
    "    ",
    "    // Rate limiter",
    "    private final RateLimiter rateLimiter = new RateLimiter();",
    "    ",
    "    // Message queue for async processing",
    "    private final BlockingQueue<Map<String, Object>> notificationQueue = ",
    "        new LinkedBlockingQueue<>();",
    "    ",
    "    // Delivery statistics",
    "    private final Map<String, Map<String, Object>> deliveryStats = new ConcurrentHashMap<>();",
    "    ",
    "    private final Lock lock = new ReentrantLock();",
    "    ",
    "    // ==================== Data Classes ====================",
    "    ",
    "    public static class Article {",
    "        public String articleId;",
    "        public String title;",
    "        public String content;",
    "        public String publisherId;",
    "        public List<String> categories;",
    "        public Instant timestamp;",
    "        ",
    "        public Article(String articleId, String title, String content,",
    "                      String publisherId, List<String> categories) {",
    "            this.articleId = articleId;",
    "            this.title = title;",
    "            this.content = content;",
    "            this.publisherId = publisherId;",
    "            this.categories = categories;",
    "            this.timestamp = Instant.now();",
    "        }",
    "    }",
    "    ",
    "    public static class NotificationPrefs {",
    "        public int maxDaily = 5;",
    "        public List<String> categories = new ArrayList<>(List.of(\"Breaking\"));",
    "        public int quietHoursStart = 22;",
    "        public int quietHoursEnd = 8;",
    "        public boolean enabled = true;",
    "        public int minPriority = 5;",
    "        ",
    "        public NotificationPrefs() {}",
    "        ",
    "        public NotificationPrefs(int maxDaily, List<String> categories,",
    "                                boolean enabled, int minPriority) {",
    "            this.maxDaily = maxDaily;",
    "            this.categories = new ArrayList<>(categories);",
    "            this.enabled = enabled;",
    "            this.minPriority = minPriority;",
    "        }",
    "    }",
    "    ",
    "    public static class Notification {",
    "        public String notificationId;",
    "        public String articleId;",
    "        public String title;",
    "        public String publisherId;",
    "        public int priority;",
    "        public Instant timestamp;",
    "        public boolean read = false;",
    "        ",
    "        public Notification(String notificationId, String articleId,",
    "                           String title, String publisherId, int priority) {",
    "            this.notificationId = notificationId;",
    "            this.articleId = articleId;",
    "            this.title = title;",
    "            this.publisherId = publisherId;",
    "            this.priority = priority;",
    "            this.timestamp = Instant.now();",
    "        }",
    "    }",
    "    ",
    "    public static class User {",
    "        public String userId;",
    "        public List<String> interests = new ArrayList<>();",
    "        public Set<String> following = new HashSet<>();",
    "        public NotificationPrefs notificationPrefs = new NotificationPrefs();",
    "        ",
    "        public User(String userId) {",
    "            this.userId = userId;",
    "        }",
    "    }",
    "    ",
    "    // ==================== Rate Limiter ====================",
    "    ",
    "    public static class RateLimiter {",
    "        private final int windowSeconds = 86400; // 24 hours",
    "        private final Map<String, List<Long>> userTimestamps = new ConcurrentHashMap<>();",
    "        private final Lock lock = new ReentrantLock();",
    "        ",
    "        public boolean canSend(String userId, int maxCount) {",
    "            lock.lock();",
    "            try {",
    "                long currentTime = System.currentTimeMillis();",
    "                long cutoff = currentTime - (windowSeconds * 1000L);",
    "                ",
    "                List<Long> timestamps = userTimestamps.computeIfAbsent(",
    "                    userId, k -> new ArrayList<>());",
    "                timestamps.removeIf(ts -> ts < cutoff);",
    "                ",
    "                return timestamps.size() < maxCount;",
    "            } finally {",
    "                lock.unlock();",
    "            }",
    "        }",
    "        ",
    "        public void recordSend(String userId) {",
    "            lock.lock();",
    "            try {",
    "                userTimestamps.computeIfAbsent(userId, k -> new ArrayList<>())",
    "                    .add(System.currentTimeMillis());",
    "            } finally {",
    "                lock.unlock();",
    "            }",
    "        }",
    "        ",
    "        public int getCount(String userId) {",
    "            lock.lock();",
    "            try {",
    "                long currentTime = System.currentTimeMillis();",
    "                long cutoff = currentTime - (windowSeconds * 1000L);",
    "                ",
    "                List<Long> timestamps = userTimestamps.get(userId);",
    "                if (timestamps == null) return 0;",
    "                ",
    "                timestamps.removeIf(ts -> ts < cutoff);",
    "                return timestamps.size();",
    "            } finally {",
    "                lock.unlock();",
    "            }",
    "        }",
    "    }",
    "    ",
    "    // ==================== Part 1 Methods ====================",
    "    ",
    "    public void registerUser(String userId, List<String> interests) {",
    "        if (users.containsKey(userId)) return;",
    "        ",
    "        User user = new User(userId);",
    "        if (interests != null) {",
    "            user.interests = new ArrayList<>(interests);",
    "            for (String category : interests) {",
    "                categoryUsers.computeIfAbsent(category, k -> ",
    "                    ConcurrentHashMap.newKeySet()).add(userId);",
    "            }",
    "        }",
    "        users.put(userId, user);",
    "    }",
    "    ",
    "    public void followPublisher(String userId, String publisherId) {",
    "        if (!users.containsKey(userId)) {",
    "            registerUser(userId, null);",
    "        }",
    "        users.get(userId).following.add(publisherId);",
    "        publisherFollowers.computeIfAbsent(publisherId, k -> ",
    "            ConcurrentHashMap.newKeySet()).add(userId);",
    "    }",
    "    ",
    "    public String publishArticle(String publisherId, Article article) {",
    "        String articleId = article.articleId != null ? article.articleId :",
    "            \"article_\" + UUID.randomUUID().toString().substring(0, 8);",
    "        article.articleId = articleId;",
    "        article.publisherId = publisherId;",
    "        ",
    "        articles.put(articleId, article);",
    "        publisherArticles.computeIfAbsent(publisherId, k -> ",
    "            new CopyOnWriteArrayList<>()).add(articleId);",
    "        ",
    "        return articleId;",
    "    }",
    "    ",
    "    // ==================== Part 2 Methods ====================",
    "    ",
    "    public void setNotificationPreferences(String userId, NotificationPrefs prefs) {",
    "        if (!users.containsKey(userId)) {",
    "            registerUser(userId, null);",
    "        }",
    "        ",
    "        User user = users.get(userId);",
    "        NotificationPrefs oldPrefs = user.notificationPrefs;",
    "        user.notificationPrefs = prefs;",
    "        ",
    "        // Update category index",
    "        Set<String> oldCategories = new HashSet<>(oldPrefs.categories);",
    "        Set<String> newCategories = new HashSet<>(prefs.categories);",
    "        ",
    "        for (String cat : oldCategories) {",
    "            if (!newCategories.contains(cat)) {",
    "                Set<String> catUsers = categoryUsers.get(cat);",
    "                if (catUsers != null) catUsers.remove(userId);",
    "            }",
    "        }",
    "        ",
    "        for (String cat : newCategories) {",
    "            if (!oldCategories.contains(cat)) {",
    "                categoryUsers.computeIfAbsent(cat, k -> ",
    "                    ConcurrentHashMap.newKeySet()).add(userId);",
    "            }",
    "        }",
    "    }",
    "    ",
    "    public void publishBreakingNews(String publisherId, Article article, int priority) {",
    "        String articleId = publishArticle(publisherId, article);",
    "        ",
    "        if (priority >= BREAKING_NEWS_THRESHOLD) {",
    "            Map<String, Object> job = new HashMap<>();",
    "            job.put(\"type\", \"breaking_news\");",
    "            job.put(\"articleId\", articleId);",
    "            job.put(\"publisherId\", publisherId);",
    "            job.put(\"title\", article.title);",
    "            job.put(\"categories\", article.categories);",
    "            job.put(\"priority\", priority);",
    "            ",
    "            notificationQueue.offer(job);",
    "            processNotificationQueue();",
    "        }",
    "    }",
    "    ",
    "    private void processNotificationQueue() {",
    "        Map<String, Object> job;",
    "        while ((job = notificationQueue.poll()) != null) {",
    "            if (\"breaking_news\".equals(job.get(\"type\"))) {",
    "                processBreakingNewsNotification(job);",
    "            }",
    "        }",
    "    }",
    "    ",
    "    @SuppressWarnings(\"unchecked\")",
    "    private void processBreakingNewsNotification(Map<String, Object> job) {",
    "        String articleId = (String) job.get(\"articleId\");",
    "        String publisherId = (String) job.get(\"publisherId\");",
    "        List<String> categories = (List<String>) job.get(\"categories\");",
    "        int priority = (Integer) job.get(\"priority\");",
    "        String title = (String) job.get(\"title\");",
    "        ",
    "        // Find target audience",
    "        Set<String> targetUsers = new HashSet<>();",
    "        ",
    "        Set<String> followers = publisherFollowers.get(publisherId);",
    "        if (followers != null) targetUsers.addAll(followers);",
    "        ",
    "        for (String category : categories) {",
    "            Set<String> catUsers = categoryUsers.get(category);",
    "            if (catUsers != null) targetUsers.addAll(catUsers);",
    "        }",
    "        ",
    "        // Filter and create notifications",
    "        for (String userId : targetUsers) {",
    "            if (shouldNotifyUser(userId, categories, priority)) {",
    "                createNotification(userId, articleId, title, publisherId, priority);",
    "            }",
    "        }",
    "    }",
    "    ",
    "    private boolean shouldNotifyUser(String userId, List<String> categories, int priority) {",
    "        User user = users.get(userId);",
    "        if (user == null) return false;",
    "        ",
    "        NotificationPrefs prefs = user.notificationPrefs;",
    "        ",
    "        if (!prefs.enabled) return false;",
    "        if (priority < prefs.minPriority) return false;",
    "        ",
    "        Set<String> userCategories = new HashSet<>(prefs.categories);",
    "        boolean hasMatch = categories.stream().anyMatch(userCategories::contains);",
    "        if (!hasMatch) return false;",
    "        ",
    "        int currentHour = LocalTime.now().getHour();",
    "        int start = prefs.quietHoursStart;",
    "        int end = prefs.quietHoursEnd;",
    "        ",
    "        boolean inQuiet;",
    "        if (start <= end) {",
    "            inQuiet = currentHour >= start && currentHour < end;",
    "        } else {",
    "            inQuiet = currentHour >= start || currentHour < end;",
    "        }",
    "        if (inQuiet) return false;",
    "        ",
    "        return rateLimiter.canSend(userId, prefs.maxDaily);",
    "    }",
    "    ",
    "    private void createNotification(String userId, String articleId,",
    "                                   String title, String publisherId, int priority) {",
    "        Notification notification = new Notification(",
    "            \"notif_\" + UUID.randomUUID().toString().substring(0, 8),",
    "            articleId, title, publisherId, priority",
    "        );",
    "        ",
    "        lock.lock();",
    "        try {",
    "            userNotifications.computeIfAbsent(userId, k -> ",
    "                new CopyOnWriteArrayList<>()).add(notification);",
    "        } finally {",
    "            lock.unlock();",
    "        }",
    "        ",
    "        rateLimiter.recordSend(userId);",
    "        ",
    "        Map<String, Object> stats = new HashMap<>();",
    "        stats.put(\"userId\", userId);",
    "        stats.put(\"deliveredAt\", Instant.now().toString());",
    "        deliveryStats.put(notification.notificationId, stats);",
    "    }",
    "    ",
    "    public List<Notification> getPendingNotifications(String userId) {",
    "        List<Notification> notifications = userNotifications.get(userId);",
    "        if (notifications == null) return new ArrayList<>();",
    "        ",
    "        return notifications.stream()",
    "            .filter(n -> !n.read)",
    "            .sorted((a, b) -> {",
    "                if (a.priority != b.priority) return b.priority - a.priority;",
    "                return b.timestamp.compareTo(a.timestamp);",
    "            })",
    "            .collect(Collectors.toList());",
    "    }",
    "    ",
    "    public boolean markNotificationRead(String userId, String notificationId) {",
    "        List<Notification> notifications = userNotifications.get(userId);",
    "        if (notifications == null) return false;",
    "        ",
    "        for (Notification n : notifications) {",
    "            if (n.notificationId.equals(notificationId)) {",
    "                n.read = true;",
    "                Map<String, Object> stats = deliveryStats.get(notificationId);",
    "                if (stats != null) {",
    "                    stats.put(\"readAt\", Instant.now().toString());",
    "                }",
    "                return true;",
    "            }",
    "        }",
    "        return false;",
    "    }",
    "    ",
    "    public int getNotificationCount(String userId) {",
    "        List<Notification> notifications = userNotifications.get(userId);",
    "        if (notifications == null) return 0;",
    "        return (int) notifications.stream().filter(n -> !n.read).count();",
    "    }",
    "    ",
    "    // ==================== Demo ====================",
    "    ",
    "    public static void main(String[] args) {",
    "        System.out.println(\"=\".repeat(70));",
    "        System.out.println(\"NEWS AGGREGATOR - PART 2: REAL-TIME NOTIFICATIONS\");",
    "        System.out.println(\"=\".repeat(70));",
    "        ",
    "        NewsAggregator aggregator = new NewsAggregator();",
    "        ",
    "        // Setup users",
    "        aggregator.registerUser(\"user_1\", List.of(\"Technology\", \"Breaking\"));",
    "        aggregator.registerUser(\"user_2\", List.of(\"Politics\", \"Breaking\"));",
    "        ",
    "        aggregator.setNotificationPreferences(\"user_1\",",
    "            new NotificationPrefs(5, List.of(\"Breaking\", \"Technology\"), true, 5));",
    "        aggregator.setNotificationPreferences(\"user_2\",",
    "            new NotificationPrefs(10, List.of(\"Breaking\", \"Politics\"), true, 8));",
    "        ",
    "        aggregator.followPublisher(\"user_1\", \"pub_nyt\");",
    "        aggregator.followPublisher(\"user_2\", \"pub_nyt\");",
    "        ",
    "        System.out.println(\"\\nUsers registered and configured.\");",
    "        ",
    "        // Publish breaking news",
    "        System.out.println(\"\\nPublishing breaking news...\");",
    "        Article breaking = new Article(\"article_123\",",
    "            \"Major Event: Breaking News!\",",
    "            \"Content...\", \"pub_nyt\",",
    "            List.of(\"Breaking\", \"Politics\"));",
    "        ",
    "        aggregator.publishBreakingNews(\"pub_nyt\", breaking, 10);",
    "        ",
    "        // Check notifications",
    "        System.out.println(\"\\nNotifications:\");",
    "        for (String userId : List.of(\"user_1\", \"user_2\")) {",
    "            List<Notification> pending = aggregator.getPendingNotifications(userId);",
    "            System.out.printf(\"  %s: %d notification(s)%n\", userId, pending.size());",
    "            for (Notification n : pending) {",
    "                System.out.printf(\"    - %s (priority: %d)%n\", n.title, n.priority);",
    "            }",
    "        }",
    "        ",
    "        System.out.println(\"\\n\" + \"=\".repeat(70));",
    "        System.out.println(\"DEMO COMPLETE\");",
    "    }",
    "}"
  ],
  "code_walkthrough": [
    {
      "lines": "1-10",
      "explanation": "Imports for dataclasses, typing, datetime, collections, threading"
    },
    {
      "lines": "13-18",
      "explanation": "NotificationPriority enum defining priority levels (LOW=1 to BREAKING=10)"
    },
    {
      "lines": "21-30",
      "explanation": "Article dataclass - same as Part 1 but now used for notifications too"
    },
    {
      "lines": "33-42",
      "explanation": "NotificationPrefs dataclass - NEW in Part 2. Stores max_daily, categories, quiet_hours, enabled flag, min_priority"
    },
    {
      "lines": "45-55",
      "explanation": "Notification dataclass - NEW in Part 2. Stores notification_id, article_id, title, publisher_id, priority, timestamp, read status"
    },
    {
      "lines": "58-63",
      "explanation": "User dataclass - Extended with notification_prefs field"
    },
    {
      "lines": "66-95",
      "explanation": "RateLimiter class - Sliding window rate limiter using timestamp lists. can_send() checks if under limit, record_send() adds timestamp, get_count() returns current count"
    },
    {
      "lines": "98-111",
      "explanation": "MessageQueue class - Simple in-memory FIFO queue for notification jobs. Production would use Kafka/SQS"
    },
    {
      "lines": "114-145",
      "explanation": "NewsAggregator __init__ - Initializes Part 1 structures plus NEW Part 2 structures: category_users inverted index, user_notifications, rate_limiter, notification_queue, delivery_stats"
    },
    {
      "lines": "149-180",
      "explanation": "Part 1 methods (register_user, follow_publisher, publish_article, get_feed) - Mostly unchanged, but register_user now updates category_users index"
    },
    {
      "lines": "184-215",
      "explanation": "set_notification_preferences - Updates user prefs and maintains category_users inverted index consistency"
    },
    {
      "lines": "217-245",
      "explanation": "publish_breaking_news - Main entry point. Stores article, checks priority threshold, enqueues notification job if breaking news"
    },
    {
      "lines": "247-275",
      "explanation": "_process_breaking_news_notification - Finds target audience via inverted index, filters users, creates notifications"
    },
    {
      "lines": "277-315",
      "explanation": "_should_notify_user - Filter pipeline: enabled check, priority check, category check, quiet hours check, rate limit check"
    },
    {
      "lines": "317-340",
      "explanation": "_create_notification - Creates Notification object, stores in user_notifications, records send for rate limiting, updates delivery stats"
    },
    {
      "lines": "342-360",
      "explanation": "get_pending_notifications - Returns unread notifications sorted by priority (desc) then timestamp"
    },
    {
      "lines": "362-380",
      "explanation": "mark_notification_read - Marks notification as read, updates delivery stats with read timestamp"
    },
    {
      "lines": "382-410",
      "explanation": "Helper methods: get_notification_count, get_notification_summary"
    },
    {
      "lines": "413-500",
      "explanation": "main() - Comprehensive demo showing: user setup, preference configuration, breaking news publishing, notification checking, rate limiting test"
    }
  ],
  "complexity_analysis": {
    "time": {
      "new_methods": {
        "publishBreakingNews": {
          "complexity": "O(1) + O(A)",
          "explanation": "O(1) to enqueue, O(A) to process where A = audience size"
        },
        "setNotificationPreferences": {
          "complexity": "O(C)",
          "explanation": "O(C) where C = number of categories to update in inverted index"
        },
        "getPendingNotifications": {
          "complexity": "O(n log n)",
          "explanation": "Filter O(n) + sort O(n log n) where n = user's notifications"
        },
        "markNotificationRead": {
          "complexity": "O(n)",
          "explanation": "Linear scan through user's notifications"
        },
        "_should_notify_user": {
          "complexity": "O(C)",
          "explanation": "O(C) for category intersection where C = article categories"
        }
      },
      "overall_change": "Part 2 adds near-constant overhead for notification processing. The inverted index lookup is O(1) per category, making audience finding extremely efficient compared to O(U) full user scan."
    },
    "space": {
      "additional_space": "O(U\u00d7C + U\u00d7N) where U=users, C=avg categories per user, N=avg notifications per user",
      "explanation": "category_users inverted index is O(U\u00d7C). user_notifications is O(U\u00d7N). RateLimiter is O(U\u00d7D) where D=max daily notifications."
    }
  },
  "dry_run": {
    "example_input": "User follows pub_nyt, has Breaking category enabled. Breaking news published with categories=[Breaking, Politics], priority=10.",
    "steps": [
      {
        "step": 1,
        "action": "publishBreakingNews called",
        "state": "article stored, priority=10 >= 8",
        "explanation": "Article stored in articles dict. Priority meets threshold."
      },
      {
        "step": 2,
        "action": "Notification job enqueued",
        "state": "queue has 1 job",
        "explanation": "Job contains article_id, publisher_id, title, categories, priority"
      },
      {
        "step": 3,
        "action": "_process_notification_queue",
        "state": "dequeue job",
        "explanation": "Worker picks up job for processing"
      },
      {
        "step": 4,
        "action": "Find target audience",
        "state": "target_users = {user_1}",
        "explanation": "publisher_followers[pub_nyt] = {user_1}, category_users[Breaking] includes user_1"
      },
      {
        "step": 5,
        "action": "_should_notify_user(user_1)",
        "state": "checking filters",
        "explanation": "enabled=True, priority=10>=5, Breaking in user categories, not in quiet hours, rate limit ok"
      },
      {
        "step": 6,
        "action": "_create_notification",
        "state": "notification created",
        "explanation": "Notification stored in user_notifications[user_1], rate_limiter updated"
      },
      {
        "step": 7,
        "action": "getPendingNotifications(user_1)",
        "state": "[Notification(title='Major Event!')]",
        "explanation": "Returns list with 1 notification, priority=10"
      }
    ],
    "final_output": "[{articleId: 'article_123', title: 'Major Event!', priority: 10}]"
  },
  "debugging_playbook": {
    "fast_sanity_checks": [
      "Publish breaking news with priority=10, verify user following publisher gets notification",
      "Set enabled=False, verify no notification received",
      "Set max_daily=0, verify rate limiting blocks all notifications"
    ],
    "likely_bugs": [
      "Quiet hours logic inverted (notifying during quiet hours)",
      "Category intersection using wrong set (user.interests vs prefs.categories)",
      "Rate limiter not recording sends after creating notification",
      "Inverted index not updated when preferences change"
    ],
    "recommended_logs_or_asserts": [
      "assert len(target_users) > 0 after audience lookup",
      "log f'User {user_id} filtered: enabled={prefs.enabled}, priority_ok={priority >= prefs.min_priority}'",
      "assert all(user_id in self.users for user_id in target_users)"
    ],
    "how_to_localize": "1. Add logging to _should_notify_user to see which filter fails. 2. Check category_users index contains expected users. 3. Verify rate_limiter.get_count() after each notification."
  },
  "edge_cases": [
    {
      "case": "User registered but no preferences set",
      "handling": "Uses default NotificationPrefs (max_daily=5, categories=['Breaking'])",
      "gotcha": "Don't assume prefs is None after registration"
    },
    {
      "case": "Priority exactly at threshold (8)",
      "handling": "Treated as breaking news (>= not >)",
      "gotcha": "Off-by-one: use >= BREAKING_NEWS_THRESHOLD"
    },
    {
      "case": "Quiet hours span midnight (22:00-08:00)",
      "handling": "Special case in _should_notify_user: if start > end, use OR logic",
      "gotcha": "Simple range check fails for overnight ranges"
    },
    {
      "case": "User follows publisher AND is interested in category",
      "handling": "Only notified once (Set union deduplicates)",
      "gotcha": "Without Set, user could receive duplicate notifications"
    },
    {
      "case": "Article has no categories",
      "handling": "Only publisher followers notified (category lookup returns empty)",
      "gotcha": "Empty categories list should not crash"
    },
    {
      "case": "Rate limit reached mid-batch",
      "handling": "Some users get notified, others don't",
      "gotcha": "Rate limit is per-user, not global"
    }
  ],
  "test_cases": [
    {
      "name": "Basic notification flow",
      "input": "user_1 follows pub_nyt, prefs=[Breaking], publish breaking news priority=10",
      "expected": "user_1 has 1 pending notification",
      "explanation": "Standard happy path - user should receive notification"
    },
    {
      "name": "Priority threshold",
      "input": "publish article with priority=7 (below threshold)",
      "expected": "No notifications created",
      "explanation": "Articles below priority 8 don't trigger breaking news pipeline"
    },
    {
      "name": "Category filtering",
      "input": "user prefs=[Technology], article categories=[Sports]",
      "expected": "User not notified",
      "explanation": "No category overlap means no notification"
    },
    {
      "name": "Rate limiting",
      "input": "max_daily=2, publish 5 breaking news articles",
      "expected": "User receives exactly 2 notifications",
      "explanation": "Rate limiter blocks after max_daily reached"
    },
    {
      "name": "Disabled notifications",
      "input": "user.prefs.enabled=False, publish breaking news",
      "expected": "User receives 0 notifications",
      "explanation": "Enabled flag is first filter check"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Scanning all users instead of using inverted index",
      "why_wrong": "O(U) for every breaking news article is unacceptable at scale. With 10M users and 58 writes/second, this means scanning 580M users/second.",
      "correct_approach": "Use inverted index: category_users[category] gives O(1) lookup of interested users",
      "code_example_wrong": "for user in all_users:\\n    if article.category in user.interests:\\n        notify(user)",
      "code_example_correct": "target_users = set()\\nfor cat in article.categories:\\n    target_users |= category_users[cat]\\nfor user in target_users:\\n    notify(user)"
    },
    {
      "mistake": "Not updating inverted index when preferences change",
      "why_wrong": "Stale index leads to users receiving notifications for categories they unsubscribed from, or missing notifications for newly subscribed categories.",
      "correct_approach": "In set_notification_preferences, compute diff of old/new categories and update index",
      "code_example_wrong": "def set_prefs(user_id, prefs):\\n    self.users[user_id].prefs = prefs  # Index not updated!",
      "code_example_correct": "def set_prefs(user_id, prefs):\\n    old = self.users[user_id].prefs.categories\\n    new = prefs.categories\\n    for cat in set(old) - set(new):\\n        self.category_users[cat].discard(user_id)\\n    for cat in set(new) - set(old):\\n        self.category_users[cat].add(user_id)"
    },
    {
      "mistake": "Blocking on push gateway in publishBreakingNews",
      "why_wrong": "Push gateways (FCM/APNS) can be slow or fail. Blocking makes the system unresponsive.",
      "correct_approach": "Enqueue notification job immediately, return to caller, process async",
      "code_example_wrong": "def publish_breaking_news(...):\\n    for user in audience:\\n        push_gateway.send(user, notification)  # Blocks!",
      "code_example_correct": "def publish_breaking_news(...):\\n    self.queue.enqueue(job)  # O(1)\\n    return  # Non-blocking\\n# Separate worker processes queue"
    },
    {
      "mistake": "Quiet hours logic using simple range check",
      "why_wrong": "Range check like 'start <= hour < end' fails for overnight ranges like 22:00-08:00.",
      "correct_approach": "Check if start > end and use OR logic for overnight ranges",
      "code_example_wrong": "in_quiet = prefs.quiet_start <= current_hour < prefs.quiet_end",
      "code_example_correct": "if start <= end:\\n    in_quiet = start <= hour < end\\nelse:\\n    in_quiet = hour >= start or hour < end"
    }
  ],
  "interview_tips": {
    "how_to_present": "Start by acknowledging the 30-second SLA is the key challenge. Immediately mention the inverted index optimization. Draw the notification flow diagram. Then walk through the filter pipeline.",
    "what_to_mention": [
      "Inverted index for O(1) audience lookup vs O(n) user scan",
      "Message queue for async processing (Kafka in production)",
      "Rate limiting with sliding window (Redis sorted sets in production)",
      "Circuit breaker for push gateway resilience",
      "Delivery tracking for analytics and debugging"
    ],
    "time_allocation": "2 min understanding requirements, 3 min explaining approach with diagram, 5 min implementing core methods, 2 min testing/edge cases",
    "if_stuck": [
      "Hint: 'How would you quickly find all users interested in Technology?'",
      "Hint: 'What if the push gateway is slow? Should we wait?'",
      "Hint: 'How do you prevent sending 100 notifications to one user per day?'"
    ]
  },
  "connection_to_next_part": "Part 2 establishes the notification infrastructure. Part 3 might add: (1) Notification batching/digest mode for less urgent news, (2) A/B testing of notification content, (3) ML-based personalization of notification timing, (4) WebSocket real-time feed updates, (5) Analytics dashboard for notification engagement.",
  "communication_script": {
    "transition_from_previous": "Great, Part 1 handles the basic feed generation. For Part 2, I need to add **real-time push notifications** for breaking news. The key challenge is the 30-second SLA - I can't scan all 10M users for every breaking news article.",
    "explaining_changes": "The key change is adding an **inverted index**: category \u2192 users. When breaking news arrives, I lookup interested users in O(1) instead of scanning everyone. I'll also add a message queue for async processing and a rate limiter to prevent spam.",
    "while_extending_code": [
      "I'm adding category_users dict to map categories to user sets...",
      "This _should_notify_user method is my filter pipeline - checks enabled, priority, categories, quiet hours, rate limit...",
      "The RateLimiter uses a sliding window - keeps timestamps and cleans old ones on each check..."
    ],
    "after_completing": "This now handles Part 2. publishBreakingNews is O(1) to enqueue plus O(audience) to process. The inverted index ensures we only process relevant users. Rate limiting prevents spam. Ready for the next part?"
  },
  "time_milestones": {
    "time_budget": "10-15 minutes for this part",
    "by_2_min": "Understand the 30-second SLA requirement, recognize inverted index is needed",
    "by_5_min": "Explain inverted index approach, draw notification flow, start coding",
    "by_10_min": "Core methods done: publishBreakingNews, _should_notify_user, get_pending_notifications",
    "by_15_min": "Rate limiting, edge cases, testing complete",
    "warning_signs": "If still designing at 5 min, simplify and start coding. If stuck on rate limiting, mention 'Redis sorted sets' and move on."
  },
  "recovery_strategies": {
    "if_part_builds_wrong": "If Part 1's follow_publisher doesn't track followers properly, fix publisher_followers dict first. Say: 'I need to ensure Part 1 tracks followers correctly before adding notifications.'",
    "if_new_requirement_unclear": "Ask: 'For the 30-second SLA, is that time to enqueue or time to deliver to device? I'll optimize for enqueue first.'",
    "if_running_behind": "Prioritize: 1) Inverted index, 2) publishBreakingNews, 3) getPendingNotifications. Skip rate limiting and mention: 'In production I'd add Redis-based rate limiting here.'"
  },
  "signal_points": {
    "wow_factors_for_followup": [
      "Immediately recognizing inverted index pattern",
      "Mentioning Kafka for production message queue",
      "Discussing circuit breaker for push gateway resilience",
      "Proactively handling the overnight quiet hours edge case",
      "Noting that rate limiting needs distributed state (Redis) in production"
    ]
  },
  "pattern_recognition": {
    "pattern": "Inverted Index + Pub-Sub + Rate Limiting",
    "indicators": [
      "'Find users interested in X' \u2192 Inverted Index",
      "'Notify in real-time' \u2192 Pub-Sub / Message Queue",
      "'Don't spam users' \u2192 Rate Limiting",
      "'Within 30 seconds' \u2192 Async processing, pre-computed indexes"
    ],
    "similar_problems": [
      "Twitter - Notify followers of new tweet",
      "Slack - Notify channel members of new message",
      "Google Alerts - Notify users when topic matches",
      "E-commerce - Notify users of price drops on watched items"
    ],
    "template": "1. Build inverted index on write (category\u2192users)\\n2. On event, lookup audience via index O(1)\\n3. Filter by user preferences\\n4. Rate limit per user\\n5. Async delivery via message queue"
  },
  "thinking_process": [
    {
      "step": 1,
      "thought": "30-second SLA means I can't scan all users",
      "why": "With 10M users, even 1ms per user = 10,000 seconds. Need O(1) lookup."
    },
    {
      "step": 2,
      "thought": "Need to pre-compute who cares about what",
      "why": "Inverted index: category \u2192 [users]. Built on preference update, queried on publish."
    },
    {
      "step": 3,
      "thought": "Publishing shouldn't block on delivery",
      "why": "Push gateways are slow/unreliable. Enqueue and return immediately."
    },
    {
      "step": 4,
      "thought": "Users hate notification spam",
      "why": "Need rate limiting (max N per day) and preference filters (categories, priority)."
    },
    {
      "step": 5,
      "thought": "Quiet hours edge case",
      "why": "22:00-08:00 spans midnight. Simple range check fails. Need special logic."
    }
  ],
  "interviewer_perspective": {
    "what_they_evaluate": [
      "Can you identify the O(n) bottleneck and fix it with inverted index?",
      "Do you understand async processing vs blocking?",
      "Can you design a filter pipeline with multiple conditions?",
      "Do you consider user experience (rate limiting, quiet hours)?"
    ],
    "bonus_points": [
      "Mentioning Kafka/SQS for production message queue",
      "Discussing Redis sorted sets for distributed rate limiting",
      "Noting circuit breaker pattern for push gateway",
      "Handling overnight quiet hours correctly",
      "Considering notification delivery tracking for analytics"
    ],
    "red_flags": [
      "Scanning all users for every breaking news article",
      "Blocking on push gateway calls",
      "Forgetting rate limiting (would spam users)",
      "Not updating inverted index when preferences change",
      "Ignoring the 30-second SLA requirement"
    ]
  },
  "ai_copilot_tips": {
    "what_to_do": [
      "Let AI generate the RateLimiter boilerplate",
      "Use AI for datetime/timezone handling",
      "Ask AI to add type hints to your methods"
    ],
    "what_not_to_do": [
      "Don't let AI decide to use O(n) user scan",
      "Verify the quiet hours logic is correct (AI often gets it wrong)",
      "Understand the inverted index update logic - it's the key insight"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Jumping to code without explaining the inverted index insight",
      "Not acknowledging the 30-second SLA challenge",
      "Ignoring the rate limiting requirement"
    ],
    "technical": [
      "Using O(n) user scan instead of inverted index",
      "Synchronous push gateway calls blocking the main thread",
      "Not maintaining index consistency on preference updates"
    ],
    "communication": [
      "Not drawing the notification flow diagram",
      "Forgetting to explain why async processing is needed",
      "Not testing with edge cases (quiet hours, rate limits)"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Is publishBreakingNews O(1) to enqueue?",
      "Does the inverted index get updated on preference changes?",
      "Does _should_notify_user check all 5 filters?",
      "Is the quiet hours logic correct for overnight ranges?",
      "Is rate limiting per-user, not global?",
      "Did I trace through the example input?"
    ],
    "quick_code_review": [
      "Type hints on all new methods",
      "Docstrings explaining time complexity",
      "Thread safety (locks) where needed",
      "No duplicate notifications (Set for target_users)"
    ]
  },
  "production_considerations": {
    "what_i_would_add": [
      "Kafka instead of in-memory Queue for durability and horizontal scaling",
      "Redis sorted sets for distributed rate limiting across servers",
      "Circuit breaker (Hystrix/Resilience4j) for push gateway",
      "Dead letter queue for failed notifications",
      "Prometheus metrics: notification_sent_total, notification_filtered_total, delivery_latency_p99"
    ],
    "why_not_in_interview": "Focus on algorithm and data structure design. Implementation details like Kafka config are separate concerns.",
    "how_to_mention": "Say: 'In production, I'd use Kafka here for durability and Redis for distributed rate limiting. For the interview, I'll simulate these with in-memory structures.'"
  },
  "generated_at": "2026-01-18T18:47:49.020902",
  "_meta": {
    "problem_id": "news_feed_aggregator",
    "part_number": 2,
    "model": "claude-opus-4-5-20251101"
  }
}