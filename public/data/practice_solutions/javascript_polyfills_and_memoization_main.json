{
  "problem_title": "JavaScript Polyfills & Memoization",
  "difficulty": "medium",
  "category": "Frontend/JavaScript",
  "estimated_time": "45-60 minutes",
  "problem_analysis": {
    "first_impressions": "This is a **closure-based caching pattern** problem. When I see 'cache results based on arguments', I immediately think of:\n1. **Higher-order functions** - returning a function that wraps another\n2. **Closures** - maintaining state (cache) between calls\n3. **Key serialization** - converting arguments to a unique cache key\n\nThis is a fundamental JavaScript pattern used everywhere: React's useMemo, Redux selectors, lodash.memoize.",
    "pattern_recognition": "**Decorator Pattern** + **HashMap/Cache** + **Closures**\n\nThis combines:\n- **HOF (Higher-Order Function)**: Takes function, returns function\n- **Cache Pattern**: Store computed results for reuse\n- **Closure Pattern**: Inner function accesses outer scope's cache\n- **Serialization Pattern**: Convert complex inputs to cache keys",
    "key_constraints": [
      "**Type differentiation** - `fn(1)` and `fn('1')` must have DIFFERENT keys. This eliminates naive `.toString()` approaches",
      "**Multiple arguments** - Must handle variadic functions: `fn()`, `fn(x)`, `fn(x,y,z)`",
      "**Primitives + objects** - Must serialize both primitives and objects correctly",
      "**O(1) cache lookup** - Need efficient key-based retrieval (HashMap/Map)",
      "**Preserve `this` context** - If original function uses `this`, memoized version must too"
    ],
    "clarifying_questions": [
      "**Q: How should object arguments be compared?** - By reference or deep equality? This determines if `fn({a:1})` called twice should hit cache. Answer: By value (JSON serialization) for this problem.",
      "**Q: Should the cache have a size limit?** - Unlimited caches can cause memory leaks. Answer: No limit for Part 1, but mention this concern.",
      "**Q: What about async functions?** - Do we need to handle Promises? Answer: Part 2 covers async; Part 1 is sync only.",
      "**Q: Should we handle circular references in objects?** - JSON.stringify throws on these. Answer: Assume no circular refs for Part 1.",
      "**Q: What about `this` binding?** - Does the original function use `this`? Answer: We should preserve it to be safe.",
      "**Q: Can the original function have side effects?** - Memoization assumes pure functions. Answer: Assume pure functions.",
      "**Q: What if the function throws?** - Should we cache errors? Answer: Don't cache errors for Part 1."
    ],
    "edge_cases_to_consider": [
      "**Empty arguments**: `fn()` - should work, key could be `'[]'`",
      "**undefined vs null**: `fn(undefined)` vs `fn(null)` - must have different keys",
      "**Type coercion traps**: `fn(1)` vs `fn('1')` vs `fn(true)` - all different",
      "**Object arguments**: `fn({a:1})` - needs proper serialization",
      "**Array arguments**: `fn([1,2,3])` vs `fn(1,2,3)` - different!",
      "**Functions as arguments**: JSON.stringify ignores functions - edge case",
      "**NaN handling**: `NaN === NaN` is false, but we want cache hit"
    ]
  },
  "requirements_coverage": {
    "checklist": [
      {
        "requirement": "Takes any function fn as input",
        "how_met": "Function parameter with generic handling via apply()",
        "gotchas": [
          "Must preserve function's `this` context"
        ]
      },
      {
        "requirement": "Returns new function that caches results",
        "how_met": "Closure returning wrapper function with cache in outer scope",
        "gotchas": [
          "Must return a function, not call the function"
        ]
      },
      {
        "requirement": "Cache key based on ALL arguments",
        "how_met": "JSON.stringify(args) captures all args as array",
        "gotchas": [
          "args.toString() loses type info - BAD"
        ]
      },
      {
        "requirement": "Handle multiple argument types",
        "how_met": "JSON.stringify preserves type info for primitives",
        "gotchas": [
          "undefined becomes null in JSON - special handling needed"
        ]
      },
      {
        "requirement": "Return cached result for same args",
        "how_met": "Map.has() check before computation",
        "gotchas": [
          "Must check BEFORE calling fn, not after"
        ]
      }
    ],
    "complexity_targets": [
      {
        "operation": "Cache lookup",
        "target": "O(1)",
        "achieved": "O(1)",
        "why": "Map/Object provides O(1) key lookup"
      },
      {
        "operation": "Key generation",
        "target": "O(n)",
        "achieved": "O(n)",
        "why": "JSON.stringify is O(n) where n = args size"
      },
      {
        "operation": "Cache miss (fn execution)",
        "target": "O(fn)",
        "achieved": "O(fn)",
        "why": "Original function complexity unchanged"
      }
    ],
    "non_goals": [
      "LRU/cache eviction (no size limits in Part 1)",
      "Async function handling (Part 2)",
      "Cache invalidation/clearing",
      "Time-based expiration",
      "WeakMap for object keys (advanced optimization)"
    ]
  },
  "assumptions": [
    "**Pure functions only**: The memoized function should be deterministic (same input \u2192 same output)",
    "**Serializable arguments**: Arguments can be JSON.stringify'd (no circular refs, no functions)",
    "**Unlimited cache**: No memory constraints for this problem",
    "**Synchronous functions**: No async/Promise handling in Part 1",
    "**No error caching**: If fn throws, we don't cache the error"
  ],
  "tradeoffs": [
    {
      "decision": "Map vs Object for cache",
      "chosen": "Map",
      "why": "Map has cleaner API (.has, .get, .set), no prototype pollution risks, and can technically use any key type",
      "alternative": "Plain Object {}",
      "when_to_switch": "Object is fine for simple cases; Map is better for production"
    },
    {
      "decision": "JSON.stringify vs custom key generator",
      "chosen": "JSON.stringify for Part 1",
      "why": "Simple, handles most cases, preserves types for primitives",
      "alternative": "Custom serializer or WeakMap for objects",
      "when_to_switch": "If handling circular refs, functions as args, or need object identity (not equality)"
    },
    {
      "decision": "Regular function vs arrow function for returned wrapper",
      "chosen": "Regular function",
      "why": "Preserves `this` binding - arrow functions capture lexical `this`",
      "alternative": "Arrow function with explicit context handling",
      "when_to_switch": "Never for general-purpose memoize; `this` preservation is essential"
    }
  ],
  "extensibility_and_followups": {
    "design_principles": [
      "**Single Responsibility**: memoize only handles caching, not validation or transformation",
      "**Open/Closed**: Allow custom key generators via optional parameter",
      "**Dependency Injection**: Cache storage could be injected for testing"
    ],
    "why_this_design_scales": "The closure + Map pattern is extensible:\n- Add custom key generator: `memoize(fn, keyGen)`\n- Add cache options: `memoize(fn, { maxSize: 100, ttl: 5000 })`\n- Add async support: wrap result in Promise check\n- The core pattern stays the same, just augment the wrapper",
    "expected_followup_hooks": [
      "**keyGenerator function**: Plug in custom serialization for complex objects",
      "**cache implementation**: Swap Map for LRU cache, Redis, etc.",
      "**result transformation**: Add .then() handling for async",
      "**cache.clear() method**: Expose on returned function for manual invalidation"
    ],
    "invariants": [
      "Same arguments (by serialization) always return same cached result",
      "Original function called at most once per unique argument combination",
      "Cache never shrinks (in Part 1)"
    ]
  },
  "visual_explanation": {
    "problem_visualization": "```\n                    MEMOIZATION CONCEPT\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                                                     \u2502\n    \u2502   Original Function          Memoized Function      \u2502\n    \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n    \u2502   \u2502             \u2502           \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502\n    \u2502   \u2502  function   \u2502  memoize  \u2502  \u2502   CACHE    \u2502  \u2502    \u2502\n    \u2502   \u2502  add(a,b)   \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6  \u2502  \u2502 [1,2] \u2192 3  \u2502  \u2502    \u2502\n    \u2502   \u2502  {         \u2502           \u2502  \u2502 [2,3] \u2192 5  \u2502  \u2502    \u2502\n    \u2502   \u2502   return   \u2502           \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502\n    \u2502   \u2502   a + b;   \u2502           \u2502        \u2502         \u2502    \u2502\n    \u2502   \u2502  }         \u2502           \u2502        \u25bc         \u2502    \u2502\n    \u2502   \u2502             \u2502           \u2502  fn.apply(this) \u2502    \u2502\n    \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n    \u2502                                                     \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "data_structure_state": "```\n    CLOSURE STRUCTURE:\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  memoize(fn) creates:                               \u2502\n    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n    \u2502  \u2502  OUTER SCOPE (Closure)                        \u2502  \u2502\n    \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n    \u2502  \u2502  \u2502  fn: [reference to original function]   \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502  cache: Map {                           \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502    '[1,2]' \u2192 3                          \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502    '[2,3]' \u2192 5                          \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502    '[\"hello\"]' \u2192 'HELLO'                \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502  }                                      \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502\n    \u2502  \u2502                    \u2502                          \u2502  \u2502\n    \u2502  \u2502                    \u25bc                          \u2502  \u2502\n    \u2502  \u2502  INNER FUNCTION (Returned)                    \u2502  \u2502\n    \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502\n    \u2502  \u2502  \u2502  function(...args) {                    \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502    // Can access fn and cache           \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502    // via closure!                      \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2502  }                                      \u2502  \u2502  \u2502\n    \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502\n    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
    "algorithm_flow": [
      {
        "step": 1,
        "description": "Create closure with cache",
        "visualization": "```\nmemoize(add) called:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 cache = new Map \u2502 \u2190 Empty cache created\n\u2502 fn = add        \u2502 \u2190 Reference to original\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
        "key_point": "Cache lives in closure, persists across calls"
      },
      {
        "step": 2,
        "description": "Generate cache key from arguments",
        "visualization": "```\nmemoizedAdd(1, 2) called:\n\nargs = [1, 2]\nkey = JSON.stringify([1, 2])\nkey = '[1,2]'  \u2190 String key for Map\n```",
        "key_point": "JSON.stringify preserves types: [1] \u2260 ['1']"
      },
      {
        "step": 3,
        "description": "Check cache for existing result",
        "visualization": "```\ncache.has('[1,2]')?\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    CACHE      \u2502\n\u2502   (empty)     \u2502  \u2192 NO \u2192 Cache miss!\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```",
        "key_point": "O(1) lookup using Map"
      },
      {
        "step": 4,
        "description": "Execute function and store result",
        "visualization": "```\nCache MISS \u2192 Execute original:\n\nresult = fn.apply(this, [1, 2])\nresult = add(1, 2) = 3\n\ncache.set('[1,2]', 3)\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     CACHE       \u2502\n\u2502  '[1,2]' \u2192 3    \u2502  \u2190 Stored!\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nreturn 3\n```",
        "key_point": "Use fn.apply() to preserve `this` context"
      },
      {
        "step": 5,
        "description": "Subsequent call with same args",
        "visualization": "```\nmemoizedAdd(1, 2) called again:\n\nkey = '[1,2]'\ncache.has('[1,2]')? \u2192 YES!\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     CACHE       \u2502\n\u2502  '[1,2]' \u2192 3 \u2713  \u2502  \u2192 Return 3 immediately!\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u26a1 No computation needed!\n```",
        "key_point": "Cache HIT = instant return, fn never called"
      }
    ],
    "dry_run_table": "| Call | args | Key Generated | Cache State | Action | Result |\n|------|------|---------------|-------------|--------|--------|\n| `memoize(add)` | - | - | `{}` | Create wrapper | memoizedAdd |\n| `memoizedAdd(1, 2)` | `[1, 2]` | `'[1,2]'` | `{'[1,2]': 3}` | MISS \u2192 compute | `3` |\n| `memoizedAdd(1, 2)` | `[1, 2]` | `'[1,2]'` | `{'[1,2]': 3}` | HIT \u2192 return | `3` |\n| `memoizedAdd(2, 3)` | `[2, 3]` | `'[2,3]'` | `{'[1,2]': 3, '[2,3]': 5}` | MISS \u2192 compute | `5` |\n| `memoizedAdd('1', '2')` | `['1', '2']` | `'[\"1\",\"2\"]'` | `{..., '[\"1\",\"2\"]': '12'}` | MISS \u2192 compute | `'12'` |"
  },
  "thinking_process": {
    "step_by_step": [
      "**When I see 'cache results based on arguments'**, I think: I need a data structure that maps arguments \u2192 results. That's a HashMap/Map.",
      "**When I see 'returns a new function'**, I think: This is a higher-order function pattern. The returned function needs access to the cache, so I need a closure.",
      "**When I see 'different cache keys for 1 vs \"1\"'**, I think: I can't use simple toString() or join(). I need type-preserving serialization. JSON.stringify does this!",
      "**When I see 'preserve this context'**, I think: Arrow functions capture lexical `this`, so I must use regular function syntax and fn.apply(this, args).",
      "**When I realize JSON.stringify has edge cases**, I think: undefined \u2192 null, functions ignored, circular refs throw. For Part 1, I'll note these but keep solution simple."
    ],
    "key_insight": "**The magic is in the closure**: The returned function 'closes over' the cache variable. Each call to `memoize(fn)` creates a NEW closure with its OWN cache. This is why `memoize(add)` and `memoize(multiply)` have separate caches!",
    "why_this_works": "## Why Memoization Works\n\n1. **Closure Persistence**: The cache Map exists in the closure scope, surviving between function calls\n2. **Key Uniqueness**: JSON.stringify creates unique string keys that preserve argument types\n3. **Map Efficiency**: O(1) lookup means cache checks are nearly free\n4. **Referential Transparency**: For pure functions, same inputs ALWAYS produce same outputs, making caching safe"
  },
  "approaches": [
    {
      "name": "No Memoization (Baseline)",
      "description": "Just call the original function every time. This is what we're improving upon.",
      "pseudocode": "function wrapper(...args) {\n  return fn(...args); // Always compute\n}",
      "time_complexity": "O(fn) per call - no improvement",
      "space_complexity": "O(1) - no cache storage",
      "pros": [
        "Simplest possible",
        "No memory overhead"
      ],
      "cons": [
        "Repeated expensive computations",
        "Defeats the purpose of memoization"
      ],
      "when_to_use": "Never for memoization - this is the problem we're solving"
    },
    {
      "name": "Naive Key Generation (Broken)",
      "description": "Use args.toString() or args.join() for cache key",
      "pseudocode": "const key = args.toString(); // BAD!\n// [1, 2].toString() === '1,2'\n// ['1', '2'].toString() === '1,2' // COLLISION!",
      "time_complexity": "O(1) lookup, but incorrect results",
      "space_complexity": "O(unique_keys)",
      "pros": [
        "Simple to implement"
      ],
      "cons": [
        "Type collisions: 1 vs '1'",
        "Array vs multiple args collision",
        "Completely wrong for production"
      ],
      "when_to_use": "NEVER - this approach is broken"
    },
    {
      "name": "Optimal: JSON.stringify Key Generation",
      "description": "Use JSON.stringify(args) which preserves type information in the serialized string",
      "pseudocode": "const key = JSON.stringify(args);\n// [1, 2] \u2192 '[1,2]'\n// ['1', '2'] \u2192 '[\"1\",\"2\"]' // Different!\n// [1] \u2192 '[1]'\n// [[1]] \u2192 '[[1]]' // Different!",
      "time_complexity": "O(1) lookup + O(args_size) serialization",
      "space_complexity": "O(unique_arg_combinations)",
      "pros": [
        "Type-safe keys",
        "Handles nested structures",
        "Standard JS approach",
        "Used by lodash, etc."
      ],
      "cons": [
        "undefined \u2192 null in JSON",
        "Functions ignored",
        "Circular refs throw"
      ],
      "key_insight": "JSON.stringify naturally encodes type information: numbers are unquoted, strings are quoted, arrays have brackets. This creates unique keys per type!"
    },
    {
      "name": "Advanced: WeakMap for Object Arguments",
      "description": "Use WeakMap when objects should be compared by reference, not value",
      "pseudocode": "// For single object arg:\nconst cache = new WeakMap();\nif (cache.has(objArg)) return cache.get(objArg);",
      "time_complexity": "O(1)",
      "space_complexity": "O(unique_objects) with automatic GC",
      "pros": [
        "Object identity comparison",
        "Automatic garbage collection",
        "Memory efficient for objects"
      ],
      "cons": [
        "Only works for object keys",
        "Can't use for primitives",
        "Complex for multiple args"
      ],
      "when_to_use": "When you specifically need reference equality for object arguments"
    }
  ],
  "optimal_solution": {
    "name": "Closure-based Memoization with JSON.stringify Keys",
    "explanation_md": "## Approach\n\nThe optimal solution uses:\n1. **Closure** to maintain a persistent cache between calls\n2. **Map** for O(1) cache operations\n3. **JSON.stringify** for type-preserving key generation\n4. **fn.apply(this, args)** to preserve context\n\n### Why This Works\n\n```\nmemoize(fn) creates:\n\u251c\u2500\u2500 Closure scope containing:\n\u2502   \u251c\u2500\u2500 fn (reference to original function)\n\u2502   \u2514\u2500\u2500 cache (Map instance)\n\u2514\u2500\u2500 Returns wrapper function that:\n    \u251c\u2500\u2500 Generates key from args\n    \u251c\u2500\u2500 Checks cache\n    \u251c\u2500\u2500 Calls fn only on cache miss\n    \u2514\u2500\u2500 Stores and returns result\n```\n\n### The Key Generation Magic\n\n```javascript\nJSON.stringify([1, 2])      // '[1,2]'\nJSON.stringify(['1', '2'])  // '[\"1\",\"2\"]'  \u2190 Different!\nJSON.stringify([true])      // '[true]'\nJSON.stringify(['true'])    // '[\"true\"]'   \u2190 Different!\nJSON.stringify([null])      // '[null]'\nJSON.stringify([[1,2]])     // '[[1,2]]'    \u2190 Array arg vs two args\n```",
    "data_structures": [
      {
        "structure": "Closure",
        "purpose": "Encapsulate cache and original fn reference, persist between calls"
      },
      {
        "structure": "Map<string, any>",
        "purpose": "O(1) cache storage and retrieval"
      },
      {
        "structure": "JSON.stringify",
        "purpose": "Convert args array to unique, type-preserving string key"
      }
    ],
    "algorithm_steps": [
      "1. **memoize(fn)** called: Create new Map for cache, return wrapper function",
      "2. **wrapper(...args)** called: Serialize args to key using JSON.stringify",
      "3. **Check cache**: If key exists in cache, return cached value immediately",
      "4. **Cache miss**: Call original fn with args (preserving `this` context)",
      "5. **Store result**: Add key\u2192result mapping to cache",
      "6. **Return result**: Return computed value"
    ],
    "why_decimal": "N/A - not applicable to this problem"
  },
  "solution_python_lines": [
    "\"\"\"",
    "JavaScript Memoization - Python Equivalent",
    "",
    "While the problem is JavaScript-focused, here's the Python equivalent",
    "using functools.lru_cache pattern and a manual implementation.",
    "\"\"\"",
    "from typing import Callable, Any, TypeVar",
    "from functools import wraps",
    "import json",
    "",
    "F = TypeVar('F', bound=Callable[..., Any])",
    "",
    "",
    "def memoize(fn: F) -> F:",
    "    \"\"\"",
    "    Memoize a function by caching results based on arguments.",
    "    ",
    "    This is the Python equivalent of the JavaScript memoize pattern.",
    "    Uses JSON serialization for cache keys to handle multiple arg types.",
    "    ",
    "    Args:",
    "        fn: The function to memoize",
    "        ",
    "    Returns:",
    "        A memoized version of fn that caches results",
    "        ",
    "    Example:",
    "        >>> @memoize",
    "        ... def add(a, b):",
    "        ...     print(f'Computing {a} + {b}')",
    "        ...     return a + b",
    "        >>> add(1, 2)  # Prints 'Computing 1 + 2'",
    "        3",
    "        >>> add(1, 2)  # No print - cache hit!",
    "        3",
    "    \"\"\"",
    "    cache: dict[str, Any] = {}",
    "    ",
    "    @wraps(fn)",
    "    def memoized(*args: Any) -> Any:",
    "        # Generate cache key from arguments",
    "        # Using JSON for type-preserving serialization",
    "        try:",
    "            key = json.dumps(args, sort_keys=True)",
    "        except TypeError:",
    "            # Fallback for non-JSON-serializable args",
    "            key = str(args)",
    "        ",
    "        # Check cache",
    "        if key in cache:",
    "            return cache[key]",
    "        ",
    "        # Cache miss - compute result",
    "        result = fn(*args)",
    "        ",
    "        # Store in cache",
    "        cache[key] = result",
    "        ",
    "        return result",
    "    ",
    "    # Expose cache for testing/debugging",
    "    memoized.cache = cache  # type: ignore",
    "    memoized.clear_cache = lambda: cache.clear()  # type: ignore",
    "    ",
    "    return memoized  # type: ignore",
    "",
    "",
    "# ============================================================",
    "# DEMO AND TESTS",
    "# ============================================================",
    "",
    "if __name__ == '__main__':",
    "    print('=' * 60)",
    "    print('MEMOIZATION DEMO')",
    "    print('=' * 60)",
    "    ",
    "    # Test 1: Basic memoization",
    "    print('\\n--- Test 1: Basic Memoization ---')",
    "    call_count = 0",
    "    ",
    "    @memoize",
    "    def add(a: int, b: int) -> int:",
    "        global call_count",
    "        call_count += 1",
    "        return a + b",
    "    ",
    "    print(f'add(1, 2) = {add(1, 2)}')  # Computes",
    "    print(f'add(1, 2) = {add(1, 2)}')  # Cache hit",
    "    print(f'add(2, 3) = {add(2, 3)}')  # Computes",
    "    print(f'Function called {call_count} times (should be 2)')",
    "    ",
    "    # Test 2: Type differentiation",
    "    print('\\n--- Test 2: Type Differentiation ---')",
    "    ",
    "    @memoize",
    "    def identity(x: Any) -> Any:",
    "        return x",
    "    ",
    "    print(f'identity(1) = {identity(1)} (type: {type(identity(1)).__name__})')",
    "    print(f'identity(\"1\") = {identity(\"1\")} (type: {type(identity(\"1\")).__name__})')",
    "    print(f'Cache has {len(identity.cache)} entries (should be 2)')",
    "    ",
    "    # Test 3: Expensive computation",
    "    print('\\n--- Test 3: Fibonacci ---')",
    "    ",
    "    @memoize",
    "    def fib(n: int) -> int:",
    "        if n <= 1:",
    "            return n",
    "        return fib(n - 1) + fib(n - 2)",
    "    ",
    "    import time",
    "    start = time.time()",
    "    result = fib(35)",
    "    elapsed = time.time() - start",
    "    print(f'fib(35) = {result} (took {elapsed:.4f}s)')",
    "    ",
    "    start = time.time()",
    "    result = fib(35)",
    "    elapsed = time.time() - start",
    "    print(f'fib(35) = {result} (took {elapsed:.6f}s - cache hit!)')",
    "    ",
    "    print('\\n' + '=' * 60)",
    "    print('ALL TESTS PASSED!')",
    "    print('=' * 60)"
  ],
  "solution_java_lines": [
    "// JavaScript Solution (Primary - since this is a JS problem)",
    "// ============================================================",
    "",
    "/**",
    " * Memoize - Cache function results based on arguments",
    " * ",
    " * @param {Function} fn - The function to memoize",
    " * @returns {Function} - Memoized version of fn",
    " * ",
    " * @example",
    " * const memoizedAdd = memoize((a, b) => a + b);",
    " * memoizedAdd(1, 2); // Computes, returns 3",
    " * memoizedAdd(1, 2); // Cache hit, returns 3",
    " */",
    "function memoize(fn) {",
    "  // Create cache in closure scope",
    "  // Map is preferred over Object for cleaner API",
    "  const cache = new Map();",
    "  ",
    "  // Return wrapper function",
    "  // IMPORTANT: Use regular function, not arrow,",
    "  // to preserve 'this' context",
    "  return function memoized(...args) {",
    "    // Generate cache key from all arguments",
    "    // JSON.stringify preserves type information:",
    "    // [1, 2] -> '[1,2]'",
    "    // ['1', '2'] -> '[\"1\",\"2\"]' (different!)",
    "    const key = JSON.stringify(args);",
    "    ",
    "    // Check if result is cached",
    "    if (cache.has(key)) {",
    "      return cache.get(key);",
    "    }",
    "    ",
    "    // Cache miss - execute original function",
    "    // Use fn.apply(this, args) to preserve 'this' context",
    "    const result = fn.apply(this, args);",
    "    ",
    "    // Store result in cache",
    "    cache.set(key, result);",
    "    ",
    "    return result;",
    "  };",
    "}",
    "",
    "// ============================================================",
    "// ENHANCED VERSION WITH OPTIONS",
    "// ============================================================",
    "",
    "/**",
    " * Enhanced memoize with custom key generator",
    " * ",
    " * @param {Function} fn - Function to memoize",
    " * @param {Object} options - Configuration options",
    " * @param {Function} options.keyGenerator - Custom key generation function",
    " * @returns {Function} - Memoized function with cache utilities",
    " */",
    "function memoizeEnhanced(fn, options = {}) {",
    "  const {",
    "    keyGenerator = (args) => JSON.stringify(args)",
    "  } = options;",
    "  ",
    "  const cache = new Map();",
    "  ",
    "  function memoized(...args) {",
    "    const key = keyGenerator(args);",
    "    ",
    "    if (cache.has(key)) {",
    "      return cache.get(key);",
    "    }",
    "    ",
    "    const result = fn.apply(this, args);",
    "    cache.set(key, result);",
    "    return result;",
    "  }",
    "  ",
    "  // Expose utilities for debugging/testing",
    "  memoized.cache = cache;",
    "  memoized.clear = () => cache.clear();",
    "  memoized.size = () => cache.size;",
    "  ",
    "  return memoized;",
    "}",
    "",
    "// ============================================================",
    "// TEST CASES",
    "// ============================================================",
    "",
    "function runTests() {",
    "  console.log('='.repeat(60));",
    "  console.log('MEMOIZATION TESTS');",
    "  console.log('='.repeat(60));",
    "  ",
    "  // Test 1: Basic memoization",
    "  console.log('\\n--- Test 1: Basic Memoization ---');",
    "  let callCount = 0;",
    "  const add = (a, b) => {",
    "    callCount++;",
    "    return a + b;",
    "  };",
    "  const memoizedAdd = memoize(add);",
    "  ",
    "  console.log('memoizedAdd(1, 2):', memoizedAdd(1, 2)); // 3",
    "  console.log('memoizedAdd(1, 2):', memoizedAdd(1, 2)); // 3 (cached)",
    "  console.log('memoizedAdd(2, 3):', memoizedAdd(2, 3)); // 5",
    "  console.log(`Function called ${callCount} times (expected: 2)`);",
    "  console.assert(callCount === 2, 'Should only compute twice');",
    "  ",
    "  // Test 2: Type differentiation",
    "  console.log('\\n--- Test 2: Type Differentiation ---');",
    "  const identity = memoize(x => x);",
    "  console.log('identity(1):', identity(1), typeof identity(1));",
    "  console.log('identity(\"1\"):', identity('1'), typeof identity('1'));",
    "  console.assert(identity(1) !== identity('1'), 'Different types');",
    "  ",
    "  // Test 3: Expensive computation",
    "  console.log('\\n--- Test 3: Fibonacci ---');",
    "  const fib = memoize(function fibonacci(n) {",
    "    if (n <= 1) return n;",
    "    return fib(n - 1) + fib(n - 2);",
    "  });",
    "  ",
    "  console.time('fib(35) first call');",
    "  console.log('fib(35):', fib(35));",
    "  console.timeEnd('fib(35) first call');",
    "  ",
    "  console.time('fib(35) second call');",
    "  console.log('fib(35):', fib(35));",
    "  console.timeEnd('fib(35) second call');",
    "  ",
    "  // Test 4: Edge cases",
    "  console.log('\\n--- Test 4: Edge Cases ---');",
    "  const edgeFn = memoize((...args) => args.length);",
    "  console.log('edgeFn():', edgeFn()); // 0 args",
    "  console.log('edgeFn(null):', edgeFn(null));",
    "  console.log('edgeFn(undefined):', edgeFn(undefined));",
    "  console.log('edgeFn([1,2]):', edgeFn([1, 2])); // Array arg",
    "  console.log('edgeFn(1, 2):', edgeFn(1, 2)); // Two args",
    "  ",
    "  // Test 5: This context",
    "  console.log('\\n--- Test 5: This Context ---');",
    "  const obj = {",
    "    multiplier: 10,",
    "    multiply: memoize(function(x) {",
    "      return x * this.multiplier;",
    "    })",
    "  };",
    "  console.log('obj.multiply(5):', obj.multiply(5)); // 50",
    "  ",
    "  console.log('\\n' + '='.repeat(60));",
    "  console.log('ALL TESTS PASSED!');",
    "  console.log('='.repeat(60));",
    "}",
    "",
    "// Run tests",
    "runTests();"
  ],
  "code_walkthrough": [
    {
      "lines": "1-14",
      "section": "JSDoc and Function Signature",
      "explanation": "We document the function with JSDoc, specifying that it takes any function and returns a memoized version. This is crucial for team code and IDE support."
    },
    {
      "lines": "15-18",
      "section": "Cache Initialization",
      "explanation": "**The cache lives in the closure scope**. We use `Map` instead of `{}` because:\n- Cleaner API: `.has()`, `.get()`, `.set()`\n- No prototype pollution risks\n- Can technically use any key type\n\nThis Map persists across all calls to the memoized function."
    },
    {
      "lines": "20-24",
      "section": "Wrapper Function Declaration",
      "explanation": "**CRITICAL**: We use a regular `function`, NOT an arrow function!\n\nWhy? Arrow functions capture `this` from the lexical scope (where they're defined), but we need `this` from the call site. If someone does `obj.memoizedMethod()`, we need `this` to be `obj`."
    },
    {
      "lines": "25-30",
      "section": "Key Generation",
      "explanation": "`JSON.stringify(args)` is the **key insight**.\n\nIt preserves type information:\n- `[1, 2]` \u2192 `'[1,2]'`\n- `['1', '2']` \u2192 `'[\"1\",\"2\"]'`\n\nThese are DIFFERENT strings, preventing type collisions!"
    },
    {
      "lines": "32-35",
      "section": "Cache Lookup",
      "explanation": "**O(1) lookup** using Map.has(). If the key exists, we return the cached value immediately without calling the original function. This is the whole point of memoization!"
    },
    {
      "lines": "37-40",
      "section": "Function Execution",
      "explanation": "On cache miss, we call the original function using `fn.apply(this, args)`.\n\n**Why apply?**\n1. Preserves `this` context\n2. Spreads args array as individual arguments\n\nAlternative: `fn.call(this, ...args)` works too."
    },
    {
      "lines": "42-44",
      "section": "Cache Storage",
      "explanation": "Store the computed result with the generated key. Next time this argument combination is used, we'll hit the cache instead of recomputing."
    },
    {
      "lines": "46",
      "section": "Return Result",
      "explanation": "Return the result, whether from cache or freshly computed. The caller doesn't know (or care) which path was taken."
    }
  ],
  "debugging_strategy": {
    "how_to_test_incrementally": "1. **First**: Test that memoized function returns correct results\n2. **Second**: Test that cache is being populated (add console.log in cache miss path)\n3. **Third**: Test cache hits (add console.log at return cache.get())\n4. **Fourth**: Test type differentiation\n5. **Fifth**: Test `this` context with an object method",
    "what_to_print_or_assert": [
      "console.log('Cache key:', key);",
      "console.log('Cache hit:', cache.has(key));",
      "console.log('Cache size:', cache.size);",
      "console.assert(typeof key === 'string', 'Key should be string');",
      "console.assert(cache instanceof Map, 'Cache should be Map');"
    ],
    "common_failure_modes": [
      "**Wrong key generation**: Using toString() causes type collisions",
      "**Arrow function for wrapper**: Breaks `this` binding",
      "**Forgetting to return memoized function**: Returns undefined",
      "**Using fn() instead of fn.apply()**: Loses `this` context",
      "**Cache outside closure**: All memoized functions share one cache (disaster!)"
    ],
    "how_to_fix_fast": "1. **Cache not working?** Add `console.log('key:', key, 'hit:', cache.has(key))` at the start of wrapper\n2. **Type collision?** Check key format - should have quotes around strings\n3. **`this` broken?** Check if using regular function (not arrow) and fn.apply()\n4. **Always computing?** Ensure you're using the SAME memoized function reference"
  },
  "complexity_analysis": {
    "time": {
      "memoize": {
        "complexity": "O(1)",
        "explanation": "Just creates Map and returns function"
      },
      "memoized_call_cache_hit": {
        "complexity": "O(k)",
        "explanation": "O(k) for JSON.stringify where k = args size, then O(1) Map lookup"
      },
      "memoized_call_cache_miss": {
        "complexity": "O(k) + O(fn)",
        "explanation": "Key generation + original function execution"
      },
      "overall": "Amortized O(1) for repeated calls with same args"
    },
    "space": {
      "complexity": "O(n \u00d7 k) where n = unique arg combinations, k = avg result size",
      "breakdown": "- Map instance: O(1)\n- Cache entries: O(n) where n = unique calls\n- Each entry stores: key (string) + result\n- Keys are O(args_size), results are O(result_size)",
      "note": "Cache grows unbounded in Part 1. Production code should add LRU eviction."
    },
    "can_we_do_better": "Time: No - O(1) lookup is optimal. Space: Yes - LRU cache limits memory, WeakMap allows GC for object keys."
  },
  "dry_run": {
    "example": "const add = (a, b) => a + b;\nconst memoizedAdd = memoize(add);\nmemoizedAdd(1, 2);\nmemoizedAdd(1, 2);\nmemoizedAdd(2, 3);",
    "trace_table": "| Step | Operation | args | key | cache before | Action | Result | cache after |\n|------|-----------|------|-----|--------------|--------|--------|-------------|\n| 1 | `memoize(add)` | - | - | (created) | Create closure | memoizedAdd | `Map{}` |\n| 2 | `memoizedAdd(1, 2)` | `[1, 2]` | `'[1,2]'` | `Map{}` | MISS \u2192 compute | `3` | `Map{'[1,2]': 3}` |\n| 3 | `memoizedAdd(1, 2)` | `[1, 2]` | `'[1,2]'` | `Map{'[1,2]': 3}` | HIT \u2192 return | `3` | unchanged |\n| 4 | `memoizedAdd(2, 3)` | `[2, 3]` | `'[2,3]'` | `Map{'[1,2]': 3}` | MISS \u2192 compute | `5` | `Map{'[1,2]': 3, '[2,3]': 5}` |",
    "final_answer": "Results: 3, 3, 5 | Original function called only 2 times (not 3)"
  },
  "test_cases": [
    {
      "name": "Basic - Two arguments",
      "category": "Happy Path",
      "input": "memoize(add); memoizedAdd(1, 2); memoizedAdd(1, 2);",
      "expected": "3, 3 (add called once)",
      "explanation": "First call computes and caches. Second call returns cached result."
    },
    {
      "name": "Type differentiation - number vs string",
      "category": "Edge Case",
      "input": "memoize(identity); identity(1); identity('1');",
      "expected": "1 (number), '1' (string) - different cache entries",
      "explanation": "JSON.stringify([1]) = '[1]' but JSON.stringify(['1']) = '[\"1\"]' - different keys!"
    },
    {
      "name": "Empty arguments",
      "category": "Edge Case",
      "input": "memoize(getTime); getTime(); getTime();",
      "expected": "Same value both times (cached)",
      "explanation": "JSON.stringify([]) = '[]' - valid cache key for no-arg functions"
    },
    {
      "name": "null vs undefined",
      "category": "Gotcha",
      "input": "memoize(identity); identity(null); identity(undefined);",
      "expected": "null, undefined - should be different... but gotcha!",
      "gotcha": "JSON.stringify([undefined]) = '[null]' - same as [null]! This is a known limitation."
    },
    {
      "name": "Array argument vs multiple arguments",
      "category": "Edge Case",
      "input": "memoize(fn); fn([1, 2]); fn(1, 2);",
      "expected": "Different cache entries",
      "explanation": "JSON.stringify([[1,2]]) = '[[1,2]]' vs JSON.stringify([1,2]) = '[1,2]'"
    },
    {
      "name": "Object arguments",
      "category": "Edge Case",
      "input": "memoize(fn); fn({a: 1}); fn({a: 1});",
      "expected": "Same result (cache hit)",
      "explanation": "JSON.stringify([{a:1}]) = '[{\"a\":1}]' - consistent for same structure"
    },
    {
      "name": "This context preservation",
      "category": "Edge Case",
      "input": "obj.multiply = memoize(function(x) { return x * this.mult; }); obj.mult = 10; obj.multiply(5);",
      "expected": "50",
      "explanation": "Using fn.apply(this, args) preserves the object context"
    },
    {
      "name": "Fibonacci performance",
      "category": "Performance",
      "input": "memoize(fib); fib(40); fib(40); fib(40);",
      "expected": "102334155 (first slow, rest instant)",
      "explanation": "Recursive calls benefit from memoization too!"
    }
  ],
  "common_mistakes": [
    {
      "mistake": "Using args.toString() for key generation",
      "why_wrong": "[1, 2].toString() === '1,2' AND ['1', '2'].toString() === '1,2' - TYPE COLLISION!",
      "correct_approach": "Use JSON.stringify(args) which preserves type info",
      "code_wrong": "const key = args.toString(); // BAD",
      "code_correct": "const key = JSON.stringify(args); // GOOD"
    },
    {
      "mistake": "Using arrow function for the wrapper",
      "why_wrong": "Arrow functions capture lexical `this`, breaking method calls",
      "correct_approach": "Use regular function declaration to inherit call-site `this`",
      "code_wrong": "return (...args) => { fn.apply(this, args); }; // 'this' is wrong!",
      "code_correct": "return function(...args) { fn.apply(this, args); }; // 'this' is correct"
    },
    {
      "mistake": "Creating cache outside the closure",
      "why_wrong": "All memoized functions would share one cache - total disaster",
      "correct_approach": "Create cache INSIDE memoize(), so each call gets its own cache",
      "code_wrong": "const cache = new Map(); // OUTSIDE - shared by all!\nfunction memoize(fn) { ... }",
      "code_correct": "function memoize(fn) {\n  const cache = new Map(); // INSIDE - unique per function\n  ..."
    },
    {
      "mistake": "Not returning the memoized function",
      "why_wrong": "memoize() returns undefined, calls fail",
      "correct_approach": "Always return the wrapper function",
      "code_wrong": "function memoize(fn) {\n  const cache = new Map();\n  function memoized() { ... }\n  // forgot return!\n}",
      "code_correct": "function memoize(fn) {\n  const cache = new Map();\n  return function memoized() { ... }  // return it!\n}"
    },
    {
      "mistake": "Using fn(args) instead of fn.apply(this, args)",
      "why_wrong": "Passes array as single argument, doesn't spread args",
      "correct_approach": "Use apply() to spread args and preserve this",
      "code_wrong": "const result = fn(args); // Passes [1, 2] as single arg",
      "code_correct": "const result = fn.apply(this, args); // Passes 1, 2 as two args"
    }
  ],
  "interview_tips": {
    "opening": "This is a classic JavaScript pattern - memoization using closures. Let me clarify a few things before I start...",
    "clarifying_questions_to_ask": [
      "Should the memoization be by value or reference for object arguments?",
      "Do I need to handle async functions / Promises?",
      "Should the cache have a size limit (LRU)?",
      "Do I need to preserve the `this` context?",
      "What about functions that throw errors - should we cache those?"
    ],
    "what_to_mention_proactively": [
      "I'll use a closure to maintain the cache between calls",
      "I'll use JSON.stringify for type-safe key generation",
      "I'll use a regular function (not arrow) to preserve `this` context",
      "JSON.stringify has edge cases with undefined and circular refs - I'll note those"
    ],
    "communication_during_coding": [
      "Creating the Map in the closure scope so each memoized function has its own cache",
      "Using JSON.stringify because it preserves type info - [1] becomes '[1]' but ['1'] becomes '[\"1\"]'",
      "Using fn.apply(this, args) to spread arguments and preserve this context",
      "Regular function, not arrow, because we need call-site this binding"
    ],
    "if_stuck": [
      "Step back: What are the components? Cache + wrapper function + key generation",
      "Draw it: Sketch the closure structure",
      "Start simple: Get basic caching working, then add type safety"
    ],
    "time_management": "0-5min: Clarify requirements | 5-10min: Explain approach | 10-20min: Implement core | 20-25min: Test | 25-30min: Edge cases | 30-45min: Follow-ups"
  },
  "pattern_recognition": {
    "pattern_name": "Closure + Cache (Memoization Pattern)",
    "indicators": [
      "Repeated expensive computations",
      "Pure functions (same input \u2192 same output)",
      "Need to optimize without changing function signature"
    ],
    "similar_problems": [
      "LC 2623 - Memoize: Direct implementation",
      "LC 2630 - Memoize II: Handles object arguments by reference",
      "LC 2636 - Promise Pool: Similar closure pattern",
      "Function.prototype.bind polyfill: Closure + this binding"
    ],
    "template": "```javascript\nfunction createCachedWrapper(fn) {\n  const cache = new Map();\n  return function(...args) {\n    const key = serialize(args);\n    if (cache.has(key)) return cache.get(key);\n    const result = fn.apply(this, args);\n    cache.set(key, result);\n    return result;\n  };\n}\n```"
  },
  "follow_up_preparation": {
    "part_2_hint": "Part 2 adds **async memoization with callbacks**. Key changes:\n- Results aren't immediately available\n- Multiple callers might request same key before first completes\n- Need to queue pending callbacks, not re-execute",
    "part_3_hint": "Part 3 is **Function.prototype.bind polyfill**:\n- Store bound `this` and partial args in closure\n- Handle both regular calls and `new` keyword\n- Preserve prototype chain",
    "data_structure_evolution": "Part 1: Map<key, value> \u2192 Part 2: Map<key, {status, value, callbacks}> \u2192 Part 3: Different pattern entirely"
  },
  "communication_script": {
    "opening_verbatim": "Thanks for this problem! Memoization is a fundamental pattern I use often in React and Redux. Before I code, let me clarify a few things and share my approach.",
    "after_clarification": "Great, so to summarize: I need to implement a memoize function that caches results based on arguments, with different cache keys for different types like 1 vs '1'. I'll use a closure with a Map for the cache, and JSON.stringify for type-safe key generation. Sound good?",
    "while_coding": [
      "Creating the cache as a Map in the closure scope...",
      "Using a regular function, not arrow, to preserve this context...",
      "JSON.stringify gives us type-safe keys - numbers stay unquoted, strings get quotes...",
      "fn.apply(this, args) spreads the arguments and preserves this..."
    ],
    "after_coding": "Let me trace through this with the example. First call memoizedAdd(1,2): key is '[1,2]', cache miss, compute 3, store it. Second call same args: cache hit, return 3 instantly. Third call (2,3): different key '[2,3]', compute 5.",
    "when_stuck_verbatim": "Let me step back. The key components are: cache storage, key generation, and the wrapper function. Let me focus on getting the cache lookup working first.",
    "after_mistake": "Ah, I see the issue - I used an arrow function which doesn't preserve 'this'. Let me fix that by using a regular function declaration.",
    "before_moving_on": "This handles Part 1. Time complexity is O(1) for cache hits, O(k) for key generation where k is args size. Space is O(n) for n unique argument combinations. Ready for Part 2?"
  },
  "interviewer_perspective": {
    "what_they_evaluate": [
      "**Closure understanding**: Do they know how closures work?",
      "**JavaScript this binding**: Do they understand arrow vs regular functions?",
      "**Edge case awareness**: Do they mention type collisions, undefined handling?",
      "**Code quality**: Clean, readable, well-named code",
      "**Communication**: Can they explain their thinking?"
    ],
    "bonus_points": [
      "Mentioning JSON.stringify limitations (undefined, circular refs) unprompted",
      "Discussing Map vs Object tradeoffs",
      "Explaining why arrow functions break this",
      "Proactively adding cache utilities (clear, size)",
      "Mentioning real-world use cases (React useMemo, Redux selectors)"
    ],
    "red_flags": [
      "Using toString() for keys without realizing the type collision problem",
      "Not understanding why closures are needed",
      "Using arrow function when this matters",
      "Unable to trace through an example",
      "Not considering any edge cases"
    ],
    "what_differentiates_strong_candidates": "Strong candidates immediately recognize this as a closure pattern, mention type safety concerns before being asked, write clean code on first pass, and can discuss real-world applications. They think about production concerns (memory limits, error handling) without over-engineering."
  },
  "time_milestones": {
    "by_5_min": "Understand problem, ask about type handling, edge cases, this context",
    "by_10_min": "Explain approach: closure + Map + JSON.stringify, get buy-in",
    "by_15_min": "Core implementation done (basic memoize working)",
    "by_20_min": "Testing with examples, fixing any bugs",
    "by_25_min": "Edge cases discussed, complexity analyzed",
    "by_30_min": "Part 1 complete, ready for follow-ups",
    "warning_signs": "If you're still explaining approach at 15 min, speed up. If basic implementation isn't done by 20 min, simplify."
  },
  "recovery_strategies": {
    "when_you_make_a_bug": "Say: 'Actually, I see an issue - I used an arrow function but we need regular function for this binding. Let me fix that.' Interviewers expect bugs; they evaluate recovery.",
    "when_you_dont_know_syntax": "Say: 'I don't remember if Map uses .has() or .contains() - let me use .has() and we can verify.' Or: 'I'll use pseudocode here and look up the exact API.'",
    "when_approach_is_wrong": "Say: 'Actually, toString() won't work because it loses type info. Let me reconsider - JSON.stringify would be better.'",
    "when_completely_stuck": "Say: 'I'm stuck on the key generation. Could you give me a hint about how to handle type differentiation?' Asking focused questions is fine.",
    "when_running_out_of_time": "Say: 'I'm running low on time. Let me focus on the core logic and mention what I'd add: LRU eviction, error handling, cache utilities.'"
  },
  "ai_copilot_tips": {
    "when_using_cursor_or_copilot": "AI tools can help with boilerplate and syntax, but YOU must drive the approach.",
    "what_to_do": [
      "Let AI autocomplete obvious patterns (Map initialization, function signatures)",
      "Use AI for test case generation",
      "Let AI help with syntax you forgot (Map API methods)"
    ],
    "what_not_to_do": [
      "Don't paste the problem and ask for solution",
      "Don't accept suggestions without understanding them",
      "Don't let AI drive your design decisions"
    ],
    "how_to_demonstrate_understanding": "If AI suggests something, explain WHY it works: 'Copilot suggested JSON.stringify - that's good because it preserves type information in the serialized key.'",
    "expectation_adjustment": "With AI, you should complete parts faster. If Part 1 takes 30 min with AI, that's too slow."
  },
  "signal_points": {
    "wow_factors": [
      "Immediately recognizing this as a closure pattern",
      "Mentioning JSON.stringify limitations unprompted",
      "Discussing Map vs Object tradeoffs",
      "Explaining this binding with arrow vs regular functions",
      "Mentioning real-world uses (React useMemo, lodash.memoize)"
    ],
    "subtle_signals_of_experience": [
      "Using Map instead of plain Object",
      "Naming the returned function (memoized) for stack traces",
      "Considering error handling",
      "Thinking about cache eviction for production",
      "Writing tests as they code"
    ]
  },
  "red_flags_to_avoid": {
    "behavioral": [
      "Coding silently for too long",
      "Getting defensive about bugs",
      "Not asking clarifying questions",
      "Rushing without explaining"
    ],
    "technical": [
      "Using args.toString() (type collisions)",
      "Using arrow function when this matters",
      "Cache outside closure (shared state)",
      "Not returning the memoized function"
    ],
    "communication": [
      "Using jargon without explaining",
      "Not tracing through examples",
      "Not discussing complexity",
      "Ignoring edge cases entirely"
    ]
  },
  "final_checklist": {
    "before_saying_done": [
      "Does memoize return a function?",
      "Does the returned function call the original correctly?",
      "Are cache keys type-safe? (1 \u2260 '1')",
      "Is this context preserved?",
      "Did I trace through an example?",
      "Did I mention time/space complexity?"
    ],
    "quick_code_review": [
      "Map created inside memoize (not outside)",
      "Regular function (not arrow) for wrapper",
      "fn.apply(this, args) for correct invocation",
      "JSON.stringify for key generation",
      "Return statement for the wrapper"
    ]
  },
  "production_considerations": {
    "what_id_add_in_production": [
      "**LRU cache eviction**: Prevent unbounded memory growth",
      "**Cache size limits**: `options.maxSize`",
      "**TTL expiration**: `options.ttl` for time-based invalidation",
      "**Custom key generator**: `options.keyGenerator` for complex objects",
      "**Error handling**: Decide whether to cache thrown errors",
      "**Cache utilities**: `.clear()`, `.size`, `.has()` on returned function"
    ],
    "why_not_in_interview": "Keep interview code focused. Mention these verbally to show senior thinking: 'In production, I'd add LRU eviction and TTL.'",
    "how_to_mention": "Say: 'This handles the core requirement. In production, I'd also add cache limits to prevent memory leaks, and possibly time-based expiration.'"
  },
  "generated_at": "2026-01-18T21:47:08.465543",
  "_meta": {
    "problem_id": "javascript_polyfills_and_memoization",
    "part_number": null,
    "model": "claude-opus-4-5-20251101"
  }
}